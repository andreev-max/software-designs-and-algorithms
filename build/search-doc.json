[{"title":"4. B-Trees","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-1/b-trees","content":"4. B-Trees B-trees are an immensely powerful tools that are used in SQL and in filesystems. They inherited a loft from red-black trees. Let us figure out what they are and how they work. B-trees are balanced search trees designed to work well on disks or other direct-access secondary storage devices. B-trees are like red-black trees, but they are better at minimizing disk I/O operations. Many database systems use B-trees, or variants of B-trees, to store information. B-trees differ from red-black trees in that B-tree nodes may have many children, from a few to thousands. That is, the &quot;branching factor&quot; of a B-tree can be quite large, although it usually depends on characteristics of the disk unit used. B-trees are similar to red-black trees in that every n-node B-tree has height O(lgn) The exact height of a B-tree can be less than that of a red-black tree, however, because its branching factor, and hence the base of the logarithm that expresses its height, can be much larger. Therefore, we can also use B-trees to implement many dynamic-set operations in time O(lgn). B-trees generalize binary search trees in a natural manner. Next image shows a simple B-tree. If an internal B-tree node x contains x[n] keys, then x has x[n] + 1 children. The keys in node x serve as dividing points separating the range of keys handled by x into x[n] C 1 subranges, each handled by one child of x. When searching for a key in a B-tree, we make an (x[n] + 1)-way decision based on comparisons with the x[n] keys stored at node x. The structure of leaf nodes differs from that of internal nodes; we will examine these differences. Figure 5.1 A B-tree T is a rooted tree (whose root is T.root) having the following properties: Every node x has the following attributes: x[n], the number of keys currently stored in node xthe x.n keys themselves, x[key[1]]; x[key[2]], …, x[key[x[n]]], stored in nondecreasing order, so that x[key[1]] ≤ x[key[2]] ≤ … ≤ x[key[x[n]]]x.leaf, a boolean value that is true if x is a leaf and false if x is an internal node. Each internal node x also contains x[n] + 1 pointers x[c[1]];x[c[2]]; … ;x[c[x[n] + 1]] to its children. Leaf nodes have no children, and so their c[i] attributes are undefined.The keys x[key[i]] separate the ranges of keys stored in each subtree: if k[i] is any key stored in the subtree with root x[c[i]], then:k1 ≤ x[key[1]] ≤ k[2] ≤ x[key[2]] ≤ … ≤ x[key[x[n]]] ≤ k[x[n] + 1]All leaves have the same depth, which is the tree's height hNodes have lower and upper bounds on the number of keys they can contain. We express these bounds in terms of a fixed integer t ≥ 2 called the minimum degree of the B-tree: Every node other than the root must have at least t - 1 keys. Every internal node other than the root thus has at least t children. If the tree is nonempty, the root must have at least one key.Every node may contain at most 2t - 1 keys. Therefore, an internal node may have at most 2t children. We say that a node is full if it contains exactly 2t - 1 keys. To perform an insertion follow this procedure: Check if the tree is empty.If tree is empty, create a new node with inserted value and use it as root of the tree.If tree is not empty, find an appropriate leaf node to append the value by using b-tree search algorithm.If found element has an empty position, add new value to the node, following nondecreasing order.If found element is full, split the leaf node, while sending the middle value to the parent. Repeat this process until sent value is added to a node.If split is performed on a root node, then create a new root node and add the middle value into it. The tree height is then increased by 1. Following is an example of adding values 1 through 10 to a b-tree. Add element 1 by creating a root node. Figure 5.2 Add element 2 by adding it to a root node. Figure 5.3 Add element 3 by splitting root node. Figure 5.4 Add element 4 by adding it to the appropriate leaf. Figure 5.5 Add element 5 by splitting node with 3 and 4. Figure 5.6 Add element 6 to the appropriate leaf. Figure 5.7 Add element 7 to appropriate leaf. Then split the leaf and send middle value (6) up. Figure 5.8 Add element 8 to appropriate leaf. Figure 5.9 Add element 9 to leaf with values 7 and 8. Split the node and send the 8 upwards. Figure 5.10 Add value 10 to node with 9. Figure 5.11","keywords":""},{"title":"2. Binary Search Tree","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-1/binary_search_tree","content":"","keywords":""},{"title":"2.1 Tree Walks​","type":1,"pageTitle":"2. Binary Search Tree","url":"docs/algorithms-and-data-structures-part-1/binary_search_tree#21-tree-walks","content":"The binary search tree property allows us to print out all the values in a binary search tree in sorted order by a simple recursive algorithm, called an inorder tree walk. This algorithm is named so because it prints the value of the root of a subtree between printing the values in its left subtree and printing those in its right subtree. (Similarly, a preorder tree walk prints the root before the values in either subtree, and a postorder tree walk prints the root after the values in its subtrees.) Listing 2.1 - Binary Tree Traversal  Figure 2.2  For example, with a tree in Figure 2.2, those tree walks would give following results: Inorder (Left, Root, Right): 3 5 6 9 11 12Preorder (Root, Left, Right): 9 5 3 6 12 11Postorder (Left, Right, Root): 3 6 5 11 12 9 info The recursive approach is used to implement the Binary Tree Traversal. Check out here the advantages and disadvantages of using recursion. Feel free to figure out on your own how to implement the same using iterative approach. "},{"title":"2.2 Searching​","type":1,"pageTitle":"2. Binary Search Tree","url":"docs/algorithms-and-data-structures-part-1/binary_search_tree#22-searching","content":"Because of the BST properties, it's very easy to search for an element with a following function: Listing 2.2 - searchTree  We can always find an element in a binary search tree whose value is a minimum by following left child pointers from the root until we encounter a null. The search of a tree's maximum is a symmetric procedure: Listing 2.3 - treeMinimum and treeMaximum  Given a node in a binary search tree, sometimes we need to find its successor in the sorted order determined by an inorder tree walk. If all values are distinct, the successor of a node node is the node with the smallest value greater than node.value. The strategy has three basic cases: in case tree and node are the same the null should be returnedin that case node has a right subtree we need to find the left most node in its right subtree which is also the lowest node in its right subtreein that case node does not have a right subtree we need to walk down the tree node until we match the node and return its parent Listing 2.4 - getSuccessor  For an example for Figure 2.2 the inorder successor of 6 is 9, the inorder successor of 5 is 6 and inorder successor of 3 is 5. "},{"title":"2.3 Insert​","type":1,"pageTitle":"2. Binary Search Tree","url":"docs/algorithms-and-data-structures-part-1/binary_search_tree#23-insert","content":"To insert a new value value into a binary search tree tree, we use the function insertNode. It takes a node node for which: node.value = value, node.left = null, and node.right = null and inserts it into an appropriate position in the tree. Listing 2.5 - insertNode  In the Figure 2.2, we want to insert 7. We look at 9 and go left, we look at 5 and go right for 6 and insert 7 into its right subtree. "},{"title":"2.4 Deletion​","type":1,"pageTitle":"2. Binary Search Tree","url":"docs/algorithms-and-data-structures-part-1/binary_search_tree#24-deletion","content":"The overall strategy for deleting a node node from a binary search tree tree has three basic cases but, as we shall see, one of the cases is a bit tricky: If node is leaf (has no children), then we simply remove it by modifying its parent to replace node with null as its child.If node has just one child, then we elevate that child to take nodes position in the tree by modifying node parent to replace node by nodes child.If node has two children, then we find node successor parent — which must be in node right subtree — and have parent take nodes position in the tree. The rest of nodes original right subtree becomes parents new right subtree, and nodes left subtree becomes parents new left subtree. This case is the tricky one because, as we shall see, it matters whether parent is nodes right child. Figure 2.3  In the Figure 2.3, we are removing element 18. Since it has no children, we set the 20's left subtree to null. Figure 2.4  In the second case we are removing element 25. Since it has only one child - 30, we replace the 20's right subtree with 30. Figure 2.5  In the third case, we are removing element 20. Node 20 has 2 children. To delete the node we need to find its inorder successor or inorder predecessor. In our example the inorder successor is node 30 and inorder predecessor is node 19. The inorder successor will be the minimum of the right subtree. The inorder predecessor is going to be the maximum of the left subtree. After replacing the node with found value, we must delete the replacing node. Listing 2.6 - deleteNode  The worst-case time complexity of search, insert, and delete operations is O(h) where h is the height of the Binary Search Tree. In the worst case, we may have to travel from root to the deepest leaf node. The height of a skewed tree may become n (number of nodes), and the time complexity of search and insert operation may become O(n). "},{"title":"1. Algorithms","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-2/algorithms","content":"","keywords":""},{"title":"1.1 Algorithm Characteristics​","type":1,"pageTitle":"1. Algorithms","url":"docs/algorithms-and-data-structures-part-2/algorithms#11-algorithm-characteristics","content":"Algorithms usually have a specific set of input values that it can work with to get a result. For example, sorting algorithms take collections of data values and try to order them. You can also talk about the classification of an algorithm using a variety of criteria. Some algorithms operate on their datasets sequentially, which means they are sequential in nature. Whereas a parallel algorithm can split a dataset into smaller pieces and then work with each one at the same time. The algorithm can be exact, in which case it produces a known predictable value, or it can be approximate, in which case it tries to find an answer that may not be. For example, a face recognition algorithm may not give the same answer every time with the same face. Algorithms can be deterministic, in which case they perform each step with an exact solution, and it can be non-deterministic if they try to find a solution using consecutive guesses that become more accurate over time. "},{"title":"1.2 Common Algorithms​","type":1,"pageTitle":"1. Algorithms","url":"docs/algorithms-and-data-structures-part-2/algorithms#12-common-algorithms","content":""},{"title":"1.2.1 Search Algorithms​","type":1,"pageTitle":"1. Algorithms","url":"docs/algorithms-and-data-structures-part-2/algorithms#121-search-algorithms","content":"This kind of algorithms find specific data in structure. (for example, a substring within a string). One of the most common types of algorithms you come across is search algorithms, which are used when you need to find a piece of data within a larger data structure. For example, searching for a substring within a larger string, or perhaps searching for a file in a set of subfolders in the file system. "},{"title":"1.2.2 Sorting Algorithms​","type":1,"pageTitle":"1. Algorithms","url":"docs/algorithms-and-data-structures-part-2/algorithms#122-sorting-algorithms","content":"Take a dataset and apply a sort to order it. Sorting algorithms are another very common type used when working with ordered datasets. And, you guessed it, they take a dataset and put them in a specific order. "},{"title":"1.2.3 Computational Algorithms​","type":1,"pageTitle":"1. Algorithms","url":"docs/algorithms-and-data-structures-part-2/algorithms#123-computational-algorithms","content":"Given one set of data, calculate another basing on this set. Computational algorithms are used to get from one dataset to another. And a simple example would be calculating whether a given number is a prime number, or perhaps converting a temperature from one scale to another. "},{"title":"1.2.4 Collection Algorithms​","type":1,"pageTitle":"1. Algorithms","url":"docs/algorithms-and-data-structures-part-2/algorithms#124-collection-algorithms","content":"Work with collections of data (count specific items, navigate among data elements, filter out unwanted data etc.). Finally, there are collection algorithms that involve manipulating or navigating between sets of data that are stored in a particular structure. It's easy to imagine examples here that count the number of specific items, filter out unwanted data, and so on. "},{"title":"1.3 Algorithm Performance​","type":1,"pageTitle":"1. Algorithms","url":"docs/algorithms-and-data-structures-part-2/algorithms#13-algorithm-performance","content":"Since algorithms are designed to work with datasets and solve computational problems, it is important to understand how to talk about the performance of an algorithm. This is an important factor in how you choose a particular algorithm for solving a computational problem, as well as understanding how your program will behave in different circumstances. So, we want to measure how the performance of an algorithm changes based on the size of the input dataset. You will often hear a term called Big-O notation that is used to describe the performance of an algorithm. This notation format is used to describe how a particular algorithm works as the input data set grows over time. And the reason the letter O is used is that the rate at which the complexity of an algorithm grows is also called order of operation. It usually describes a worst-case scenario of how long it will take to complete a given operation. And it's important to note that many algorithms and data structures have more than one Big-O value. For example, data structures can usually perform several types of operations, such as inserting or searching for values, each with its own order of operations. Notation\tDescription\tExampleO(1)\tConstant time\tLooking for a single element in an array knowing index O(logn)\tLogarithmic\tFinding an item in a sorted array with a binary search O(n)\tLinear time\tSearching an unsorted array of for a specific value O(nlogn)\tLog-linear\tComplex sorting algorithms like heap sort and merge sort O(n2)\tQuadratic\tSimple sorting algorithms, such as bubble sort, selection sort So let's take a look at some common Big-O notation terms to see what they mean in real-world scenarios. Each of these items are arranged in ascending order of complexity of time. The simplest example is what's called constant time, and this corresponds to a Big-O equal to one. And in essence, this means that the operation in question does not depend on the number of elements in a given dataset. A good example of this is calculating whether a number is even or odd, or looking for a specific index of an element in an array. Next comes the order of log n, which is called logarithmic time. And a typical example of this kind of operations is searching for a specific value in a sorted array using binary search. Thus, as the number of elements in the sorted array grows, it only takes a logarithmic ratio of time to find any given element. The next is linear time, which corresponds to Big-O of n, and this level of time complexity corresponds to a typical example of finding an element in an unsorted array. We also have an order of n times logn or the so-called logarithmic time complexity. Examples would be some sorting algorithms such as heap sort and merge sort. And finally, the order of n squared, which is called the quadratic time complexity, and as you probably guessed, this is not a very good level of performance, because it means that as the number of elements in the dataset increases, the time it takes to process they increase in the square of this number. An example would be several simpler sorting algorithms such as bubble sort and selective sort. Figure 1.1  Believe it or not, there is actually even worse than quadratic dependence. But this is a good list of the levels of difficulty that you are likely to encounter in your work. As you can see, there is a graph (Figure 1.1) representatively showing how much the number of operations will change depending on the number of input elements. "},{"title":"1.4 Correctness of Algorithm​","type":1,"pageTitle":"1. Algorithms","url":"docs/algorithms-and-data-structures-part-2/algorithms#14-correctness-of-algorithm","content":"An algorithm is considered correct if, at any admissible (for a given problem) input, it finishes its work and produces a result that meets the requirements of the problem. In this case, the algorithm is said to solve the given computational problem. An incorrect algorithm (for some input) may not stop at all or give an incorrect result, but this does not mean that such algorithms are completely useless. If errors are rare enough, or it is possible to control the frequency of errors, we may admit the use of incorrect algorithms. It may be that initially we have a specific task with one data set, and we have compiled an algorithm. Then some new data begins to arrive, there are not many of them, but with them the algorithm slows down significantly. But since there is little such data so far, the algorithm is quite working. "},{"title":"1.5 Analyzing Algorithm​","type":1,"pageTitle":"1. Algorithms","url":"docs/algorithms-and-data-structures-part-2/algorithms#15-analyzing-algorithm","content":"Analyzing an algorithm has come to mean predicting the resources that the algorithm requires. Occasionally, resources such as memory, communication bandwidth, or computer hardware are of primary concern, but most often it is computational time that we want to measure. Generally, by analyzing several candidate algorithms for a problem, we can identify a most efficient one. Such analysis may indicate more than one viable candidate, but we can often discard several inferior algorithms in the process. Before we can analyze an algorithm, we must have a model of the implementation technology that we will use, including a model for the resources of that technology and their costs. For this lecture, we will assume a generic one processor, random-access machine (RAM) model of computation as our implementation technology and understand that our algorithms will be implemented as computer programs. In the RAM model, instructions are executed one after another, with no concurrent operations. "},{"title":"1. Elementary Data Structures","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-1/elementary_data_structures","content":"","keywords":""},{"title":"1.1 Stacks and Queues​","type":1,"pageTitle":"1. Elementary Data Structures","url":"docs/algorithms-and-data-structures-part-1/elementary_data_structures#11-stacks-and-queues","content":"Figure 1.1  The first data structure we are going to look at is a stack (Figure 1.1). A stack is a dynamic set in which the element removed from the set is the one most recently inserted. The stack implements a last-in, first-out, or LIFO policy. Figure 1.2  The next data structure we should be aware of is a queue (Figure 1.2). A queue is a dynamic set in which the element removed from the set is the on that has been in the set for the longest time. The stack implements a first-in, first-out or FIFO policy. Those are two types of collections of data with defined operations such as insertions, removals and element search. Stacks and queues could be used in order to process certain types of operations. For example, we have a function that calls another function, that, in turn calls a different function. Then, the result from the innermost functions are being returned up. In a situation like this it's better to use a stack. We would take the uppermost function, start the execution until we reach a function call. At this moment we would take the state of execution of current function, put it into a stack and start execution of an inner function. This operation is repeated with every inner function. When the execution flow reaches a return statement, an item is removed from the stack and execution continues. Operations of addition for a stack are usually called push, and operations of removal are called pop. A peek operation is sometimes defined on a stack, with this operation we would look into contents of the top element of the stack without removal. For queue, similar operations are usually called enqueue and dequeue. Figure 1.3  There are also data structures that have properties of both a queue and a stack, called double ended queue (Figure 1.3). It's important to know when to apply each type of data structure. For example, other than managing state of the execution, a stack is useful for a reversal of elements. If a string is inserted into a stack, when popped it will be reversed. Other usage of a stack would be for storage of previous operations from Command pattern. In this case, if your commands have an undo operation, one could simply pop the last command and reverse its actions. Operations on a stack are also highly effective and take constant time - O(1). That is why the stack is usually implemented as a linked list or a dynamic array. On the other hand, if you need to find an element in a stack, it will take, in a worst-case O(n) time. Sorting a stack is also not an easy task. Queues are like stacks in terms of time needed for adding and removing an element. It takes constant time to enqueue and dequeue an element. Queues are implemented using double linked list. "},{"title":"1.2 Linked Lists​","type":1,"pageTitle":"1. Elementary Data Structures","url":"docs/algorithms-and-data-structures-part-1/elementary_data_structures#12-linked-lists","content":"So, what are linked lists? Linked list (Figures 1.4) is a data structure in which the objects are arranged in a linear order. Order in a linked list is determined by a pointer in each object. Other variation of a linked list is a double linked list (Figures 1.5), where each element also contains a pointer to the previous element. Figure 1.4  Figure 1.5  The advantage of this data structure is usage of pointers. In languages with manual memory allocation this allows data structures to allocate memory dynamically. In javascript, this advantage is mitigated in general, but other features of a double linked list could be used. Main operations on a linked list are add, access, delete and search. With add operation, memory is allocated for a new node and then the pointer in the last element is updated to point to the new node. Search operation takes an index it needs to access, goes to the first node, then to second node and to next one, until the searched node is reached. There is also an operation called insert into defined on a linked list. It takes a new node and an index after which it should be placed (i). With this operation, a node with index i - 1 is found. Pointer from this node is stored somewhere, then replaced with pointer to inserted node. Then, pointer from node with index i - 1 is stored in newly added node. Figure 1.6  Figure 1.7  Other type of linked lists are cyclic linked lists (Figure 1.6). In a non-cyclic linked list, the last element is pointing to null, and no element is pointing to the first element. In a cyclic linked list, the last element is pointing to the first element. In a cyclic double linked list (Figure 1.7), the last element is pointing to the first and first points to the last. When accessing elements in a linked list, the first element could be accessed in constant time O(1). In the worst case, if the last element is needed the time will be O(n). "},{"title":"5. Graphs","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-1/graphs","content":"","keywords":""},{"title":"5.1 BFS​","type":1,"pageTitle":"5. Graphs","url":"docs/algorithms-and-data-structures-part-1/graphs#51-bfs","content":"Breadth-first search (BFS) is one of the simplest algorithms for searching a graph and the archetype for many important graph algorithms. Given a graph G = (V, E) and a distinguished source vertex s, breadth-first search systematically explores the edges of G to discover every vertex that is reachable from s. It computes the distance (the smallest number of edges) from s to each reachable vertex. It also produces a breadth-first tree with root s that contains all reachable vertices. For any vertex v reachable from s, the simple path in the breadth-first tree from s to v corresponds to the shortest path from s to v in G, that is, a path containing the smallest number of edges. The algorithm works on both directed and undirected graphs. The breadth-first-search procedure BFS below assumes that the input graph G = (V, E) is represented using adjacency lists. It attaches several additional attributes to each vertex in the graph. We store the color of each vertex u ϵ V in the attribute u.color and the predecessor of u in the attribute u.p. If u has no predecessor (for example, if u = s or u has not been discovered), then u.p = null. The attribute u.d holds the distance from the source s to vertex u computed by the algorithm. The algorithm also uses a first-in, first-out queue Q to manage the set of gray vertices. Listing 5.1 - BFS function BFS(G, s) { let u, v; for (u of G) { u.color = 'WHITE'; u.d = Number.POSITIVE_INFINITY; u.p = null; } s.color = 'GRAY'; s.d = 0; s.p = null; Q = []; Q.push(s); while (Q.length &gt; 0) { u = Q.unshift(); for (v of G.Adj[u]) { if (v.color === 'WHITE') { v.color = 'GRAY'; v.d = u.d + 1; v.p = u; Q.push(Q, v) } } u.color = 'BLACK'; } }  Here is a visualization of this type of search. Figure 5.2  "},{"title":"5.2 DFS​","type":1,"pageTitle":"5. Graphs","url":"docs/algorithms-and-data-structures-part-1/graphs#52-dfs","content":"The strategy followed by depth-first search (DFS) is, as its name implies, to search &quot;deeper&quot; in the graph whenever possible. Depth-first search explores edges out of the most recently discovered vertex v that still has unexplored edges leaving it. Once all of vs edges have been explored, the search &quot;backtracks&quot; to explore edges leaving the vertex from which v was discovered. This process continues until we have discovered all the vertices that are reachable from the original source vertex. If any undiscovered vertices remain, then depth-first search selects one of them as a new source, and it repeats the search from that source. The algorithm repeats this entire process until it has discovered every vertex. Listing 5.2 - DFS function DFS(G) { for (let u of G) { u.color = 'WHITE'; u.p = null; } let time = 0; for (let u of G) { if (u.color === 'WHITE') { dfsVsisit(G, u); } } function dfsVsisit(G, u) { time++; u.d = time; u.color = 'GRAY'; for (let v of G.Adj[u]) { if (v.color === 'WHITE') { v.p = u; dfsVsisit(G, v); } } u.color = 'BLACK'; time++; u.f = time; } }  Here is an example of steps performed in DFS. Figure 5.3  "},{"title":"5.3 Finding the Shortest Path​","type":1,"pageTitle":"5. Graphs","url":"docs/algorithms-and-data-structures-part-1/graphs#53-finding-the-shortest-path","content":"And now we are reaching the theme of your home task – search of the shortest path. To find the shortest path in an unweighted graph, the best solution will be to use BFS. With weighted graphs the task becomes non-trivial. One of the most common tasks of searching a short path is a travelling salesman problem that asks the following question: &quot;Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?&quot;. The simplest way to find out is to use brute-force and try to find all permutations and see which one is the cheapest. The downside to this approach is its running time which lies within a polynomial factor of O(n!), the factorial of the number of cities, so this solution becomes impractical even for only 20 cities. Let us look at a different, much easier problem. Professor Patrick wishes to find the shortest possible route from Phoenix to Indianapolis. Given a road map of the United States on which the distance between each pair of adjacent intersections is marked, how can she determine this shortest route? One possible way would be to enumerate all the routes from Phoenix to Indianapolis, add up the distances on each route, and select the shortest. It is easy to see, however, that even disallowing routes that contain cycles, Professor Patrick would have to examine an enormous number of possibilities, most of which are simply not worth considering. For example, a route from Phoenix to Indianapolis that passes through Seattle is obviously a poor choice, because Seattle is several hundred miles out of the way. In a shortest-paths problem, we are given a weighted, directed graph G = (V, E), with weight function: E -&gt; R mapping edges to real-valued weights. The weight w(p) of path p = (v[0], v[1], …, v[k]) is the sum of the weights of its constituent edges:  One of the ways to solve this problem would be to use Dijkstra's algorithm. "},{"title":"5.4 Dijkstra's Algorithm​","type":1,"pageTitle":"5. Graphs","url":"docs/algorithms-and-data-structures-part-1/graphs#54-dijkstras-algorithm","content":"Dijkstra's algorithm solves the single-source shortest-paths problem on a weighted, directed graph G = (V, Е) for the case in which all edge weights are nonnegative. In this section, therefore, we assume that w(u, v) &gt; 0 for each edge (u, v) ϵ Е. Dijkstra's algorithm maintains a set S of vertices whose final shortest-path weights from the source s have already been determined. The algorithm repeatedly selects the vertex u 2 V - S with the minimum shortest-path estimate, adds u to S, and relaxes all edges leaving u. In the following implementation, we use a min-priority queue Q of vertices, keyed by their d values. Dijkstra's algorithm can be implemented as following: Listing 5.3 - Dijkstra function Dijkstra(G, w, s) { initSingleSource(G, s); S = []; Q = G.V; // build queue with priorities according to d values of vertices while (Q) { let u = Q.extractMin(); S.push(u); for (let vertex in G.Adj[u]) { relax(u, v, w); } } }  Where functions initSingleSource and relax are defined like this: Listing 5.4 - initSingleSource and relax function initSingleSource(G, s) { for (let vertex of G) { v.d = Number.MAX_SAFE_INTEGER; v.p = null; } s.d = 0; } function relax(u, v, w) { if (v.d &gt; u.d + w(u, v)) { v.d = u.d + w(u, v); v.p = u; } }  And here is a visualization of Dijkstra's algorithm. The process of relaxing an edge (u, v) consists of testing whether we can improve the shortest path to v found so far by going through u and, if so, updating v.d and v.p. Figure 5.4  "},{"title":"6. 📚 Home Task","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-2/hometask","content":"","keywords":""},{"title":"Job runner​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/algorithms-and-data-structures-part-2/hometask#job-runner","content":"As an implementation of this home task you should create circular job runner. Each job must have a priority and should be run according to it. Priority could be set by randomizer. Job result is insignificant in terms of the h/w, for example it could be logging of job's priority in console. Job runner must handle at least 10000 jobs without noticeable performance issues. tip Job runner is nothing more than a priority queue "},{"title":"5. Other sorting algorithms","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-2/other_sorting_algorithms","content":"5. Other sorting algorithms There are many other sorting algorithms. The following table provides an overview of some sorting algorithms. It is a selection of the most common sorting algorithms. Algorithm\tTime best case\tTime avg case\tTime worst case\tSpaceQuicksort\tO(n log n)\tO(n log n)\tO(n2)\tO(log n) Bubble Sort\tO(n)\tO(n2)\tO(n2)\tO(1) Counting Sort\tO(n + k)\tO(n + k)\tO(n + k)\tO(n + k) Selection Sort\tO(n2)\tO(n2)\tO(n2)\tO(1) Some of them, like Quicksort and Merge Sort alongside with Heap Sort are based on the divide and conquer principle and are considered efficient sorting algorithms that achieve a much better time complexity of Θ(nlogn) and therefore, also suitable for large data sets with billions of elements.Quicksort picks an element as a pivot and partitions the array based on the pivot. How to pick pivot? Always pick the first element as a pivotAlways pick the last element as a pivot (implemented below)Pick a random element as a pivotPick median as a pivot The partition process is a key process. Choose x element as pivot, put x and its position in a sorted array, then put all smaller elements before the pivot, and all larger elements after the pivot. Bubble Sort algorithm is the most straightforward way of sorting, it has the suboptimal characteristics, but it is easy to perceive. Counting Sort sorts the elements of an array by counting the number of occurrences of each unique element in the array. It has the linear time and will take O(k + n) (where k is the value of the max element in the input array) time to finish, but it is efficient if the range of input data is not significantly greater than the number of elements to be sorted. Selection Sort sorts elements by picking a minimum element from an unsorted subarray and putting it at the beginning of the sorted subarray (considering ascending order). Article If you are interested in more algorithms you can find useful information in the article.","keywords":""},{"title":"3. Divide and Conquer","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-2/divide_and_conquer","content":"","keywords":""},{"title":"3.1 Merge Sort​","type":1,"pageTitle":"3. Divide and Conquer","url":"docs/algorithms-and-data-structures-part-2/divide_and_conquer#31-merge-sort","content":"Listing 3.1 - Merge sort  info The space complexity of Merge Sort implementation above is: O(n) It can be improved by implemented in-place merge sort when the sort is applied to the provided array without creating new one and thus saving the memory. More information about can be found here. This is how mergeSort looks like. We take half the length of the array and divide it into two parts. And we call the merge function to the same sorting from the left and right sides. The merge function itself compares and merges our sequences. Although the code for merge sort works correctly when the number of elements is not even, our recurrence-based analysis is simplified if we assume that the original problem size is a power of 2. Each divide step then yields two subsequences of size exactly n/2. This assumption does not affect the order of growth of the solution to the recurrence. We reason as follows to set up the recurrence for T(n), the worst-case running time of merge sort on n numbers. Merge sort on just one element takes constant time. When we have n &gt; 1 elements, we break down the running time as follows: Divide: The divide step just computes the middle of the subarray, which takes constant time. Thus, D(n) = Θ(1).Conquer: We recursively solve two subproblems, each of size n/2, which contributes 2T(n/2) to the running time.Combine: We have already noted that the MERGE procedure on an n-element subarray takes time Θ(n), and so C(n) = Θ(n). When we add the functions D(n) and C(n) for the merge sort analysis, we are adding a function that is Θ(n) and a function that is Θ(1). This sum is a linear function of n, that is Θ(n). Adding it to the 2T(n/2) term from the &quot;conquer&quot; step gives the recurrence for the worst-case running time T(n) of merge sort:  The master method provides a &quot;cookbook&quot; method for solving recurrences of the form:  where a ≥ 1 and b &gt; 1 are constants and f(n) is an asymptotically positive function. According to the master theorem: If f(n) = O(nlogba-ϵ) for some constant ϵ &gt; 0, then T(n) = θ(nlogba)If f(n) = θ(nlogba) then T(n) = θ(nlogbalgn)If f(n) = Ω(nlogba+ϵ) for some constant ϵ &gt; 0, and if af(n/b) &lt; cf(n) for some constant c &lt; 1 and all sufficiently large n,then T(n) = θ(f(n)) Let's use the master method to solve the &quot;divide and conquer&quot; recurrence: 2T(n/2) + Θ(n). Here, we have a=2, b=2, f(n) = Θ(n), and thus we have that: nlogba = nlog22 = n. Case 2 applies, since f(n) = Θ(n), and so we have the solution: T(n) = Θ(nlgn). "},{"title":"4. Heap. Heap Sort. Priority Queue","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-2/heap","content":"","keywords":""},{"title":"4.1 Heap​","type":1,"pageTitle":"4. Heap. Heap Sort. Priority Queue","url":"docs/algorithms-and-data-structures-part-2/heap#41-heap","content":"What does this heap look like? We have an array that we can represent as a tree. The numbers above the element in the array and the heap are the same, you can see how they are substituted into the leaves. Figure 4.1  Figure 4.2  It doesn't have to be an array, different programming languages have different data structures. For following example it is more convenient to consider it as an array. Figure 2.1 function maxHeapify(A, i) { let l = left(i); let r = right(i); if (l &lt;= A.heapSize &amp;&amp; A[l] &gt; A[i]) { largest = l; } else { largest = i; } if (r &lt;= A.heapSize &amp;&amp; A[r] &gt; A[largest]) { largest = r; } if (largest != i) { // exchange A[i] with A[largest] [A[i], A[largest]] = [A[largest], A[i]]; maxHeapify(A[largest]); } }  Array A, which will represent our heap, also has attributes such as length - the number of elements in the array. And heap-size, the number of elements in the heap. The root of the tree is the first element in the array. We can easily calculate all the indexes of the nodes. The parent node or node is i/2. The left child is 2i and the right is 2i + 1. There are two types of our heaps. If max hip has the largest root node and the heap goes down, min has a minimum root node and goes up. For heap sorting, max heap is usually used, and min heap is used for building a priority queue. "},{"title":"4.2 Maintaining the Heap Property​","type":1,"pageTitle":"4. Heap. Heap Sort. Priority Queue","url":"docs/algorithms-and-data-structures-part-2/heap#42-maintaining-the-heap-property","content":"In order to maintain the max-heap property, we call the function maxHeapify. When it is called, maxHeapify assumes that the binary trees rooted at left(i) and right(i) are max-heaps, but that A[i] might be smaller than its children, thus violating the max-heap property. Function maxHeapify lets the value at A[i] &quot;float down&quot; in the max-heap so that the subtree rooted at index i obeys the max-heap property. Figure 4.3  This heap must somehow support itself, for example, when inserting or when deleting elements a heap rebuild should take place. We have a procedure, let's call it maxHeapify. When it is called, we assume that the left and right nodes are also maxHeap. But these nodes can be smaller than its children, and we have to let it go down below. As we can see, the second element has ceased to meet the requirement, and we check the left heap until we reach the sheet. At each step, the largest of the elements A[i], A[left(i)], and A[right(i)] is determined, and its index is stored in largest. If A[i] is largest, then the subtree rooted at node i is already a max-heap and the procedure terminates. Otherwise, one of the two children has the largest element, and A[i] is swapped with A[largest], which causes node i and its children to satisfy the max-heap property. The node indexed by largest, however, now has the original value A[i], and thus the subtree rooted at largest might violate the max-heap property. Consequently, we call maxHeapify recursively on that subtree. The running time of maxHeapify on a subtree of size n rooted at a given node i is the Θ(1) time to fix up the relationships among the elements A[i], A[left(i)], and A[right(i)], plus the time to run maxHeapify on a subtree rooted at one of the children of node i (assuming that the recursive call occurs). The children's subtrees each have size at most 2n/3 - the worst case occurs when the bottom level of the tree is exactly half full—and therefore we can describe the running time of maxHeapify by the recurrence:  The solution to this recurrence, by case 2 of the master theorem is T(n) = O(lgn). And so, let's analyze the algorithm. We define the largest element of the three, then swap and so on, omit the element. For our first node, we have a Tetta from n. For a single node, then we split into under trees and go down under the trees. We have a maximum number of child subtrees, in the worst case, 2n/3. This is when we go from half to the very bottom. Thus, the following time is obtained: T(n) = O(lgn). Turning to the master theorem, we get the result: lg6 = 2.6. This is a very good result, we need to spend less resources than our operations. "},{"title":"4.3 Building a Heap​","type":1,"pageTitle":"4. Heap. Heap Sort. Priority Queue","url":"docs/algorithms-and-data-structures-part-2/heap#43-building-a-heap","content":"The heap should be built using method buildMaxHeap. To do this, you need to run the entire array through the maxHeapify function. As we see the complexity becomes nlg(n), we have a linear dependency - we apply a function for each element and call maxHeapify itself. We can use the procedure maxHeapify in a bottom-up manner to convert an array A[1..n], where n = A.length, into a max-heap. The elements in the subarray A[(n/2+1)..n] are all leaves of the tree, and so each is a 1-element heap to begin with. The function buildMaxHeap goes through the remaining nodes of the tree and runs maxHeapify on each one. We can compute a simple upper bound on the running time of buildMaxHeap: Each call to maxHeapify costs O(lgn) time.Procedure buildMaxHeap makes O(n) such calls.Thus, the running time is O(nlgn). This upper bound, though correct, is not asymptotically tight. Figure 4.4  We have an unsorted array, and we usually start in the middle. Each time the offset is made, the heap gets a complete look. "},{"title":"4.4 Heap Sort​","type":1,"pageTitle":"4. Heap. Heap Sort. Priority Queue","url":"docs/algorithms-and-data-structures-part-2/heap#44-heap-sort","content":"The heapsort algorithm starts by using buildMaxHeap to build a max-heap on the input array A[1..n], where n = A.length. Since the maximum element of the array is stored at the root A[1], we can put it into its correct final position by exchanging it with A[n]. If we now discard node n from the heap — and we can do so by simply decrementing A.heapSize - we observe that the children of the root remain max-heaps, but the new root element might violate the max-heap property. All we need to do is to restore the max-heap property, however, is call maxHeapify, which leaves a max-heap in A[1..n-1]. The heapsort algorithm then repeats this process for the max-heap of size n - 1 down to a heap of size 2. The heapsort procedure takes time O(nlgn) since the call to buildMaxHeap takes time O(n) and each of the n - 1 calls to maxHeapify takes time O(lgn). Based on this data structure, we can build a sort algorithm called &quot;heap sort&quot;. We have to build our heap from some dataset, and then starting from the first elements we put it in the first place and reduce the length with our heap, it remains in the array, but it is not part of the heap. Thus, each time we rebuild our heap, we will sort our array and each time we sort the smaller array. heapsort is thus executed for nlgn. Figure 4.5  We take the first element and remove it from the heap when we put it first in the array. The tree is automatically rebuilt, now we take the first one again and put it in second place, and so on, until the heap ceases to exist and our array is completely sorted. "},{"title":"4.5 Priority Queue​","type":1,"pageTitle":"4. Heap. Heap Sort. Priority Queue","url":"docs/algorithms-and-data-structures-part-2/heap#45-priority-queue","content":"A priority queue is a data structure for maintaining a set S of elements, each with an associated value called a key. A max-priority queue supports the following operations: INSERT(S, x) inserts the element x into the set S.MAXIMUM(S) returns the element of S with the largest key.EXTRACT-MAX(S) removes and returns the element of S with the largest key.INCREASE-KEY(S, x, k) increases the value of element xs key to the new value k, which is assumed to be at least as large as xs current key value. This is a very good sort, but in most cases it is not the most optimal sort. But for some reason we are considering it, and all because on the basis of the heap it is very good to build a queue with priority. This is how it is implemented in most programs. For example, where you can use this queue - schedule a job on the server or use an event-driven approach when modeling physical processes with great complexity. For example, an event occurs with a minimum priority, it is executed, the time is recalculated, inserted into the queue, and the event we need appears at the top. Also, there are queues with the highest priority or with the lowest. You can insert an element into it, you can take the maximum element, extract the maximum element, and you can change the priority of some element. For example, processor time, there is a queue of tasks that it executes in one clock cycle, it performs a task, the priority changes - we insert it into the queue and take it with the next priority. "},{"title":"6. 📚 Home Task","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-1/hometask","content":"","keywords":""},{"title":"Graph generator​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/algorithms-and-data-structures-part-1/hometask#graph-generator","content":"As an implementation of this home task, you should create an application that allows creating a weighted graph and keep it as an adjacency list. For that, you need to implement WeightedGraph interface interface WeightedGraph&lt;T&gt; { addVertex(key: string): void; addEdge(vertex1: T, vertex2: T, weight: number): void; }  so that for a graph  you can use your implementation of WeightedGraph interface to represent it in code  const vertices = [ new Vertex('1'), new Vertex('2'), new Vertex('3'), new Vertex('4'), new Vertex('5') ]; const edges = [ new Edge(vertex1, vertex4, 3), new Edge(vertex1, vertex2, 5), new Edge(vertex1, vertex3, 4), new Edge(vertex2, vertex4, 6), new Edge(vertex2, vertex3, 5), ]; const graph: WeightedGraph = new &lt;Your WeightedGraph implementation&gt;; vertices.forEach(verticle =&gt; graph.addVertex(verticle)); edges.forEach(edge =&gt; graph.addEdge(edge.from, edge.to, edge.weight));  "},{"title":"Find the shortest path​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/algorithms-and-data-structures-part-1/hometask#find-the-shortest-path","content":"The application should have the possibility to find the shortest paths from one vertex to others (findAllShortestPaths method) and to find the shortest path between two vertexes (findShortestPath method). For that, you should implement the Dijkstra interface bellow interface Path { path: string[]; distance: number; } interface Dijkstra&lt;T&gt; { findShortestPath(vertex1: T, vertex2: T): Path; findAllShortestPaths(vertex: T): Record&lt;string, Path&gt;; }  and use it like bellow  const dijkstra: Dijkstra = new &lt;Your Dijkstra implementation&gt;(graph); dijkstra.findShortestPath(vertex4, vertex3); // { path: ['4', '1', '3'], distance: 7 } dijkstra.findShortestPath(vertex1, vertex5); // { path: [], distance: Infinity } dijkstra.findShortestPath(vertex1, vertex1); // { path: ['1'], distance: 0 } dijkstra.findAllShortestPaths(vertex4); /* { '1': { path: ['4', '1'], distance: 3 }, '2': { path: ['4', '2'], distance: 6 }, '3': { path: ['4', '1', '3'], distance: 7 }, '5': { path: [], distance: Infinity } } */  Your application should work with much more complex graphs. The one provided above is just an example. "},{"title":"Evaluation criteria​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/algorithms-and-data-structures-part-1/hometask#evaluation-criteria","content":"Only graph generator is implemented.Graph generator is implemented and only one of the methods of Dijkstra interface is implemented correctly.Graph generator is implemented and both methods of Dijkstra interface are implemented correctly with minor issues with regard to edge cases.Graph generator is implemented and both methods of Dijkstra interface are implemented correctly without any issue. "},{"title":"3. Red-Black Tree","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-1/red-black_tree","content":"","keywords":""},{"title":"3.1 Insert and Delete​","type":1,"pageTitle":"3. Red-Black Tree","url":"docs/algorithms-and-data-structures-part-1/red-black_tree#31-insert-and-delete","content":"The search-tree operations TREE-INSERT and TREE-DELETE, when run on a red-black tree with n keys, take O(lgn) time. Because they modify the tree, the result may violate the red-black properties. To restore these properties, we must change the colors of some nodes in the tree and also change the pointer structure. Figure 3.2  We change the pointer structure through rotation, which is a local operation in a search tree that preserves the binary-search-tree property. Image below shows the two kinds of rotations: left rotations and right rotations. When we do a left rotation on a node x, we assume that its right child y is not null; x may be any node in the tree whose right child is not null. The left rotation &quot;pivots&quot; around the link from x to y. It makes y the new root of the subtree, with x as ys left child and ys left child as xs right child. Listing 3.1 - rotateLeft and rotateRight rotateLeft() { let y = this.right; this.right = y.left; if (!y.left.isNil) { y.left.parent = this; } if (!y.isNil) y.parent = this.parent; if (this.parent) { if (this.id == this.parent.left.id) { this.parent.left = y; } else { this.parent.right = y; } } else { this.tree.root = y; } y.left = this; if (!this.isNil) this.parent = y; }, rotateRight() { let y = this.left; this.left = y.right; if (!y.right.isNil) { y.right.parent = this; } if (!y.isNil) y.parent = this.parent; if (this.parent) { if (this.id == this.parent.right.id) { this.parent.right = y; } else { this.parent.left = y; } } else { this.tree.root = y; } y.right = this; if (!this.isNil) this.parent = y; }  This is how methods of left and right rotation are defined. They are completely symmetrical. Figure 3.3  Here is a visualization of a rotation. In this example, we are rotating element x in a tree T left. After a rotation, the y element &quot;pulls&quot; its right subtree up (elements 19, 20, 22). Left subtree of x (9) stays the same, and left subtree of y becomes right subtree of x. Listing 3.2 - insertNode insertNode(data) { let current, parent, x; current = this.root; parent = null; while (!current.isNil) { if (data == current.value) return current; parent = current; current = data &lt; current.value ? current.left : current.right; } x = new rbNode(this); x.value = data; x.parent = parent; x.isRed = true; x.isNil = false; x.left = new rbNode(this); x.right = new rbNode(this); if (parent) { if (x.value &lt; parent.value) { parent.left = x; } else { parent.right = x; } } else { this.root = x; } this.insertFixup(x); return x; }  To insert a node, first we have to find a place to insert it into. The new node will always be added as a leaf. This means that both of his children are NIL and are black. The newly added node will always be red. After insertion, we perform a insertFixup operation defined as following: Listing 3.3 - insertFixup insertFixup(x) { while (x.id != this.root.id &amp;&amp; x.parent.isRed) { if (x.parent.id == x.parent.parent.left.id) { let y = x.parent.parent.right; if (y.isRed) { x.parent.isRed = false; y.isRed = false; x.parent.parent.isRed = true; x = x.parent.parent; } else { if (x.id == x.parent.right.id) { x = x.parent; x.rotateLeft(); } x.parent.isRed = false; x.parent.parent.isRed = true; x.parent.parent.rotateRight(); } } else { let y = x.parent.parent.left; if (y.isRed) { x.parent.isRed = false; y.isRed = false; x.parent.parent.isRed = true; x = x.parent.parent; } else { if (x.id == x.parent.left.id) { x = x.parent; x.rotateRight(); } x.parent.isRed = false; x.parent.parent.isRed = true; x.parent.parent.rotateLeft(); } } } this.root.isRed = false; }  To perform the fixup, we have to look at the parent, and check if the red-black property is followed. If the parent node is black – we can exit. If it is red, we recolor it black and preform a rotation to balance the tree. By inserting a red node with 2 NIL-children, we are keeping the property of black height (property 4). Although, this could mean that we are breaking the property 3, according to which both children of a red node have to be black. So, let's look at a situation when a parent of a new node is red, by which the property 3 will be violated. Let's look at 2 different cases: Case 1: Red parent, red &quot;uncle&quot;. This is called red-red violation. The new node X has a red parent and a red &quot;uncle&quot; (the other sibling of parents' parent). A simple recolor will fix the red-red violation. After recoloring, we must check the &quot;grandparent&quot; of the new node because it could be red. Look at how the new red node influences nodes at the top. At the end we recolor the root node black. If it was red before, we increase the black height of the tree. Case 2: Red parent, black &quot;uncle&quot;. This is the other case of red-red violation – the &quot;uncle&quot; of the new node is black. Here, the nodes could be rotated to correct the subtrees. At this point, the algorithm could exit because there are no red-red violations, and the root of the tree is painted black. Please note, that if the node x was the right sibling, then at first, the left rotation will be applied. It will make the new node the left sibling. Every correction, performed at insertion makes us go up a tree by one level. The deletion of a node is analogous to insertion, but instead of looking at the uncle node, we look at the sibling of the deleted node. If you want to learn more about deletion, please look it here. Let us look at an example of insertion of a node. Figure 3.4  Figure 3.5  At first (a), we insert a node z with value 4. It's inserted red, the parent of it is red and the uncle t is red too. To fix this red-red violation, we recolor the parent of z and y to black and make the parent red (transition a-b). Now, we have a red-red violation, and we assume the previous grandparent node of z (7) as z. At this point, the uncle of z – y would be node 14. To fix this red-red violation, we perform a left-rotate on parent of the node z (transition b-c). At this point we assume that the previous parent of z as z (node 2) and its uncle y is 14. The node 7 is still red, and we have the red-red violation. To fix it, we have to recolor parent of z to black, recolor grandparent of z to red and perform a right rotation on grandparent (transition c-b). At this point, since the parent element of z is black, we can be sure that the tree is balanced. "},{"title":"2. Insertion Sort","type":0,"sectionRef":"#","url":"docs/algorithms-and-data-structures-part-2/insertion_sort","content":"","keywords":""},{"title":"2.1 Asymptotic Notation​","type":1,"pageTitle":"2. Insertion Sort","url":"docs/algorithms-and-data-structures-part-2/insertion_sort#21-asymptotic-notation","content":"Consider what theta is. We found our worst case 𝜃(n2). For a given function g(n) - that is, for our algorithm. We denote 𝜃(g(n)) as the set of the following functions when there is a set of positive constants C and n0 such that the inequality holds for every n greater than zero. Theta is an accurate estimate (it must be bounded at both the top and bottom). For example, an algorithm requiring Ω(nlogn) requires at least nlogn time, but the upper bound is not known. An algorithm requiring Θ(nlogn) is preferable because it requires at least nlogn(Ω(nlogn)) and at most nlogn(O(nlogn)). For a given function g(n) we denote by θ(g(n)) the set of functions: θ(g(n)) = { f(n): there exist positive constants c1, c2 and n0 such that 0 ≤ c1g(n) ≤ f(n) ≤ c2g(n) for all n ≥ n0 } Figure 2.2  Theta notation is asymptotically tied to top and bottom functions, that is, it keeps it in a narrower framework. If we only have an upper bound, we use big O notation. For the functions g(n), a positive constant must be satisfied and the inequality holds for each n greater than 0. O large is most useful because it represents the worst case. For a given function g(n) we denote by θ(g(n)) the set of functions: Ω(g(n)) = { f(n): there exist positive constants c, and n0 such that 0 ≤ cg(n) ≤ f(n) for all n ≥ n0 } Figure 2.3  Omega notation. If big O is notation for the upper bound, then omega is for the lower one. It is defined in a similar way to big O, but we restrict the function from below. That is, we show the best implementation, for example, an already sorted collection in the input. Figure 2.4  After that, you can already analyze your code, put down the execution time, etc. We've covered insertionSort using an incremental approach, i.e. each time we took the next element and considered for each sorted array. We remember that the quadratic option is not the best and let's see what else we can use. "},{"title":"5. Interface","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-1/interface","content":"","keywords":""},{"title":"5.1 When Should a Class Implement an Interface?​","type":1,"pageTitle":"5. Interface","url":"docs/building-blocks-of-oop-part-1/interface#51-when-should-a-class-implement-an-interface","content":"Class implements Strategy pattern, or it is part of family of objects: IRepository, IFormatter, IPrecondition.Class implements role interface (as a result of ISP): ICloneable, IComparable, etc.Class implements interface required for connection with other classes. Class is an Adapter, the need for an interface is determined by DIP;Class implements interface, because external environment depends on it. Provides testability to users of this class. This is not a single reason to create an interface. "},{"title":"5.2 When Should a Class Depend on an Interface?​","type":1,"pageTitle":"5. Interface","url":"docs/building-blocks-of-oop-part-1/interface#52-when-should-a-class-depend-on-an-interface","content":"When should a class depend on an interface? For example, getting it through the constructor. The arguments of the class indicate that he cannot take some decision on his own, and he needs help from the called class. It's easiest when a class depends on primitives, a little more complicated when it depends on specific classes, and most difficult when it depends on an interface. Class deals with family of types: the &quot;family of types&quot; exists already and defined by requirements of existing model.As a result of DIP: class wants to communicate with object of another level, it defines the interface by itself and requires its implementation.For testing purposes: useful in case if implementation of the abstraction relies on external environment. caution Don't create interfaces &quot;Just in case&quot;! Figure 5.2 - Simple sequence diagram Figure 5.3 - Moe talks to Trip and Bicycle  Each route is rated according to its difficulty. Mountain bike rides have an additional difficulty rating. Clients have a certain level of fitness and technical skill level for mountain biking, based on this we can determine if the requested ride is suitable for them. Customers can rent bicycles, or they can bring their own. Should the Trip class be responsible for figuring out if there is a suitable bike for each given trip? Or more generally &quot;Should the recipient of this message (Trip) be responsible for responding to this message?&quot; The Trip class will respond to the suitable_trips message, and the Bicycle class will respond to the suitable_bicycle message. The customer can get the result if it communicates with 2 objects. Asking for &quot;What&quot; Instead of Telling &quot;How&quot;. Figure 5.4 - Trip tells a Mechanic how to prepare each Bicycle Figure 5.5 - Trip asks a Mechanic to prepare each Bicycle  1st diagram: the Trip is almost ready, and it needs to make sure that all the bicycles that will be participating in it are ready for it. Thus, the Trip must know exactly how to prepare the bike and what messages and in what sequence to send to the Mechanic. Trip each every bike, it washes it, fixes it and gives it away for a ride. The downside is that the Trip needs to know this whole big Mechanic interface, and secondly, if the mechanic starts implementing new behavior, we will need to update the Trip class. In the 2nd diagram, Trip asks the Mechanic to prepare each bike, leaving the implementation details to the Mechanic. This refactoring greatly improves support and extensibility. But this is not an ideal solution yet, because Trip knows about bicycles as well as about mechanics, perhaps in the future this interface can also be reduced. Using Messages to Discover Objects Figure 5.6 - Moe asks the TripFinder for a suitable trip  This diagram is already based on refactoring. We have created the TripFinder class, which aggregates the Trip class and the Bicycle class in itself, it refers to the Trip class and says - tell us what are the available trips and for each available trip checks the required bike, and the user returns the list of available trips. At this stage, TripFinder implements the logic of working with our internal systems. "},{"title":"5.3 Interface vs Abstract Class​","type":1,"pageTitle":"5. Interface","url":"docs/building-blocks-of-oop-part-1/interface#53-interface-vs-abstract-class","content":"Parameters\tInterface\tAbstract classMultiple inheritances\tImplement several interfaces\tOnly one abstract class Structure\tAbstract methods\tAbstract &amp; concrete methods When to use\tFuture enhancements\tTo avoid independence Adding new methods\tCould be hard\tEasy to do Access modifiers\tOnly public\tPublic, protected, private Usage\tDefines the peripheral abilities of a class\tDefines the identity of a class An interface is more flexible from a client's point of view: any class can implement any interface. But the interface is &quot;stiffer&quot; from the point of view of its developer: it is more difficult to change it (the work of all clients will be broken), restrictions cannot be imposed on the client's constructor, and the code cannot be reused. Important Reasons For Using Interfaces: Interfaces are used to achieve abstraction.Designed to support dynamic method resolution at run timeIt helps you to achieve loose coupling.Allows you to separate the definition of a method from the inheritance hierarchy An abstract class is &quot;stiffer&quot; from the clients' point of view: the client will be forced to abandon the current base class. But an abstract class is &quot;more flexible&quot; from the point of view of its developer: it allows you to reuse code, restrict the constructor of descendants, allow you to make changes (easily add a virtual method without breaking existing clients), and more clearly define a &quot;contract&quot; with descendants using Template Methods. Important Reasons For Using Abstract Class: Abstract classes offer default functionality for the subclasses.Provides a template for future specific classesHelps you to define a common interface for its subclassesAbstract class allows code reusability. "},{"title":"5.4 Summary: Creating a Message-Based Application​","type":1,"pageTitle":"5. Interface","url":"docs/building-blocks-of-oop-part-1/interface#54-summary-creating-a-message-based-application","content":"Create Explicit Interfaces - every time you create a class, declare its interfaces. Methods in the public interface should: Be explicitly identified as such.Be more about what than how.Have names that, insofar as you can anticipate, will not change. Honor the Public Interfaces of Others - do your best to interact with other classes using only their public interfaces.Exercise Caution When Depending on Private Interfaces - despite your best efforts, you may find that you must depend on a private interface, this is a dangerous dependency that should be isolated.Minimize Context - construct public interfaces with an eye toward minimizing the context they require from others. Keep the what versus how distinction in mind; create public methods that allow senders to get what they want without knowing how your class implements its behavior. "},{"title":"7. 📚 Home Task","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-1/hometask","content":"","keywords":""},{"title":"Specific Steps​","type":1,"pageTitle":"7. 📚 Home Task","url":"docs/building-blocks-of-oop-part-1/hometask#specific-steps","content":"Create a Point class, which creates 2 dimensional point with coordinates. It should contain: two instance variables x and y;default constructor which creates a point at the location of (0, 0);overloaded constructor (use multiple constructors declaration for Typescript) which creates a point by x and y coordinates;toString() method should return a Point class stringified representation in format: &quot;(x, y)&quot;;distance() method should be overloaded (use multiple methods declaration for Typescript) with next implementations: no args: distance from this point to (0, 0);distance(other: Point) - distance from this point to a given instance ofPoint;distance(x, y) - distance from this point to a given point (x, y). Create abstract superclass called Shape, which contains: two protected instance variables: color (string), filled(boolean) and points (Point[]);overloaded constructor (use multiple constructors declaration for Typescript): a constructor that takes a list of points and initializes the color to &quot;green&quot;and filled to true by default, and a constructor that takes a list of points, the color and filled properties;Make sure that the Shape has at least 3 points (2 points is just a line).toString() method that returns &quot;A Shape with color of xxx and filled/Not filled. Points: (x1, y1), (x2, y2)...&quot;;getPerimeter() that calculates the perimeter using Point.distance method; Create class Triangle that takes 3 points as it's vertices. Triangle must inheritShape abstract class. Triangle should contain: a constructor (use multiple constructors declaration for Typescript) which createsTriangle class using three instances of Point class, may also provide color and filled properties;override toString() method, it should return a Triangle class stringified representation in format &quot;Triangle[v1=(x1, y1),v2=(x2, y2),v3=(x3, y3)]&quot;;override getType() method, which prints &quot;equilateral triangle&quot; if all the three sides are equal, &quot;isosceles triangle&quot; if any two of the three sides are equal, or&quot;scalene triangle&quot; if all sides are different. "},{"title":"Evaluation criteria​","type":1,"pageTitle":"7. 📚 Home Task","url":"docs/building-blocks-of-oop-part-1/hometask#evaluation-criteria","content":"Only some classes were implemented.Some classes were not implemented.Some required methods are missing.All tasks are implemented to a full extend. "},{"title":"6. Object-oriented Design Introduction","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-1/object-oriented_design_introduction","content":"","keywords":""},{"title":"6.1 Design Smells​","type":1,"pageTitle":"6. Object-oriented Design Introduction","url":"docs/building-blocks-of-oop-part-1/object-oriented_design_introduction#61-design-smells","content":"Let us look at the criteria for the so-called bad design or the so-called bad design smells, as there are code smells, there are also bad design smells: RigidityFragilityImmobilityViscosityNeedless Complexity Rigidity indicates that a system is rigid if it is difficult to change it, or even a small change will entail high costs. This suggests that the system is no longer flexible and extensible. Fragility indicates that a system is fragile if a change in some part breaks something in another part, while the part in which something breaks is not connected in any way and does not explicitly depend on the part in which something has changed. Immobility means that a system is immobile if certain parts of it cannot be separated into separate components or into separate modules and reused in another part of this system, and in the best cases, in other systems in general. But this, of course, is even harder. Viscosity. The system is viscous if basic operations are difficult or take too long to complete. So, they are simply ignored. An example of such operations that are difficult to modify and take a long time are slow tests. If they are hard to run, if they are hard to write, if they are slow to execute, then most likely no one will support them, no one will write them, no one will run them. Needless Complexity or premature optimization - indicates that the system is unnecessarily complicated or prematurely optimized, has too much code that is not currently used, but was written with the intention that it may be needed in the future if the customer wants what -that functionality, it seems as we prepared for this. In fact, this generates dead code, that is, the code that is not used, first for days, then months, years, and then everyone forgets who wrote it, why it was written, and are simply afraid to delete it, because, it may be used somewhere, but nobody knows where. In general, the main reason for all the listed bad design smells is the lack of flexibility in the system. The system must be flexible, or, as per saying: software must be soft that is, it must be easy to change. And that is why we need a good design. "},{"title":"6.2 What is Design?​","type":1,"pageTitle":"6. Object-oriented Design Introduction","url":"docs/building-blocks-of-oop-part-1/object-oriented_design_introduction#62-what-is-design","content":"Figure 6.1 – Lifecycle of a construction project  Let us imagine the process of creating something. It will have three phases: the actual design phase; the process of creation or construction and the final product. Let us take construction industry as an example. What will be a design? - Well, obviously a drawing or blueprint. What will the creation process be? - In our case, this will be the construction process in accordance with the ready-made blueprint. And what the final product will be - a house or a building. As you can see from the diagram, the creation or building process is much bigger than the design process, it is longer and more expensive. That is why there is a need for the blueprint to be well developed at the planning stage, because during the construction process, each change will be too expensive and complicated, and the cost of an error will be too high. Figure 6.2 – Lifecycle of a software development project  Now let us apply this constructing analogy to the architecture of a software system, just in reverse order. What will be the final product? – An application that solves some specific problems in its domain area. What will be the creation process? – The process of interpreting or compiling source code. And the design process, oddly enough, is the source code itself. So, in fact, neither diagrams, nor the relationships between them, nor drawings, and so on - they are not design, they help us structure, organize our thoughts into a specific approach and implement it in the form of source code. In this case, the design phase is much longer and more expensive than the creation phase. That is why the design phase should be iterative, gradual, with constant feedback from both the product and the client. In general, this is the main difference between software and, for example, construction. In software, we have one unbreakable constant that will never change throughout the entire time of our development - these are changes, there have always been changes, they will always occur. And this is the reason why we need design as an ongoing interactive process. "},{"title":"6.3 Why Change is Hard and the Problem Design Solves​","type":1,"pageTitle":"6. Object-oriented Design Introduction","url":"docs/building-blocks-of-oop-part-1/object-oriented_design_introduction#63-why-change-is-hard-and-the-problem-design-solves","content":"Object-oriented application is made of parts – objectsInteractions are embodied in the messages that pass between the objectsSender object – Target object creates dependencies between the twoObject-oriented design is about managing dependencies Requirements, product, ecosystem, environment, customer ¬ all this will change. The system needs a design that is ready for such changes. Such design would consist of certain parts that would interact with each other to create the behavior of something whole: a class, a component, an architectural layer, or an application. As you understand parts are objects, interactions between them are implemented using messages that are sent between these objects. At the same time, sending the correct message to the correct recipient-object requires knowledge of where this object is and how to interact with it. This knowledge creates a relationship between two or three objects, or generally a huge number of objects in the system. Cross dependencies, cycle-dependency and so on arise. Accordingly, all these dependencies complicate system change. Object-oriented design is essentially dependency management. In the absence of design, unmanaged dependencies lead to chaos, because objects begin to know too much about each other, and at some point, it is easier to throw everything out and rewrite entire application than to add some next changes. Since these dependencies just become unmanageable. By changing something in one place, even if there are some tests, we do not exclude the possibility that something will not break in another place. "},{"title":"6.4 The Purpose oF OOD​","type":1,"pageTitle":"6. Object-oriented Design Introduction","url":"docs/building-blocks-of-oop-part-1/object-oriented_design_introduction#64-the-purpose-of-ood","content":"Software must: Satisfy customer's needsBe flexible for change and enhancement Thus, the goal of object-oriented design is just two things. The first is, of course, to satisfy the needs of the customer, and the second is to be easy to change and be adaptable and ready for such changes and extensions. "},{"title":"6.5 The Tools of Design​","type":1,"pageTitle":"6. Object-oriented Design Introduction","url":"docs/building-blocks-of-oop-part-1/object-oriented_design_introduction#65-the-tools-of-design","content":"Design Principles: SOLID, DRY, KISSDesign Patterns: Creational, Behavioral, StructuralOOP Principles: Abstraction, Encapsulation, Polymorphism, Inheritance In fact, there are a lot of approaches and tools, for example, these are the very principles of object-oriented programming: abstraction, encapsulation, etc., which were mentioned at the very beginning of the manual, they are basic, theoretical, but they fit perfectly into the practice of writing code, in the system design and are an essential tool in the fighting complexity, that is, a tool in the creation of object-oriented design. Also, such tools as design patterns: Solid, Dry, Kiss. We will consider all these principles and tools in subsequent lectures. "},{"title":"1. Programming Paradigm","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-1/programming_paradigm","content":"","keywords":""},{"title":"1.1 Declarative Programming​","type":1,"pageTitle":"1. Programming Paradigm","url":"docs/building-blocks-of-oop-part-1/programming_paradigm#11-declarative-programming","content":"In declarative programming, the programmer instructs the computer on what is to be computed.You do not know how it works, but you know what it does.It is a very good idea to decouple DOM manipulation from app logic. This improves the testability of code.Improves readability of a code First programming paradigm we are going to talk about is Declarative Programming. In this paradigm we must define the specification for solving a task, i.e., we describe what the problem's field and how what kind of result we expect. The order of execution and the method of achieving results does not matter. A common example of declarative programming is HTML. It describes the contents of the page, but not the way it should be rendered. Listing 1.1 - Example of declarative code select upper(name) from people where length(name) &gt; 5 order by name  On the example above, you can see an SQL query. It is also an example of declarative programming. Here, we describe the context of the problem, a list of people and what we want to get from that list: a list of names, uppercased, where the length of the name is larger than 5. The list of names should be ordered in ascending order. We do not care what type of database we are using. We do not describe how to retrieve the data or how to go through each entry of people list. Whether the application should use quick sort or merge sort. It is all up for the application or interpreter to decide. "},{"title":"1.2 Imperative Programming​","type":1,"pageTitle":"1. Programming Paradigm","url":"docs/building-blocks-of-oop-part-1/programming_paradigm#12-imperative-programming","content":"The script is basically telling the computer how to do something.Imperative phrases which change the global state of a program&quot;Not scalable With imperative programming, we describe the system as a process of execution of instructions that change the state of the system. It is commonly considered to be less extensible than the others. Examples of languages with imperative programming support are C++, C, Go, JavaScript. You should always remember that you cannot always categorize a certain language to a single programming paradigm. Usually, the languages support 2 or even 3 paradigms at the same time. For example, JavaScript supports imperative, functional, and object-oriented paradigms at the same time. Listing 1.2 - Example of imperative code result = [] i = 0 start: numPeople = length(people) if i &gt;= numPeople goto finished p = people[i] nameLength = length(p.name) if nameLength &lt;= 5 goto nextOne upperName = toUpper(p.name) addToList(result, upperName) nextOne: i = i + 1 goto start finished: return sort(result)  Above you can see an example of code written in imperative style. We precisely describe the sequence of actions to achieve the desired result. To get the expected result we must know how to achieve it. We know exactly in which order should those instructions be arranged in. Opposite to the previous example from declarative programming, here you can see that we have variables with state. One variable has an Integer type, the other is an array. To achieve the result, we must add conditions, loops, gotos. With imperative programming you know exactly what is happening. You can dial into the execution of a program and easily debug it. While with declarative, the exact path of a program is not deterministic from the perspective of executed code. Both approaches have their place in a programming with their strengths and weaknesses. It is also worth mentioning that all code is imperative in the end, when it is executed by the processor. "},{"title":"1.3 Object-Oriented Programming​","type":1,"pageTitle":"1. Programming Paradigm","url":"docs/building-blocks-of-oop-part-1/programming_paradigm#13-object-oriented-programming","content":"Program is defined by object which combine state and behaviorGood for structured and modular codeWell suited for big projects Object-oriented paradigm describes the computer program as a set of specific objects, that are instances of a class. The objects communicate by sending, receiving, and processing the messages. The messages may include parameters. The objects have state, which they can change when processing a message. Objects may create other objects or may send messages when processing a message. It is safe to say that object-oriented paradigm is well-suited for big projects that require having a state within the application. It is message-oriented approach provides a way for objects to be replaced by other objects of a same type. This means that the behavior of a program can be changed just by replacing an object. Also, same objects as building blocks could be reused in other parts of the same system. Listing 1.3 - Example of OOP code  "},{"title":"1.4 Functional Programming​","type":1,"pageTitle":"1. Programming Paradigm","url":"docs/building-blocks-of-oop-part-1/programming_paradigm#14-functional-programming","content":"Treats computations as the evaluation of functions and avoids changing state and mutable dataEliminating side effects, i.e., changes in state that do not depend on the function inputs, can make it much easier to understand and predict the behavior of a programEmphasize using of immutable data Last, but not least, Functional paradigm describes the program as a set of functions (not objects or procedures) that are used as building blocks to manipulate data. It forces us to use function in their mathematical sense, as they just declare a relationship between two entities. Functions do not change the state of a program (also known as pure), they simply pipe the data through them to produce a result. There are no variables, only constants. Listing 1.4 - Example of FP code  In the example we have a certain nesting of certain functions, where the result of the function can be expressed as a list of arguments that are passed to this function. However, arguments can also be functions. By the way, not all programming languages can pass a function as a parameter to another function, this is the so-called first-class citizen function. JavaScript has this capability, that is why it has some concepts of functional programming. A program in functional programming is not represented by a specific state, but by a combination of function calls at a certain point in time. Functional programming pushes us towards the idea that it would be nice to use immutable data. Since immutable data is faster, because we put them into memory once, and they do not change. There are disadvantages and advantages to this, but this is how it works in functional programming. There are so-called pure functions in functional programming, that is, functions without side effects. When you have a list of parameters as function arguments, a certain logic for handling them and a certain result in return. The function does not change data and state outside its scope. In fact, if you change a variable outside the scope of the function, this already indicates that the function is impure, that is, it has a side effect. This is neither bad nor good, these are just different approaches. Functional programming assumes that the functions are just pure and should follow the principle of single responsibility, that is, each function should have single responsibility. Because the essence of functional programming is in the combination of various functions with different responsibilities to achieve the result. "},{"title":"2. Duck Typing","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-2/duck_typing","content":"","keywords":""},{"title":"2.1 If It Walks Like a Duck and Talks Like a Duck Then It's a Duck​","type":1,"pageTitle":"2. Duck Typing","url":"docs/building-blocks-of-oop-part-2/duck_typing#21-if-it-walks-like-a-duck-and-talks-like-a-duck-then-its-a-duck","content":"To better understand the meaning of this phrase let us analyze it using one of previous examples based on the UML-diagram below: Figure 2.1 - Trip – Mechanic interaction  In this example, Trip class earlier had to do few calls of Mechanic class method, now those calls are combined into single prepareBicycles method call, as you can see on Figure 2.1. But if we will need to prepare something besides bicycles, then our code may look like on example below: Listing 2.1 class Mechanic {} class TripCoordinator {} class Driver {} class Trip { bicycles; customers; vehicle; prepare(prepares: object[]) { return prepares.map((preparer) =&gt; { switch (preparer.constructor) { case Mechanic: return preparer.prepareBicycles(this.bicycles); case TripCoordinator: return preparer.buyFood(this.customers); case Driver: preparer.fillTank(this.vehicle); return preparer.fillWaterTank(this.vehicle); } }); } }  When introducing new preparers in addition to Mechanic, like TripCoordinator and Driver you will notice how dramatically increased the number of dependencies in prepare method. Now it knows every class name, classes' methods' names and their arguments because it needs to prepare some specific things before the trip. What is even worse, is the fact that this type of code only will increase its size and dependencies number with time, it is the easiest way for developer to add another switch case to already existing cases. "},{"title":"2.2 Finding the Duck​","type":1,"pageTitle":"2. Duck Typing","url":"docs/building-blocks-of-oop-part-2/duck_typing#22-finding-the-duck","content":"We have identified the problem which we need to solve, and now we need to minimize dependencies number to make Trip functionality easily extensible without usage of switch-case operator and other similar approaches. Analyzing existing functionality, we may notice something common between all the preparers, something, that each of them does, but at the same time what they are not. To understand what the instance is we are talking about, let us look on the UML-diagram on Figure 2.2: Figure 2.2 - Missing Preparer type  Every preparer class is responsible for preparing something for the Trip, so we can try to extract some Preparer abstraction and call it a duck type. As a result we have something similar to an interface, but actually it is just a role which can be applied to some specific class in some specific moment of time, and we cannot say that every Preparer class is a part of some types' hierarchy. This is the exact moment when we can extract our duck types, the next step is to review changes in code, which is required to extract the duck type. Our refactoring will be based on the UML-diagram from Figure 2.3: Figure 2.3 - Trip – Preparer interaction  When we finish the refactoring, every Preparer will have prepareTrip method which takes Trip instance as an argument so every preparer can take needed data from the instance. Below you can see the refactoring result: Listing 2.2 class Trip { prepare(prepares: { prepareTrip(trip: Trip) }[]) { prepares.map((preparer) =&gt; { preparer.prepareTrip(this); }); } } class Driver {} class Mechanic { prepareTrip(trip: Trip) { trip.bicycles.map((bicycle) =&gt; { this.prepareBicycle(bicycle); }); } } class TripCoordinator { prepareTrip(trip: Trip) { this.buyFood(trip); } }  Trip class changed the most, we have removed all the dependencies on specific implementations of other classes, now every Preparer only need to have prepareTrip method so Trip class will not change anymore with addition of new preparers. "},{"title":"2.3 Writing Code that Relies on Ducks​","type":1,"pageTitle":"2. Duck Typing","url":"docs/building-blocks-of-oop-part-2/duck_typing#23-writing-code-that-relies-on-ducks","content":"To sum up the information about duck types we will try to make a list of main points which helps us to write a code using duck types. Recognizing Hidden Ducks. You need to timely understand where the duck types are hidden and how to extract them, pay attention to the next places in the code: Case statements that switch on class.instanceof operator.Checking the method exists (if (obj.someMethod) { obj.someMethod() }); Placing Trust in Your Ducks. Let client code trust the duck type, in lack of the trust client code means the next: &quot;I know who you are, so I know what you do&quot;. Such knowledge transforms into tight coupling between classes which results into non extensible code. Flexible applications built on top of objects which works on trust – your goal as a developer is to make those objects reliable, to let the trust work.Documenting Duck Types. Preparer duck type and its open interface is a specific part of the design, but at the same time it is a virtual part of code, because it is neither a class nor a real interface. Preparers are an abstraction, just a convention which gives you the powerful system design tool, but this abstraction makes code less obvious. When you create a duck type, you must document and cover it with tests.Sharing Code between Ducks. In our example shared is only prepareTrip method, but when you start using duck types, you may notice that some part of the functionality is common for all the types. Share such functionality using mixins and other available approaches.Choosing Your Ducks Wisely. The last point, as always, tells us that you do not need to create duck types just to have them. You need to find a balance between resources required for the refactoring, benefit gained, support simplicity and code clarity. "},{"title":"6. 📚 Home Task","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-2/hometask","content":"","keywords":""},{"title":"Specific Steps​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/building-blocks-of-oop-part-2/hometask#specific-steps","content":"The Item class is the common ancestor to the various types of items that can exist in this fantasy game. All instances of Item are given a unique number id. These are to be assigned by the Item constructor. The first instance of an item is assigned an id of 0 (zero); the next is assigned 1, etc. Note that you have available a class variable that will help with the implementation of the constructor (and there is a static reset() method). compareTo(other: Item): The Item class implements the Comparable interface. This requires adding the compareTo(other: Item) method to the class. The compareTo(other: Item) method takes in another instance of Item and compares it to the current instance. If the current instance's value field is greater than other's value field then the method should return a positive integer (convention is 1). If the current instance's value field is less than other's value field then the method should return a negative integer (convention is -1). If both items are equal, then compare the name field of the items lexicographically (meaning, compare each character in the strings based on its value, ignoring case. i.e. A == a), returning the appropriate value. Item.toString(): for an Item with the name of &quot;ring&quot;, a value of 3000, and a weight of 0.013, the method must return a string in the following format (excluding the quotes): &quot;ring − Value: 3000, Weight: 0.01&quot;  The ItemWeightComparator class implements the ItemComparator interface, meaning instances of it can be passed to methods requiring a comparator for objects of type Item. The compare(first: Item, second: Item) method of ItemWeightComparator should function similarly to the compareTo(other: Item) method of the Item class, but for the weight field of the Items. If the weights are equal, this method should call the compareTo(other: Item) method of the first Item and return the resulting value. The Weapon class is an abstract implementation of Item and describes items that can deal damage and break from use. All instances of Weapon have a base damage value baseDamage and a modifier to that value damageModifier. The sum of these two values determines the effective damage that this Weapon can do on a single use. In addition, Weapons have a base durability value baseDurability, and a modifier to that value durabilityModifier. The sum of these two values determines the effective durability of the Weapon. When this sum reaches zero or less, the effective durability is zero and the Weapon is considered to be broken and cannot be used. You need to implement the next methods: Weapon.getDamage(): Returns the effective Weapon damage. Weapon.getDurability(): Returns the effective durability of the Weapon. Weapon.toString(): for a Weapon with the name of &quot;hammer&quot;, a value of 300, a weight of 2.032, a baseDamage value of 30.4219, a damageModifier of 0.05, a baseDurability of 0.7893, and a durabilityModifier of 0.05, the method returns a string in the following format: &quot;hammer − Value: 300, Weight: 2.03, Damage: 30.47, Durability: 83.93%&quot; Weapon.use(): This method returns a string describing what happens when a Weapon is used. For a Weapon with the name of &quot;hammer&quot;, and an effective damage of 30.4725, the method should return the following: &quot;You use the hammer, dealing 30.47 points of damage.&quot; &quot;Using&quot; a Weapon lowers (subtracts) its effective durability by Weapon.MODIFIER_CHANGE_RATE. If the effective durability of the Weapon hits or drops below 0, the Weapon will &quot;break&quot;. If the Weapon &quot;breaks&quot;, the method should output the previous string, but additionally with a newline character and the additional text &quot;The hammer breaks.&quot;: &quot;You use the hammer, dealing 34.05 points of damage. The hammer breaks.&quot; For a Weapon with the name of &quot;hammer&quot;, if it is &quot;broken&quot; (The effective durability is 0 or less), calling its use() method returns the following: &quot;You can't use the hammer, it is broken.&quot;  In this case, there is no change to durabilityModifier. The Sword class is a concrete implementation of Weapon that you must provide. All instances of the Sword class have the name &quot;sword&quot;.Sword.polish(): This method increases the instance's damageModifier by adding Weapon.MODIFIER_CHANGE_RATE each time polish() is called, up to 25% of the baseDamage value. If the base damage of a sword were to be 100, then the maximum that the effective damage could be increased to would be 125. The Bow class is a concrete implementation of Weapon that you must provide. All instances of the Bow class have the name &quot;bow&quot;.Bow.polish(): This method increases the instance's durabilityModifier by adding Weapon.MODIFIER_CHANGE_RATE. Any changes are capped such that effective durability is no larger than one (1). The Inventory class is a container for items in this fantasy game. You need to add the following methods: Inventory.sort(): This sorts the items in the Inventory instance based on their value.Inventory.sort(comparator: ItemComparator): This sorts the items in the Inventory instance based on their weight.Inventory.toString(): returns string representation of the item list (.join(', ')). The Consumable class describes those items that can be eaten by the player. Consumables can be marked as consumed, and can be spoiled. These properties are stored in the instance variables consumed and spoiled, respectively. A newly-created Consumable object should have its consumed field set to false. Consumable.use(): If a Consumable is not spoiled and is not consumed, calling this simply returns the value from a call to Consumable.eat(). For a Consumable with the name of &quot;bread&quot; that has already been consumed, this method returns the following: &quot;There is nothing left of the bread to consume.&quot;  Assuming for this Consumable named &quot;bread&quot; that the value returned by a call to its eat() method is the following: &quot;You eat the bread.&quot;  If this &quot;bread&quot; were to be spoiled, the method returns this string, appended with a newline and the text &quot;You feel sick.&quot;: &quot;You eat the bread. You feel sick.&quot;  "},{"title":"Specific instructions​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/building-blocks-of-oop-part-2/hometask#specific-instructions","content":"Start from creating Item, Consumable, and Inventory classes.Create the Sword, Bow and ItemWeightComparator classes "},{"title":"Implementation details​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/building-blocks-of-oop-part-2/hometask#implementation-details","content":"both int/float types in the UML diagram represents &quot;number&quot; type in Typescript;Item class: numberOfItems is static getter property which returns counter (keep it outside class declaration and increment every time class constructor is executed)reset() method should assign 0 to the countercompareTo(other: Item) - see description above Consumable class: consumed is false when create new instance Inventory class: items - Item[]sort() method is polymorphic and has 2 declarations: sort() and sort(comparator: ItemComparator) Weapon class: don't forget to use super in constructor (note that parent classes can require extra fields, such as name) Pizza class: example of eat() method: "},{"title":"Evaluation criteria​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/building-blocks-of-oop-part-2/hometask#evaluation-criteria","content":"Only some classes were implemented.Some classes were not implemented.Some required methods are missing.All tasks are implemented to a full extend. "},{"title":"Software Designs and Algorithms: Contents","type":0,"sectionRef":"#","url":"docs/contents","content":"Software Designs and Algorithms: Contents Building Blocks of OOP, Part 1Building Blocks of OOP, Part 2Functional ProgrammingDesign PatternsSOLID PrinciplesAlgorithms and Data Structures, Part 1Algorithms and Data Structures, Part 2","keywords":""},{"title":"4. Inheritance in Details","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-1/inheritance_in_details","content":"","keywords":""},{"title":"4.1 Intro​","type":1,"pageTitle":"4. Inheritance in Details","url":"docs/building-blocks-of-oop-part-1/inheritance_in_details#41-intro","content":"JavaScript is a bit confusing for developers experienced in class-based languages (like Java or C++), as it is dynamic and does not provide a class implementation per se (the class keyword is introduced in ES2015, but is syntactical sugar, JavaScript remains prototype-based). When it comes to inheritance, JavaScript only has one construct: objects. Each object has a private property which holds a link to another object called its prototype. That prototype object has a prototype of its own, and so on until an object is reached with null as its prototype. By definition, null has no prototype, and acts as the final link in this prototype chain. Nearly all objects in JavaScript are instances of Object which sits on the top of a prototype chain. While this confusion is often considered to be one of JavaScript's weaknesses, the prototypal inheritance model itself is, in fact, more powerful than the classic model. It is, for example, fairly trivial to build a classic model on top of a prototypal model. Inheritance mechanisms, which play a key role in the object approach in terms of extensibility and reuse, model the relationship (IS-A relationship) and exploit the relationship between the base class and its descendant. info Inheritance is the mechanism of basing an object or class upon another object (prototypical inheritance) or class (class-based inheritance), retaining similar implementation. info In most class-based object-oriented languages, an object created through inheritance (a &quot;child object&quot;) acquires all the properties and behaviors of the parent object Experienced developers can tell you that overuse of inheritance leads to code that is difficult to understand and maintain. This is primarily because the IS-A relationship is much stronger than the relationship that appears during composition. Therefore, when making changes, you need to be very careful and see if any methods have been overridden, what is the contract of the parent class, at the level of coupling. Inheritance is essentially an automatic message delegation mechanism. Inheritance creates a relationship in which if one object cannot respond to a received message, it passes that message to another. And this transfer happens automatically. "},{"title":"4.2 Recognizing Where to Use Inheritance​","type":1,"pageTitle":"4. Inheritance in Details","url":"docs/building-blocks-of-oop-part-1/inheritance_in_details#42-recognizing-where-to-use-inheritance","content":"Let's look at an example where inheritance can be applied. Let's imagine that we want to rent a bike. Listing 4.1 class Bicycle { constructor(options) { this.size = options.size; this.tapeColor = options.tapeColor; }; spares() { return { chain: '11-speed', tireSize: '28', tapeColor: this.tapeColor, }; }; } const bike = new Bicycle({size: 'M', tapeColor: 'red'}); bike.size; // =&gt; 'M' bike.spares(); // =&gt; {chain: '11-speed', tireSize: '28', tapeColor: 'red'}  And we need to know what parts need to be replaced in case of a breakdown, so we added spares method. But what happens if we add another bike style? For example, a mountain bike. Now our method looks a little strange. Listing 4.2 class Bicycle { constructor(options) { // previous options this.style = options.style; this.frontShock = options.frontShock; }; spares() { if (this.style === 'road') { return { chain: '11-speed', tireSize: '28', tapeColor: this.tapeColor, }; } return { chain: '11-speed', tireSize: '29', frontShock: this.frontShock, }; }; } const crossCountryBike = new Bicycle({style: 'XC', size: 'M', frontShock: 'mountain'}); const roadBike = new Bicycle({style: 'road', size: 'M', tapeColor: 'red'});  We added 2 new arguments for MountainBike. The new style property defines what the spares method (details) will return using the if statement inside the method. Already this code is hard to maintain, and if we need to add another type of bicycles, our code will turn into a big dump. It's time for an Abstract class. Figure 1.1 – Abstract class  Subclasses are specializations of their superclasses. MountainBike should have everything a Bicycle plus something else. The picture above shows a class diagram where Bicycle is a superclass for MountainBike and RoadBike. The Bicycle will contain general behavior, and MountainBike and RoadBike will add specializations. The public interface of the Bicycle should include a spares method and a size property, and the interfaces of its subclasses will add the necessary parts. The Bicycle is now an abstract class. "},{"title":"4.3 Creating an Abstract Superclass with Shared Abstract Behavior​","type":1,"pageTitle":"4. Inheritance in Details","url":"docs/building-blocks-of-oop-part-1/inheritance_in_details#43-creating-an-abstract-superclass-with-shared-abstract-behavior","content":"Listing 4.3 abstract class Bicycle { // keep only common parts } class RoadBike extends Bicycle { constructor(options) { super(options); this.tapeColor = options.tapeColor; }; spares() { return { ...super.spares(), tapeColor: this.tapeColor, }; }; } class MountainBike extends Bicycle { constructor(options) { super(options); this.frontShock = options.frontShock; }; spares() { return { ...super.spares(), frontShock: this.frontShock, }; }; }  Abstract classes exist in order to inherit from them. They provide a common repository that stores the behavior common to all subclasses, and each of them is a specialization of an abstract class. It almost never makes sense to create an abstract superclass with a single subclass. "},{"title":"4.4 Template Method Pattern: Default Implementation​","type":1,"pageTitle":"4. Inheritance in Details","url":"docs/building-blocks-of-oop-part-1/inheritance_in_details#44-template-method-pattern-default-implementation","content":"This gives subclasses the ability to inject specialization by overriding the default values set in the parent class. This technique of describing the basic structure/algorithm in a superclass and redefining parts of this structure/algorithm to those that are already specific for a particular class is called the template method. Bicycle now provides a structure, a general algorithm, for its subclasses. In those places where the base class provides the ability to influence this algorithm to the derived classes, it sends messages defaultChain and defaultTireSize. Listing 4.4 abstract class Bicycle { protected readonly defaultChain = '11-speed'; constructor(opts) { // ... this.chain = opts.chain || this.defaultChain; this.tireSize = opts.tireSize || this.defaultTireSize; }; } class RoadBike extends Bicycle { protected readonly defaultTireSize = '28'; } class MountainBike extends Bicycle { protected readonly defaultTireSize = '29'; }  Something similar can be found in ReactJs library. When creating a component, it has methods componentDidMount(), shouldComponentUpdate() you can change their implementation yourself. Okay, we split the MountainBike and the RoadBike, but now there are new problems: Mountain bike and road bike classes depend on their abstract class;Abstract class depends on children;If you forget to call super methods – the result might not contain all data required;Users of road and mountain bike depend on the abstract class, even if they don't know anything about it. "},{"title":"4.5 Using Hook Messages: Decoupling Subclasses​","type":1,"pageTitle":"4. Inheritance in Details","url":"docs/building-blocks-of-oop-part-1/inheritance_in_details#45-using-hook-messages-decoupling-subclasses","content":"This strategy removes the knowledge of the algorithm from the subclass and returns control to the superclass. Which was done by adding the postInitialize method. RoadBike and MountainBike no longer control the initialization process, but instead bring specialization to a more abstract algorithm. This algorithm is defined in the abstract superclass Bicycle, which in turn is responsible for sending postInitialize. To achieve this result Bicycle constructor should always be called, this will happen automatically if derived classes will have no constructor. This same technique can be used to remove the dispatch of super in the spares method. Listing 4.5 abstract class Bicycle { constructor(opts) { this.size = opts.size; this.chain = opts.chain; this.tireSize = opts.tireSize; this.postInitialize(opts); }; protected postInitialize() {}; spares() { return { tireSize: this.tireSize, chain: this.chain, ...this.localSpares() }; }; } class RoadBike extends Bicycle { protected postInitialize(opts) { this.tapeColor = opts.tapeColor; }; protected localSpares() { return { tapeColor: this.tapeColor }; }; } class MountainBike extends Bicycle { protected postInitialize(opts) { this.frontShock = opts.frontShock; }; protected localSpares() { return { frontShock: this.frontShock }; }; }  "},{"title":"4.6 Summary​","type":1,"pageTitle":"4. Inheritance in Details","url":"docs/building-blocks-of-oop-part-1/inheritance_in_details#46-summary","content":"Inheritance solves the problem of related types that share a great deal of common behavior but differ across some dimension;The best way to create an abstract superclass is by pushing code up from concrete subclasses;Abstract superclasses use the template method pattern to invite inheritors to supply specializations, and they use hook methods to allow these inheritors to contribute these specializations without being forced to send super;Well-designed inheritance hierarchies are easy to extend with new subclasses, even for programmers who know very little about the application; "},{"title":"4. The Law of Demeter","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-2/the_law_of_demeter","content":"","keywords":""},{"title":"4.1 Avoiding violations​","type":1,"pageTitle":"4. The Law of Demeter","url":"docs/building-blocks-of-oop-part-2/the_law_of_demeter#41-avoiding-violations","content":"One example of how you can avoid unnecessary dependency. We have a User who have Account and this account has a plan and User has discountedPlanPrice which violate the Law of Demeter. Listing 4.2 abstract class User { private account: Account; discountedPlanPrice(coupon: Coupon) { return coupon.discount( this.account.getPlan().getPrice(), ); }; } class Account { private plan: Plan; getPlan() { return this.plan; }; }  One of the common ways to remove such chains is by using delegation. A wrapper method encapsulates or hides knowledge that would otherwise be implemented in the message chain. Listing 4.3 class Account { private plan: Plan; discountedPlanPrice(coupon) { return coupon.discount(this.plan.getPrice()); }; }  To avoid such problems, you need to think over the application architecture in advance. info Delegation is an effective technique to avoid Law of Demeter violations, but only for behavior, not for attributes. "},{"title":"5. Conclusion","type":0,"sectionRef":"#","url":"docs/design-patterns/conclusion","content":"5. Conclusion You may successfully code without having an idea of what patterns are. Moreover, you might have implemented some of them without even noticing. But conscious usage of tool differs is an important step from a beginner level to professional. You may hammer a nail, and you may hit it with a drill as well, if you make enough effort. Professional developer understands, that it's not a purpose of a drill. Software development would be much easier without changes at all. But changes are everywhere: requirements, environment, hardware and so on. The main purpose of software development is creation of systems, that will allow localizing and minimize negative influence of such changes. That is why we should write reusable code with minimal dependency on other parts of the program and use SRP (single responsibility) and OCP (open-closed) principles. That is why we should use abstractions and depend on them rather than on realization details. And also prefer composition over inheritance. Using design patterns, the code, which conducts these approaches and principles, can be achieved much easier. For example, Strategy pattern allows writing code, which is opened for extension, but closed for modification. Observer pattern allows creating loose coupled code and so on.","keywords":""},{"title":"2. Unified Modeling Language","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-1/unified_modeling_language","content":"","keywords":""},{"title":"2.1 What is UML​","type":1,"pageTitle":"2. Unified Modeling Language","url":"docs/building-blocks-of-oop-part-1/unified_modeling_language#21-what-is-uml","content":"UML is a general-purpose, developmental, modeling language in the field of software engineering that is intended to provide a standard way to visualize the design of a system. It is logical to assume that before starting to write code, we need to design our computer system. If the system (program) is small, for example some of your pet-project, then there is no need for visual design, because all the components of this system and their interconnections, in principle, you can keep in your head if you are writing this project alone. As soon as several people appear on the project and information needs to be somehow shared, as soon as the project grows, as soon as the number of components on the project becomes more than ten, you have a certain need for some plan, a representation of your system. There is a language called UML or Unified Modeling Language for describing system components and their interrelationships. In fact, it gives us a list of terms, abstractions, concepts, and tools for high-level modeling of our system. In principle, the UML is to some extent design patterns in the programming world. When I say that in this part of the system, I need to apply a class that has only one instance to share its state between other components of the system - it will take too long, and we all know perfectly well what it is called a singleton. That is, we have some tools, some concepts, in terms of which we can discuss not some low-level details, but higher-level abstractions. The use of UML is not limited to programming, it is also used for modeling business processes, systems design, drawing up the organization structure, and so on. Figure 2.1 - UML diagram of Student class  As you can see on the Figure 2.1, there is nothing complicated in the UML. Here is a diagram of the Student class, where at the top you see the name of the class, below is a list of properties that are inherent in this class, even below its behavior, that is, the methods that this class has. Usually, the system is not limited to just one class, as we have already mentioned, there are tens, hundreds of classes, or even more. Naturally, all these classes somehow interact with each other, somehow communicate, send messages to each other, call each other's methods, send events, and so on. The visual representation of the classes and the relationship between these classes is called class diagrams. There are a lot of relationships, some of the most basic ones are shown in the Figure 2.2. Let us take a closer look at the relationship between the classes. Figure 2.2 – UML Relations  "},{"title":"2.2 Association​","type":1,"pageTitle":"2. Unified Modeling Language","url":"docs/building-blocks-of-oop-part-1/unified_modeling_language#22-association","content":"There are different types of relationship between two classes / objects. The most basic type of relationship is association, which means that the two classes are somehow related to each other, and we do not yet know exactly how this relationship is expressed and are going to clarify it in the future. This usually happens in the early stages of system design, when we know that there is a relationship, but what specific relationship - inheritance, composition, or something else is not yet clear to us. We are designing the system more globally. The association helps us a lot when we indicate that one class in some way interact with another class. At the initial stage, this is enough for us. Further, of course, this will be clarified. Why is this a directional association? – Because the arrow shows us that we have a component that uses another component. In this case the CustomService uses the CustomRepository component, and not vice versa. Figure 2.3 – Directed association  An association is a relationship in which objects of one type are somehow related to objects of another type. For example, an object of one type contains or somehow uses an object of another type. The player plays in a team. We do not yet know what kind of relationship they have, or we are not interested in it at this stage of the design. But we know that there is a relationship. "},{"title":"2.3 Inheritance​","type":1,"pageTitle":"2. Unified Modeling Language","url":"docs/building-blocks-of-oop-part-1/unified_modeling_language#23-inheritance","content":"A more precise type of relationship is the public inheritance relationship (IS A Relationship), which says that everything that is true for the base class is true for its successor. With its help we can get polymorphic behavior, abstract from the concrete implementation of classes, dealing only with abstractions (interfaces or base classes) and do not pay attention to implementation details. Figure 2.4 – Inheritance relationship  Although inheritance is a great tool in the hands of any OOP programmer, it is clearly not enough for solving all types of problems. Firstly, not all relationships between classes are defined by the &quot;is a&quot; relationship, and secondly, inheritance is the strongest relationship between two classes that cannot be broken at runtime (this relationship is static and, in strongly typed languages, is determined at compile time). That is, JavaScript, as we all know, has prototypal inheritance and indeed it can be changed for inherited classes, properties can be changed, you can just change prototypes. But this is more an exception rather than a rule. Because you cannot do this in classical inheritance: once inherited in the source code, at run time you will not break this connection, and you will not change the base class. That is why it is believed that inheritance is the strongest relationship between objects. That is why architects and system designers recommend using inheritance only when it is necessary. I think you have heard the concept of preferring composition over inheritance, this suggests that composition can be broken at run time, and you can replace one object in the composition at runtime with another, change the behavior dynamically. You cannot do this with the inheritance. "},{"title":"2.4 Composition and Aggregation​","type":1,"pageTitle":"2. Unified Modeling Language","url":"docs/building-blocks-of-oop-part-1/unified_modeling_language#24-composition-and-aggregation","content":"When relationships between components go beyond inheritance, relationships such as composition and aggregation come to our rescue. They both model a HAS-A Relationship and are usually expressed in that the class of a whole contains the fields (or properties) of its constituent parts. The line between the concepts is thing, but important, especially in the context of dependency management. We will also talk about dependency management a little later, when we touch on the topic of object-oriented design, because dependency management is one of the tools of object-oriented design. Figure 2.5 – Composition and Aggregation  A couple of points to make it easier to remember the visual notation: the diamond is always on the side of the whole, and the simple line is on the side of the component.a filled rhombus indicates a stronger bond - composition, an open rhombus indicates a weaker bond - aggregation. The difference between composition and aggregation is that in the case of composition, the whole explicitly controls the lifetime of its component part (the part does not exist without the whole), and in the case of aggregation, although the whole contains its component part, their lifetimes are not related (for example, the component part is passed via constructor parameters). Listing 2.1. CompositeCustomService uses composition to manage its constituent parts, and AggregatedCustomService uses aggregation. In this case, explicit control of the lifetime usually leads to a higher coupling between the whole and the part, since a specific type is used that closely connects the participants with each other. Listing 2.1 – Example of Composition and Aggregation class CompositeCustomService { // Composition private readonly repository: CustomRepository = new CustomRepository(); public doSomething() { // Usage of repository } } class AggregatedCustomService { // Aggregation private readonly repository: AbstractRepository; constructor(repository: AbstractRepository) { this.repository = repository; } public doSomething() { // Usage of repository } }  Another example of composition. Let us say a bicycle is a whole part and its components (shock absorbers, wheels, handlebars) are parts. In fact, a single shock absorber without a bike makes no sense. An example of aggregation. Suppose there is a university or a school as a whole and teachers, professors as parts, for a certain period they may be part of this university, in some period they may not be included. They can exist without this university after the university is destroyed, that is, its lifetime is over. "},{"title":"5. Design by Contract","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-2/desing_by_contract","content":"","keywords":""},{"title":"5.1 Correctness​","type":1,"pageTitle":"5. Design by Contract","url":"docs/building-blocks-of-oop-part-2/desing_by_contract#51-correctness","content":"Design by contract (DbC), also known as contract programming, programming by contract and design-by-contract programming, is an approach for designing software. It prescribes that software designers should define formal, precise and verifiable interface specifications for software components, which extend the ordinary definition of abstract data types with preconditions, postconditions and invariants. These specifications are referred to as &quot;contracts&quot;, in accordance with a conceptual metaphor with the conditions and obligations of business contracts. Before we will proceed to contracts, we need to understand why we need to learn this theme, and the first term we need to understand is &quot;system correctness&quot;. Listing 5.1 // Example 1 const doSomething = (x) =&gt; { return x / 2; } // Example 2 // { x = 5 } x = x ˆ 2 { x &gt; 0 } =&gt; the weakest postcondition // Example 3 // { x = 5 } x = x ˆ 2 { x = 25 } =&gt; the strongest postcondition  This function by itself is neither correct nor incorrect, correctness can be applied when we talk about expected results. This function is correct if we say that &quot;Returned value is half the size of the argument&quot;, but it is not correct if we say that &quot;Returned value should be positive&quot; because there are no guarantees that the function will not receive a negative number as the argument. This example makes it clear that correctness can be applied to the specification, but not to the function code. The next part we need to review is a Hoare triple from examples two and three. The first triple is correct as before the operation x ^ 2 precondition is met and x is equal to 5, then after the operation postcondition (x is greater than 0) also will be met (subject to correct implementation of integer arithmetic). In this example postcondition is not the strongest one, the strongest possible postcondition for this precondition is {x = 25} and the weakest one is {x &gt; 0}. We always can create a new triple from existing one making precondition and postcondition weaker or stronger. Figure 5.1 - x &gt; 5 is stronger than x &gt; 0  The concept of &quot;stronger&quot; and &quot;weaker&quot; came from logic. It is said that the condition P1 is stronger than P2, and P2 is weaker than P1 if the fulfillment of P1 implies the fulfillment of P2, but they are not equivalent. For example, x &gt; 5 (P1) is stronger than x &gt; 0 (P2), since if P1 is fulfilled, P2 is fulfilled as well (after all, if x is greater than 5, then, naturally, x is greater than 0), and they are not equivalent. Listing 5.2 class Stack&lt;T&gt; { private count = 0; private maxAmount = 15; public push(e: T) { console.assert(this.count &lt; this.maxAmount, 'Stack not overflown'); const previousCount = this.count; // method implementation console.assert(this.count === previousCount + 1, 'One more item'); } public pop(): T { console.assert(this.count !== 0, 'Stack is empty'); // method implementation console.assert(result !== null, 'Result is not null'); console.assert(this.count === previousCount - 1, 'One less item'); return result; } }  Each function has strict semantic properties that reflect what the function does, regardless of how it does it. In this case, preconditions define properties that must be met every time before function is executed, and postconditions - those properties that must be met after its execution. The precondition binds the calling code: the conditions are defined under which the program call by the client is legitimate (for example, x &gt; 0 for the Sqrt function or count ! = 0 for the Pop function of the Stack class). In this case, the client's obligations benefit the provider class, since the class performing the operation does not need to worry about what to do if a precondition is violated: return a default value or error code, throw an exception, save information about the error to the I/O stream, or interrupt the program execution. The postcondition binds the class: the conditions that must be met upon completion of the operation are determined (the Stack class must provide an increase in the number of elements by 1 after the push function is executed). Here, the client's benefit (the result of performing the function) turns into the supplier's obligations (he can no longer fail to fulfill his obligations, since they are spelled out in the contract). "},{"title":"5.2 Preconditions and Postconditions for Inheritance​","type":1,"pageTitle":"5. Design by Contract","url":"docs/building-blocks-of-oop-part-2/desing_by_contract#52-preconditions-and-postconditions-for-inheritance","content":"Let us review an example from Figure 5.2 where we have C class which contains link to a B class. Due to dynamic linking D class (or any other B subclass) can be used instead of B class after the start of program execution. Figure 5.2 - B – C – D classes relations  Listing 5.3 class B { public foo(x: number): number { console.assert(x &gt; 5, 'x &gt; 5'); //method implementation console.assert(result, 'result &gt; 0'); return result; } } class C { private b: B; public bar(x: number) { if (x &gt; 5) { const result = this.b.foo(x); console.assert(result &gt; 0, 'result &gt; 0'); } } }  B class has a public foo function with a precondition of x &gt; 5 (pre_b) and a postcondition result &gt; 0 (post_b). By checking the precondition, class C fulfills its part of the contract and can expect class B (or one of its subclasses) to fulfill the contract. According to the Liskov substitution principle, the behavior of the given code fragment should not change if we substitute any B subclass. Let us assume that the function foo in class D starts to require more (contains a stronger precondition like x &gt; 10), and guarantees less (contains a weaker postcondition like x &gt; -5) In this case, although the client of class B fulfills its part of the contract and provides an input value to the function foo that satisfies the precondition, it may not get the expected result. Strengthening the precondition means that the data correct for the base class will become incorrect for its subclass (in our example, it can be the value x equal to 6), and weakening the postcondition means that the result that the client of the base class expects may not be returned by the subclass (in our example, this could be the result of the function Foo equal to -1). Hence, we can conclude that when overriding methods, the precondition can be replaced only by an equal or weaker one (require less), and a postcondition - only equal to it or stronger (guarantees more). The new version of the method should not reject calls allowed in the original, and should, at a minimum, provide guarantees equivalent to those of the original version. It is free, although not obligated, to allow more calls or provide stronger guarantees. "},{"title":"5.3 Covariance and Contravariance​","type":1,"pageTitle":"5. Design by Contract","url":"docs/building-blocks-of-oop-part-2/desing_by_contract#53-covariance-and-contravariance","content":"Based on the previous example, we can come to terms such as covariant and contravariant, when replacing the base class with its subclass, the input values for its methods must be contravariant, that is, the precondition must be the same or weaker, and the output values must be covariant, that is, the same or stronger. Consider the following example for better understanding: Listing 5.4 class Locality {} class City extends Locality {} class NewYork extends City {} function covariance(city: City): void {} covariance(new Locality()); // error... does not support supertype covariance(new City()); // ok support exact type covariance(new NewYork()); // ok support subtype function contravariance(city: City): void {} contravariance(new Locality()); // ok support supertype contravariance(new City()); // ok support exact type contravariance(new NewYork()); // error... does not support subtype  We have inheritance structure built of three classes, Locality as a base class and City and NewYork as more specific classes. Function with name covariance accepts City instances as an argument, but it also can accept NewYork instances as the more specific subclass and at the same time it can not accept City superclass as the argument – Locality because covariance will be violated in such case. Everything is vice versa for the contravariance function – it can accept City and its supertype as the argument but cannot accept City subclass. Let us look on another example, with a more detailed implementation, to understand how contravariance works on input values: Listing 5.5 class Price {} class Destination {} class USADestination extends Destination {} class TexasDestination extends USADestination {} class ShippingCalculator { public getRate(destination: USADestination): Price { return new Price() } } class InternationalShippingCalculator extends ShippingCalculator { // ok - contravariance on input value public getRate(destination: Destination): Price { return new Price() } } class TexasShippingCalculator extends ShippingCalculator { // wrong - covariance on input value public getRate(destination: TexasDestination): Price { return new Price() } }  In this example, we also have an inheritance hierarchy of three classes, the base Destination, its USADestination subclass and the even more specific TexasDestionation class. If we want to create a ShippingCalculator class that will accept USADestination as input and return the Price to us, and then create its InternationalShippingCalculator subclass which will already accept any Destination as input, then this will be correct since the contravariance of the input values is observed, and we can replace the ShippingCalculator with InternationalShippingCalculator, and it will work. But if after that we want to extend the functionality of the ShippingCalculator by creating its TexasShippingCalculator subclass which will only accept TexasDestionation as input, then in this case we can already say that the contravariance is not observed, since the input value is more specific, and in this case we cannot replace the ShippingCalculator on TexasShippingCalculator while keeping the system working. Based on the next example we will find out how to meet contravariance for the output values: Listing 5.6 class Animal { public feed(food): void { console.log('yumm!') } public walk(): void { throw new Error('Not implemented') } } class Snake extends Animal { public crawl(): void { console.log('crawling') } } class Wolf extends Animal { public walk(): void { console.log('walking') } } class CanisLupus extends Wolf {} class ZooCage { public getContent(): Wolf { return new Wolf() } } class CanisLupusCage extends ZooCage { // ok - returns subtype public getContent(): CanisLupus { return new CanisLupus() } } class Terrarium extends ZooCage { // wrong - returns supertype public getContent(): Animal { return new Snake() } }  We have the base Animal class and its three subclasses, while the Snake and Wolf classes are its direct subclasses, and the CanisLupus class is a Wolf subclass. If we want to create a ZooCage class that will return the contents of the cage and the expected output value will be the Wolf class, then to maintain covariance in the CanisLupusCage class, we need to return the Wolf or CanisLupus class. If we create a Terrarium class with an output value of the Animal class, then the covariance will not be met, since the Animal class is a superclass of the Wolf class. "},{"title":"1. Design Patterns","type":0,"sectionRef":"#","url":"docs/design-patterns/design_patterns","content":"","keywords":""},{"title":"1.1 History of Patterns​","type":1,"pageTitle":"1. Design Patterns","url":"docs/design-patterns/design_patterns#11-history-of-patterns","content":"Who has invented patterns? It's a good but not quite accurate question, since patterns are not being invented. More likely, that they are being explored. Patterns are not extraordinary solutions, but opposite. Most typical, often used solutions for common problems. Historically the concept of patterns was not about software design. It came from a book about buildings. It was firstly described in book &quot;A Pattern Language. Towns. Buildings. Construction&quot; as a language of environment design. Here patterns were used for architectural questions: how high windows should be, how many floors should be in the building, how much place should be taken for trees and lawn. This idea was adopted by authors Erich Gamma, Richard Helm, Ralph Johnson and John Vissides. In 1994 they published a book &quot;Design Patterns: Elements of Reusable Object-Oriented Software&quot;, which consisted of 23 patterns for different commonly occurring software design problems. Long title of the patterns book was hard to remember, and soon they started calling it &quot;Book by the gang of four&quot; and later just &quot;GoF book&quot;. Since then, dozens of object-oriented design patterns were discovered. "},{"title":"1.2 Types of Patterns​","type":1,"pageTitle":"1. Design Patterns","url":"docs/design-patterns/design_patterns#12-types-of-patterns","content":"Creational patterns – provide a way to create objects while hiding the creation logic, rather than instantiating objects directly using new operator. This gives program more flexibility in deciding which objects need to be created for a given use case. Structural patterns – are related to class and object composition. Concept of inheritance is used to compose interfaces and define ways to compose objects to obtain new functionalities. Behavioral patterns – are used for efficient and safe communication between objects and distribution of responsibility among them. For this purpose, both inheritance and composition-based mechanisms can be used. Patterns are software development tools. Like real-world tools, that you can simply buy in a hardware store, they have specific purpose and are not equally useful in different scenarios. Some of them are similar to a trusty hummer, that has very wide range of use. Others can be associated with very specific measurement tool, which is great to have on rare occasion. We are not going to cover all gang of four design patterns. We will target the most common and most useful. And by the way, most of them are not quite easy to implement in plain JavaScript, and therefore we will use Typescript in examples. "},{"title":"1. Functional programing (FP)","type":0,"sectionRef":"#","url":"docs/functional-programming/general_fp","content":"","keywords":""},{"title":"1.1 Imperative programing paradigm​","type":1,"pageTitle":"1. Functional programing (FP)","url":"docs/functional-programming/general_fp#11-imperative-programing-paradigm","content":"Imperative programming is one of the oldest programming paradigms. It has a close connection to machine architecture. By changing the state through assignment statements we are achieving results. The state is changing by performing step-by-step tasks. The main concept is how to achieve our goal. If you are following the imperative programming paradigm you have several statements and the result is stored after execution of all of them. Pros Very simple to implement Cons Less efficient and less productiveParallel programming is not possible Listing 1.1 const doubleMap = (numbers) =&gt; { const doubled = []; for (let i = 0; i &lt; numbers.length; i++) { doubled.push(numbers[i] * 2); } return doubled; }; console.log(doubleMap([2, 3, 4])); // [4, 6, 8]  In the Listing 1.1 our goal is to double each array element and return a new array with doubled values. As was mentioned before, in case of imperative programming, our focus is on HOW to achieve the result. So, we have several main steps: creation of new empty array doubledgoing through array with for loopdouble each elementpush the doubled element into doubled arrayreturn doubled array By doing these steps one-by-one as a result we will have [4, 6, 8]. "},{"title":"1.2 Declarative programing paradigm​","type":1,"pageTitle":"1. Functional programing (FP)","url":"docs/functional-programming/general_fp#12-declarative-programing-paradigm","content":"The main idea of Declarative programming paradigm is to define what needs to be accomplished by the program, but not how it needs to be implemented. So, in other words, instead of instructing how to achieve the desired results we focus only on the result itself. It is different from imperative programming which focuses on a set of commands which need to be executed in order to achieve the required solution. Declarative programming describes a particular class of problems that have to be solved and a language implementation takes care of finding the solution. With this approach, the resulting program is simpler to read. The same example, but in a declarative way. Listing 1.2 const doubleMap = (numbers) =&gt; numbers.map((n) =&gt; n * 2); console.log(doubleMap([2, 3, 4])); // [4, 6, 8]  Let's analyze what is the difference - in this case, we know that map function creates a new array, so we do not need to think about it. We also know that map goes through the array, so we can skip the implementation of these parts. So, there are several main steps: all routine work is done by mapwe only pass the callback in which we provide the condition which is important to us in this case. "},{"title":"1.3 Is FP imperative or declarative?​","type":1,"pageTitle":"1. Functional programing (FP)","url":"docs/functional-programming/general_fp#13-is-fp-imperative-or-declarative","content":"In order to answer this question, let's compare these two approaches: Characteristic\tImperative Approach\tFunctional ApproachDescription\tThe program directly changes computed state\tThe program avoids mutating state and computation data Key points\tDirect assignments, global variables, common data structures\tCompositiionality, resursion, no side effects Programmer focus\tHow to perform tasks and how to track state changing\tWhat is desired and what transformations are required State changes\tImportant\tNon-existent Order of execution\tImportant\tLow importance Primary flow control\tLoops, conditionals and function calls\tFunction calls, resursion Primary manipulation unit\tInstances of structures or classes\tFunctions as first-class objects and data collections As we can see FP implements most of the declarative rules, such as programmers focus on what to do, composition, recursion, immutability, functions as first-class objects, etc. "},{"title":"6. 📚 Home Task","type":0,"sectionRef":"#","url":"docs/design-patterns/hometask","content":"","keywords":""},{"title":"Step 1: Starting Simply​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/design-patterns/hometask#step-1-starting-simply","content":"You are coding up the back-end for a Package Handling system. Another team is creating a front-end part, but this is not ready yet. Yet another team is working on a persistence layer which, will be able to generate unique Shipment ID's for you when needed (see below), but this is also not yet ready. You will need, at minimum, two objects. One will represent the controlling, or Client object that will interact with the front-end, when it is available. The other will represent the object being shipped. State that will come from the end user via the front-end part is the next: ShipmentID - a number that represents an existing ID, or 0, which means you have to generate a new, unique ID at construction timeWeight - a number, storing the weight of the item in ouncesFromAddress - a string containing street, city, and state, should be changeableFromZipCode - a string containing exactly 5 characters, should be changeableToAddress - a string containing street, city, and state, should be changeableToZipCode - a string containing exactly 5 characters, should be changeable The client object will obtain a single instance of the object which represents the item being shipped, and then ask it to 'ship itself' (calls its ship method). The return from this request will be a single string indicating the shipment ID, where the item was sent from, where it is going, and how much the cost was. The cost will be determined by the weight. The rate of 39 cents per ounce will be applied. Once the client has this return, it should send it to the console for display. Things to note: • Make sure you follow good practices. Always program by intention, and always encapsulate the construction of instances. • Since you don't have the actual front-end part to get the shipment data, you need to create a mock for it. Just make sure it will be easy to replace the mock with the real implementation in the future. tip Remember programming by intention tends to produce cohesive methods, which are easier to change and move from place to place. • Since you don't have the actual persistence layer which can generate unique ID's for you, you'll need to simply generate a unique ID for now. Again, make sure this is as easy as possible to change when the real code is ready. Hint: make a method called getShipmentID which, for now, just increases a static int by one and returns it but in the future will get the real shipment ID. Figure 6.1 illustrates this in the UML. Figure 6.1 - Client using Shipment  "},{"title":"Step 2: Multiple Shippers​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/design-patterns/hometask#step-2-multiple-shippers","content":"Now you are informed that there are multiple partner companies used to actually ship the item in question. This will affect the per-ounce rate used when cost is determined. The companies are: Air East: Based in AtlantaChicago Sprint: Based in a suburb of ChicagoPacific Parcel: Based in San Diego The correct shipper to use is determined by the zip code of the sender (the &quot;from&quot; zip code). If the from zip code begins with 1, 2, or 3, then the source location is in the east, and Air East will be used. A 4, 5, or 6 as the first digit of the from zip code means Chicago Sprint is the right choice. A 7, 8, or 9 will mean the western US, and therefore Pacific Parcel. Air East charges 39 cents per ounce, as we are accustomed to paying (they are the vendor we have been using all along). Chicago Sprint charges 42 cents. Pacific Parcel charges 51 cents. Things are expensive in southern California! Note that the &quot;to&quot; zip code does not affect the price. All our vendors have reciprocal agreements for cross-country shipping. If the zip code is unknown, Air East will be the default. Figure 6.2 illustrates this in the UML. Figure 6.2 - Shipment using Shipper as Strategy  "},{"title":"Step 3: Different Kinds of Shipments​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/design-patterns/hometask#step-3-different-kinds-of-shipments","content":"Now there are three types of items being shipped: Letters, Packages, and Oversize. The way you know which type of thing is being shipped is determined by weight2. Regardless of which shipper is being used, the following rules apply: A Letter is anything up to and including 15 ounces (less than a pound)A Package is anything up to and including 160 ouncesAn Oversize package is anything heavier than 160 ounces The various shippers have different actions to take, depending on what sort of item is being shipped: \tAir West\tChicago Sprint\tPacific ParcelLetter\t0.39 per ounce\t0.42 per ounce\t0.51 per ounce Package\t0.25 per ounce\t0.20 per ounce\t0.19 per ounce Oversized\t$10 flat in addition to standard package charge\tNo charge\t0.02 added per ounce in addition to standard package charge Figure 6.3 illustrates this in the UML. Figure 6.3 - Shipments using Shipper as Bridge  "},{"title":"Step 4: Marking Shipments with Special Codes​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/design-patterns/hometask#step-4-marking-shipments-with-special-codes","content":"If selected in the GUI, the Shipment may be marked Fragile, Do Not Leave, and Return Receipt Requested, or any combination of these three. Here again, the GUI is not actually available, so you'll need to stub this out somehow, somewhere. The effect of this will be that when the Client asks the Shipment to &quot;ship itself&quot;, this extra information will appear at the bottom, in all uppercase and surrounded by double asterisks. Here is an example, with all three marks applied: Shipment with the ID 17263 will be picked up from 12292 4th Ave SE, Bellevue, Wa 92021 and shipped to 1313 Mockingbird Lane, Tulsa, OK 67721 Cost = 5.1 **MARK FRAGILE** **MARK DO NOT LEAVE IF ADDRESS NOT AT HOME** **MARK RETURN RECEIPT REQUESTED**  Figure 6.4 illustrates this in the UML. Figure 6.4 - Shipper being decorated  note You may not strictly follow every UML-diagram. If you want to replace some designs pattern to another one, which you think fit better, or you suppose some pattern is redundant here you may not use it (please, add comments why it's redundant). In case of implementation Shipment and Shipper classes as Singletons you may face with issue where Singleton can't play role of Base/Abstract class. In such case you can consider using composition instead of inheritance or just to not make those classes as Singletons at all. "},{"title":"Evaluation criteria​","type":1,"pageTitle":"6. 📚 Home Task","url":"docs/design-patterns/hometask#evaluation-criteria","content":"Only the step 1 is completed.Steps 3 and 4 are not completed.The last step is not completed.All the steps are completed. "},{"title":"3. Principles of OOP","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-1/principles_of_oop","content":"","keywords":""},{"title":"3.1 Abstraction​","type":1,"pageTitle":"3. Principles of OOP","url":"docs/building-blocks-of-oop-part-1/principles_of_oop#31-abstraction","content":"Abstraction in object-oriented programming means the highlighting of some significant parts, meaningful information from a component, no matter whether it is a class or an architectural layer in the system, or a logical unit of our system. In general, the highlighting of significant parts or exclusion of insignificant parts from consideration. In OOP, only data abstraction is considered, usually it simply called as &quot;abstraction&quot; implying a set of the most significant characteristics of an object available for the program. Abstraction is essential when dealing with system complexity by hiding implementation details and highlighting essential aspects of behavior. The main idea of abstraction is to describe real life objects and how they interact in a software system. Abstraction can be implemented using interfaces and abstract classes. Listing 3.1 – Example of Promise object in JavaScript new Promise((resolve, reject) =&gt; { // asynchronous code }) .then((result) =&gt; { // handling the result }) .catch((error) =&gt; { // handling an error });  An example of abstraction is a JavaScript class Promise (Listing 3.1), which has a well-defined public interface (then, catch, all methods) while the client (the client is not a browser, but the calling program, the component that uses the Promise) works exclusively with meaningful behavior, public interface. It knows that by calling the then method he will receive the data, and by calling the catch method he will handle the error and so on. In this case, it does not matter at all how exactly the Promise object performs its work with asynchronous actions. Thus, all behavior that is insignificant to the client is hidden behind the abstraction. And if the logic of work inside the Promise object itself changes, the client will not change accordingly, because it does not depend on this behavior. The open part means the abstraction, that is, the interface should be the most stable, since a certain number of clients depend on it. Accordingly, the more the number of clients does depend on, the more stable it should be, because when the interface changes, there will be a cascading change in all clients. The hidden part, that is, the implementation details, is the more unstable part of the abstraction, it can change while maintaining the public interface. Listing 3.2 – Abstraction example – Class CoffeeMachine with public method brewCoffee enum CoffeeSelection { FILTER_COFFEE, ESPRESSO, CAPPUCCINO, } class CoffeeBean { // implementation of CoffeeBeen } class Coffee { constructor(selection: CoffeeSelection, volume: number) { // implementation of Coffee } } class Configuration { constructor(weight: number, volume: number) { // implementation of Configuration } } class CoffeeMachine { private configMap: Map&lt;CoffeeSelection, Configuration&gt;; private beans: Map&lt;CoffeeSelection, CoffeeBean&gt;; constructor(beans: Map&lt;CoffeeSelection, CoffeeBean&gt;) { this.beans = beans; // create coffee configuration this.configMap = new Map&lt;CoffeeSelection, Configuration&gt;(); this.configMap.set(CoffeeSelection.ESPRESSO, new Configuration(8, 28)); this.configMap.set( CoffeeSelection.FILTER_COFFEE, new Configuration(30, 480) ); } public brewCoffee(selection: CoffeeSelection): Coffee { const coffee = new Coffee(selection, 100); console.log(&quot;Making coffee...&quot;); return coffee; } }  Listing 3.3 – Abstraction example – Using class CoffeeMachine to brew coffee const main = () =&gt; { // create a |Map of available coffee beans const beans = new Map&lt;CoffeeSelection, CoffeeBean&gt;(); beans.set( CoffeeSelection.ESPRESSO, new CoffeeBean(&quot;My favorite espresso bean&quot;, 1000) ); beans.set( CoffeeSelection.FILTER_COFFEE, new CoffeeBean(&quot;My favorite filter coffee bean&quot;, 1000) ); // get a new CoffeeMachine object const machine = new CoffeeMachine(beans); // brew a fresh coffee const espresso: Coffee = machine.brewCoffee(CoffeeSelection.ESPRESSO); };  Well, you can see that we have a certain abstraction called a CoffeeMachine, it is presented on the Listing 3.3. A coffee machine is a kind of abstraction, in which there are some implementation details, that is, not significant behavior: configuration, configMap, working with different coffee beans, it knows how to brew espresso, it knows how to brew filtered coffee - all this is not important for the client. The client knows that the coffee machine has one and only public method (interface method) brewCoffee and the client depends only on this method. It is important for the client to know that he needs to create an instance of the CoffeeMachine class, pass coffee beans there and call the brewCoffee method. The CoffeeMachine is an abstraction, and the method brewCoffee is a significant behavior that we have highlighted in this abstraction. Everything else, all the settings of the coffee machine, initialization in the constructor of some configuration of everything else - for the client this is not meaningful behavior, it should not depend on it, because it is unstable, it can change. The implementation details are changed systematically, the requirements are changed systematically, the main thing is not to change the public interface on which clients depend. "},{"title":"3.2 Encapsulation​","type":1,"pageTitle":"3. Principles of OOP","url":"docs/building-blocks-of-oop-part-1/principles_of_oop#32-encapsulation","content":"If abstraction allows us to highlight the essential behavior of our component, the essential aspects of its behavior, then encapsulation is the tool that helps to hide unimportant implementation details out of sight. In the design field, there are two concepts - encapsulation and data hiding, information hiding. Encapsulation is commonly used in the context of information hiding. Public mutable data violates encapsulation, because in this case any client of the class can change the internal state of the class object without the notification of the class. To achieve encapsulation in the design, two components are distinguished, the two parts of the class that were mentioned earlier are the public part, its public interface, and the private part, not meaningful to the client behavior, implementation details. At the same time, the class interface that has encapsulation should not just take and duplicate the property of this class through accessors (getters and setters), it should provide abstract interface, a higher-level one that is needed by the client. In other words, the public part should expose more about what the class does and hide unnecessary implementation details from clients. Abstraction and encapsulation complement each other and form some more general holistic picture of the object-oriented programming paradigm. Listing 3.4 – Encapsulation is violated class Paystub { private readonly employees: Employee[]; public getEmployees(): Employee[] { return this.employees; } public computePayroll(): number { // using this.employees for calculation return 42; } } const p1 = new Paystub(); const employees = p1.getEmployees(); employees.push(new Employee()); employees.push(new Employee()); p1.computePayroll();  Listing 3.5 – Encapsulation is not violated class Paystub2 { private readonly employees: Employee[]; public addEmployee(employee: Employee): void { this.employees.push(employee); } public computePayroll(): number { // using this.employees for calculation return 42; } } const p2 = new Paystub2(); p2.addEmployee(new Employee()); p2.addEmployee(new Employee()); p2.computePayroll();  Here we have two classes. The first class on the Listing 3.4 is Paystub, the other class is Paystub2 (Listing 3.5). In both examples, we have the private data employees, which is an array that can contain a certain number of instances of the Employee class. In the example on the Listing 3.4, the getEmployees method returns this.employees array so the client can access and modify the data (add and remove items). In the second example, the designer of our system, in which this class appears, made a certain assumption that the client would be able to add Employee to Paystub2, in what way - the client should not be interested. It should not depend on implementation details, how exactly Employees will be added to the Paystub2 class, it should only depend on the abstract public interface, that is, on the addEmployees method. It should be enough for the client to call the addEmployees method with instances of the Employee class, it no longer depends on the data structure, an object or a linked list can be used instead of an array. In the second case, the client will not break, everything will work as before, only the implementation of the addEmployees method will change. In the first case, everything will break, because the client knows that this is an array, he works with this data as with an array, when we change it to an object, and we cannot push data there, if you will need to add new records there - the client will break. This is bad, because there can be not one, but a thousand such clients, and the half of the system will collapse because this system depends on the internal implementation in which there is pseudo encapsulation. As mentioned earlier, class members do not just have to be duplicated through setters and getters, and getEmployees is, in fact, a regular getter. And the abstraction should provide some high-level interface for working with itself. Another example to show that hiding data is not just about creating private class members and working with them. Suppose we have a server. You are writing an application from scratch. Server is written on NodeJS and some configuration data is required on the backend. Suppose these are passwords for connecting to a database or some sort of sensitive information. All this data is stored in the config.json file located somewhere on your server, in some directory. And then we have 2 options: You can spread the logic of working with the configuration throughout the application in such a way that any component that needs a part of the configuration will just read this config.json file, parse it, and so on.The client is agnostic to the location and the configuration format. And access is provided through the ConfigurationProvider class or module, which encapsulated the logic for working with configuration, it would be able to parse it and return data. And ConfigurationProvider will be provided through dependency injection to the components where it is needed. The second case is also an encapsulation, in which we hide the entire management of the configuration, and if something changes (for example, the data storage format changes from json to xml), it would not be necessary to rewrite all components that depend on the configuration. Clients of ConfigurationProvider interface will continue to work. Abstraction and encapsulation also play a key role in fighting complexity, providing the ability to design at a higher level, abstracting from implementation details. "},{"title":"3.3 Inheritance​","type":1,"pageTitle":"3. Principles of OOP","url":"docs/building-blocks-of-oop-part-1/principles_of_oop#33-inheritance","content":"Inheritance is the mechanism of basing an object or class upon another object (prototypical inheritance) or class (class-based inheritance), retaining similar implementation. In most class-based object-oriented languages, an object created through inheritance (a &quot;child object&quot;) acquires all the properties and behaviors of the parent object. Here, I hope things should be much easier because you are most familiar with this concept. Inheritance mechanisms also play a key role in the object-oriented approach, in terms of extensibility, reusability of components in the system. This is an &quot;is&quot; or &quot;is a&quot; relationship, a relationship between a base class and descendants. This relationship is the strongest and in statically typed languages it cannot be broken, and this must be considered when assessing the need to use inheritance in this case. If inheritance were applied in a place where one could do without it, as a result, with poor support, this all make difficult to understand and maintain code, because the inheritance hierarchy can be 10 classes or more, and it is rather difficult to understand somewhere in the middle or how the last class will behave, it is hard to understand in what places which methods are being overwritten or overridden, and so on. Therefore, inheritance must be approached wisely. Listing 3.6 – Inheritance example class Person { protected name: string; constructor(name: string) { this.name = name; } } class Employee extends Person { private department: string; constructor(name: string, department: string) { super(name); this.department = department; } public getDetails() { return `Hello, my name is ${this.name} and I work in ${this.department}.`; } } const howard = new Employee(&quot;Howard&quot;, &quot;Sales&quot;); console.log(howard.getDetails()); // ok console.log(howard.name); // error console.log(howard.department) // error  On the Listing 3.6 you can see an example of inheritance. We have a Person class and an Employee class. Employee inherits some methods and some properties from Person. There are 3 types of access modifiers: Private – not accessible from the outside, only instances of this current class can work with these properties. The Employee class has a department property, and only objects of the Employee class can work with this property.Protected – is a little wider than private, only instances of the current class and classes of descendants can work with them. From Employee, we can refer to name from Person. Moreover, they are also closed to the outside world.Public - public properties and methods are those that are provided to clients in the form of a public interface, on which they will depend, which should be the most stable and the most unchangeable. "},{"title":"3.4 Polymorphism​","type":1,"pageTitle":"3. Principles of OOP","url":"docs/building-blocks-of-oop-part-1/principles_of_oop#34-polymorphism","content":"Polymorphism is the provision of a single interface to entities of different types or the use of a single symbol to represent multiple different types. In general, the word polymorphism consists of two parts: poly – many, morphs - forms, that is, many forms. The word polymorphism is used not only in programming, but also in other areas, and it describes situations where something can exist in several forms. In programming, polymorphism describes such a concept when objects of different types are sharing the same interface. Each type can provide its own implementation of this interface. If we discuss the concept of polymorphism in its classical representation, that is, in statically typed languages, in Java or Typescript, there are two types of polymorphism - static polymorphism and dynamic polymorphism: Static polymorphism: allows you to implement multiple methods within the same class that use the same name but a different set of parameters. That is called method overloading. (Listing 3.7)Dynamic polymorphism: does not allow the compiler to determine the executed method. Within an inheritance hierarchy, a subclass can override a method of its superclass. That enables the developer of the subclass to customize or completely replace the behavior of that method. (Listing 3.8) Listing 3.7 is an example of static polymorphism in TypeScript. There is a certain HeroService from the Angular documentation, and it has a getHero method that behaves differently depending on the parameters that are passed to it. Method overloading differs from one language to another because TypeScript makes it impossible to write different implementations for the same method. But it allows writing different signatures so that you can declare a method with different arguments and with different types of values obtained, while still using the same implementation. Listing 3.7 – Static polymorphism example interface Hero { name: string; skill: string; weakness: string; } class HeroService { protected heroes: Hero[] = [ { name: &quot;Superman&quot;, skill: &quot;fly&quot;, weakness: &quot;cryptonit&quot; }, { name: &quot;Spiderman&quot;, skill: &quot;spider-sense&quot;, weakness: &quot;MJ&quot; }, { name: &quot;Batman&quot;, skill: &quot;superhuman power&quot;, weakness: &quot;law&quot; }, { name: &quot;Flash&quot;, skill: &quot;run&quot;, weakness: &quot;unknown&quot; }, ]; public getHero(name: string); public getHero(name: string, skill: string); public getHero(name: string, skill?: string): Hero { if (!skill) { return this.heroes.find((hero) =&gt; hero.name === name); } return this.heroes.find( (hero) =&gt; hero.name === name &amp;&amp; hero.skill === skill ); } } const heroService = new HeroService(); const hero1 = heroService.getHero(&quot;Flash&quot;); const hero2 = heroService.getHero(&quot;Superman&quot;, &quot;fly&quot;);  Dynamic polymorphism. Everything is simple here; this is a usual method overriding in the inherited classes. Dynamic, because at the compilation stage no binding is carried out and the actual implementation of the method can be defined only in Runtime, we do not know which of the class instances will be called. On the Listing 3.8 you can see that in AntiheroService method getHero is overridden to accept weakness instead of name or skill. Listing 3.8 – Dynamic polymorphism example class HeroService { // implementation of HeroService } class AntiHeroService extends HeroService { public getHero(weakness: string): Hero { return this.heroes.find((hero) =&gt; hero.weakness === weakness); } } const antiHeroService = new AntiHeroService(); const hero = antiHeroService.getHero(&quot;law&quot;);  "},{"title":"3. Mixins","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-2/mixins","content":"","keywords":""},{"title":"3.1 Sharing Role Behavior with Mixins​","type":1,"pageTitle":"3. Mixins","url":"docs/building-blocks-of-oop-part-2/mixins#31-sharing-role-behavior-with-mixins","content":"Mixins is another OOD tool, inheritance is not the only way to share a behavior, every problem which we solve using inheritance also can be solved using other tools, and one of such tools are mixins. But each tool has its pros and cons so let us look on what mixins can give us and what the price we must pay to use them. "},{"title":"3.2 Understanding Roles​","type":1,"pageTitle":"3. Mixins","url":"docs/building-blocks-of-oop-part-2/mixins#32-understanding-roles","content":"Sometimes you need to share some behavior between non-related objects, such case is a direct opposite to inheritance hierarchy (IS-A relation). It is rather a role, which object can play on some state of its lifecycle. Let us review some basic example below: Listing 3.1 const sayMixin = { say(phrase) { alert(phrase); } }; const sayHiMixin = { __proto__: sayMixin, sayHi() { super.say(`Hello ${this.name}`); }, sayBye() { super.say(`Bye ${this.name}`); } }; class User { constructor(public name) {} }  We have sayMixin with say method which prints given phrase on the screen, we also have its extended version – sayHiMixin. When you need to use mixin functionality on some object, you can just add it to the object's prototype, and this will give us the possibility to use mixins methods on this object. Listing 3.2 Object.assign( User.prototype, sayHiMixin ); new User('Dave').sayHi();  But such approach has some consequences, prototypes functionality is not the most convenient in usage, apart from that, Object.assign() only makes a shallow copy, so you can use existing JavaScript libraries to make mixins usage easier. "},{"title":"3.3 Writing the Concrete Code​","type":1,"pageTitle":"3. Mixins","url":"docs/building-blocks-of-oop-part-2/mixins#33-writing-the-concrete-code","content":"To better understand how mixins work and what they can give us we will go back to bicycles example. Let us look on the case when we need to make our bicycles schedulable, this functionality will give as an opportunity to schedule a single bicycle on a specific period. We also need to add leadDays property which will store number of days required to prepare the bicycle. Listing 3.3 class Schedule { isScheduled(schedulable, starting, ending) { console.log(`Checking if ${schedulable.constructor.name}` + `is available on ${starting} - ${ending}`); //do the checks return true; } } class Bicycle { leadDays = 1; constructor(parts, schedule = new Schedule()) { this.schedule = schedule; // ... } isSchedulable(starting, ending) { const withLeadTime = starting - this.leadDays; return this.schedule.isScheduled(this, withLeadTime, ending); } }  Figure 3.1 - Bicycle classes know if they are schedulable  Based on the result above and UML-diagram from Figure 3.1 we can say that major part of logic is stored in Schedule class, this class is used in isSchedulable method, it needs two dates, one for the start and one for the end of booking, Schedule instance receives start date with subtracted leadDays, so we will always have enough time to prepare the bicycle for a trip. Now we can schedule a bicycle, but we also have other classes like Mechanic and Driver and each of them has its own leadDays value. Extracting common logic, we can create Schedulable duck type. Figure 3.2 - Schedulable duck type  Let us review UML-diagram from Figure 3.2, we have new Schedulable instance, but relation between Bicycle and Schedulable is not IS-A, because Bicycle should not be schedulable under normal conditions. This duck type rather describes Bicycle specific behavior when it is required to be scheduled for the trip, or under specific conditions in other words. Other parts of our system should not even know that Bicycle is schedulable, these classes relations will be better to describe as BEHAVES-AS. Listing 3.4 const SchedulableMixin = (superclass) =&gt; class extends superclass { private _schedule: Schedule; protected leadDays = 0; set schedule(schedule) { this._schedule = schedule; } get schedule() { return this._schedule || new Schedule(); } isSchedulable(starting, ending) { const withLeadDays = starting - this.leadDays; return this.schedule.isScheduled(this, withLeadDays, ending); } } class Bicycle extends SchedulableMixin(Object) { protected leadDays = 1; } class Vehicle extends SchedulableMixin(Object) { protected leadDays = 3; } class Mechanic extends SchedulableMixin(Object) { protected leadDays = 4; }  We have extracted common logic to SchedulableMixin with isSchedulable method, and now we can easily mix it to any class in our hierarchy, either Bicycle, Mechanic or Driver, so we will have schedulable behavior when we only need it. In this case decorators could be used as an alternative solution, you may know about them from TypeScript, and they solve this problem in as similar manner, so mixins are not the only solution to add a behavior. The only consequence in Schedulable mixin is that we need to store leadDays property in a target class, so it can be used in mixin. "},{"title":"3.4 Mixins: Writing Inheritable Code​","type":1,"pageTitle":"3. Mixins","url":"docs/building-blocks-of-oop-part-2/mixins#34-mixins-writing-inheritable-code","content":"To better understand which consequences mixins have in general let us review the scheme from Figure 3.3. Figure 3.3 - Mixins call stack  Taking a closer look at this scheme we can notice that mixins added additional levels to the call stack, this makes understanding and debugging of the application less obvious, so you need to keep this in mind and use mixins only when they are really needed. Recognize the Antipatterns. There are two antipatterns which may indicate that you can gain a benefit from inheritance. First of them is using variables with a type/category to determine a type of object and send it a message. The second is usage of direct object type checking or switch-case operator – then you rather missed a duck type. Duck types may have not only common interface but also common behavior, which is recommended to extract to mixins.Insist on the Abstraction. All the code in an abstract superclass which should be used in every subclass, superclasses should not contain a code which is only applied for some subclasses. This limitation is also applicable to mixins, all the mixin functionality should be used in every place where it is mixed in. If you cannot identify an abstraction, then probably it is not existing, and inheritance cannot be applied to solve this problem.Honor the Contract. Subclasses must honor the contract, so they can be easily replaced with superclasses without any change in a system behavior. This means that they need to answer on the same messages receiving the same input data and returning the same result data. Thereby they cannot do something which will force a client code to check them for a type to understand what to wait from them. Subclasses which do not honor the contract cannot work synchronously thus making all the inheritance hierarchy unpredictable. This also violates Liskov Substitution Principle which you will learn about in the lecture about SOLID.Preemptively Decouple Classes. Try to avoid super method call, use template method pattern and so-called hooks instead, they give subclass a possibility to specify the common algorithm which is controlled by superclass. Remember that it is not a &quot;silver bullet&quot; and do not follow this approach blindly.Create Shallow Hierarchies (Figure 3.4). Try to create as compact hierarchies as it is possible. Shallow hierarchies are easy to understand, shallow and wide are slightly more difficult, but they still are easy to understand. Deep and narrow hierarchies tend to become wider and much difficult to understand and maintain. You should avoid deep and wide hierarchies, they create a long path to target method or property which is missing in a target class. Such hierarchies are difficult to maintain, and they create a high risk of application failure. Figure 3.4 - Hierarchies come in different shapes  "},{"title":"1. Composition","type":0,"sectionRef":"#","url":"docs/building-blocks-of-oop-part-2/composition","content":"","keywords":""},{"title":"1.1 What is the Composition​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#11-what-is-the-composition","content":"Composition is one of the fundamental concepts in object-oriented programming. It describes a class that references one or more objects of other classes in instance variables. This allows you to model a HAS-A association between objects. You can find such relationships quite regularly in the real world. A car, for example, has an engine and modern coffee machines often have an integrated grinder and a brewing unit. Each part separately may not give us significant value, a musical note, for instance, does not contain a lot of information, while using composition we can create musical composition which can give us much more information than each note separately. "},{"title":"1.2 Composition vs Inheritance​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#12-composition-vs-inheritance","content":"Comparing composition with inheritance we can say that inheritance models strong IS-A relation between classes, it means that mountain bike is-a bicycle, while composition models weaker HAS-A relation – mountain bike has-a wheel. Let us go back to the example from the previous lecture. Listing 1.1 abstract class Bicycle { protected readonly defaultChain = '11-speed'; constructor(opts) { this.style = opts.style; this.chain = opts.chain || this.defaultChain; this.tireSize = opts.tireSize || this.defaultTireSize; } spares() { return { chain: this.chain, tireSize: this.tireSize }; } } class RoadBike extends Bicycle { protected readonly defaultTireSize = '28'; constructor(opts) { super(opts); this.tapeColor = opts.tapeColor; } spares() { return { ...super.spares(), tapeColor: this.tapeColor }; } protected get defaultChain() { return '2-speed'; } } class MountainBike extends Bicycle { protected readonly defaultTireSize = '29'; constructor(opts) { super(opts); this.frontShock = opts.frontShock; } spares() { return { ...super.spares(), frontShock: this.frontShock }; } }  Currently, we have abstract class Bicycle** and two subclasses – RoadBike and MountainBike. If you need continuously extend existing functionality, you will notice that spare parts functionality may not change all the time or will require adjustments because of specific implementations of different subclasses. It becomes too difficult to extend spare parts functionality, and we will use composition to solve this problem. "},{"title":"1.3 Moving from Inheritance to Composition​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#13-moving-from-inheritance-to-composition","content":""},{"title":"1.3.1 1st Refactoring: Composing a Bicycle of Parts: Creating a Parts Hierarchy​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#131-1st-refactoring-composing-a-bicycle-of-parts-creating-a-parts-hierarchy","content":"Let us refactor current functionality, we will move spare parts to Parts class so inheritance will be replaced with composition. You can use UML diagram from Figure 1.1 to better understand what we will get after refactoring. Figure 1.1 – Bicycle asks Parts for spares and Bicycle has a Parts  Listing 1.2 abstract class Parts { protected chain: string; protected tireSize: string; constructor(opts) { this.chain = opts.chain || this.defaultChain; this.tireSize = opts.tireSize || this.defaultTireSize; this.postInitialize(opts); } spares() { return { chain: this.chain, tireSize: this.tireSize, ...this.localSpares }; } protected abstract get localSpares(); protected abstract get defaultTireSize(); protected get defaultChain() { return '11-speed'; } protected postInitialize(opts) {}; }  Now we have separate Parts class with all the spares functionality encapsulated inside it. With new approach Bicycle type depends on provided parts, when you call spares method inside Bicycle it is delegated to Parts instance, and it decides which exact parts to return. Listing 1.3 class RoadBikeParts extends Parts { private tapeColor: string; postInitialize(opts) { this.tapeColor = opts.tapeColor; } protected get localSpares() { return { tapeColor: this.tapeColor }; } protected get defaultTireSize() { return '28'; } } class MountainBikeParts extends Parts { private frontShock: string; constructor(opts) { super(opts); this.frontShock = opts.frontShock; } protected get localSpares() { return { frontShock: this.frontShock }; } protected get defaultTireSize() { return '29'; } }  After refactoring you need to pass bicycle size and Parts instance to create a new Bicycle, you can see it on example below: Listing 1.4 const roadBike = new Bicycle( {size: 'M'}, new RoadBikeParts({tapeColor: 'red'}) ); const mountainBike = new Bicycle( {size: 'M'}, new MountainBikeParts({frontShock: 'manitou'}) );  Now Bicycle class is only responsible for its size and for which parts it can consume. "},{"title":"1.3.2 2nd Refactoring: Composing a Bicycle of Parts: Creating a Part​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#132-2nd-refactoring-composing-a-bicycle-of-parts-creating-a-part","content":"But it is not a result, let us continue the refactoring and adjust Parts class to make it look like typed collection. After refactoring our classes structure will look like on UML-diagram below: Figure 1.2 – Bicycle, Parts and Part relations  Listing 1.5 class Bicycle { constructor(private size: string, private parts: Parts) {} spares() { return this.parts.spares(); } } class Parts { constructor(private parts: Part[]) {} spares() { return this.parts .filter(({needsSpare}) =&gt; needsSpare) .reduce((spares, {name, value}) =&gt; ({ ...spares, [name]: value })); } } class Part { constructor( public name: string, public value: string, public needsSpare = true ) {} }  Now we have three main classes: Bicycle class is the same as before the refactoring, Parts class composes separate Part instances, on diagram it is showed as &quot;one-to-many&quot; relation between Parts and Part classes. With new approach, theoretically, we can just skip Parts class and just put typed collection directly inside the Bicycle class, but we have more than just a collection, we have some additional logic which is related to Parts functionality. Each Part instance has needsSpare property which indicates if we need to take a spare for this instance of Part. If we take a closer look on the MountainBike, we will see that it may have rear shock, but we do not need a spare for it. This is logic which Parts class contains, without this part of functionality, we may choose the option described above. Below you can see an example how to use new approach. Listing 1.6 const roadBike = new Bicycle( 'M', new Parts([ new Part('chain', '11-speed'), new Part('tireSize', '28'), new Part('tapeColor', 'red') ]) ); const mountainBike = new Bicycle( 'L', new Parts([ new Part('chain', '11-speed'), new Part('tireSize', '29'), new Part('readShock', 'fox', false), new Part('frontShock', 'manitou') ]) );  "},{"title":"1.3.3 3rd Refactoring: Composing a Bicycle of Parts: Creating a Part Factory​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#133-3rd-refactoring-composing-a-bicycle-of-parts-creating-a-part-factory","content":"The next step will help us to further adjust Parts creation, as we can use Factory pattern to unify parts creation. On the one hand, this will help us to simplify new Bicycle instances creation, but on the other hand, we need to understand that if some functionality will be changed or extended, this may require us to review our abstraction or design pattern. In the current case, Factory can encapsulate all the Parts creation inside, so it will look like on example below: Listing 1.7 const roadConfig = new Set([ ['chain', '11-speed'], ['tireSize', '28'], ['tapeColor', 'red'] ]); const mountainConfig = new Set([ ['chain', '11-speed'], ['tireSize', '29'], ['readShock', 'fox', true], ['frontShock', 'manitou'] ]); PartsFactory.build(roadConfig); PartsFactory.build(mountainConfig);  "},{"title":"1.4 Composition: Accepting the Consequences of Inheritance​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#14-composition-accepting-the-consequences-of-inheritance","content":"info &quot;Inheritance is specialization.&quot; — Bertrand Meyer, Touch of Class: Learning to Program Well with Objects and Contracts. &quot;Inheritance is best suited to adding functionally to existing classes when you will use most of the old code and add relatively small amounts of new code.&quot; — Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, Design Patterns: Elements of Reusable Object-Oriented Software "},{"title":"1.4.1 Benefits of Inheritance​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#141-benefits-of-inheritance","content":"Use of inheritance results in code that can be described as open-closed; hierarchies are open for extension while remaining closed for modification.Correctly written hierarchies are easy to extend. The hierarchy embodies the abstraction and every new subclass plugs in a few concrete differences. The existing pattern is easy to follow and replicating. Hierarchies by their nature provide guidance for writing the code to extend them.Use Inheritance for IS-A Relationships "},{"title":"1.4.2 Cons of Inheritance​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#142-cons-of-inheritance","content":"Choosing inheritance to solve the wrong kind of problem.High cost of making changes near the top of an incorrectly modeled hierarchy. In this case, the leveraging effect works to your disadvantage; small changes break everything.Impossibility of adding behavior when new subclasses represent a mixture of types. "},{"title":"1.5 Composition: Accepting the Consequences of Composition​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#15-composition-accepting-the-consequences-of-composition","content":"info &quot;Use composition when the behavior is more than the sum of its parts.&quot; — paraphrase of Grady Booch, Object-Oriented Analysis and Design "},{"title":"1.5.1 Benefits of Composition​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#151-benefits-of-composition","content":"When using composition, the natural tendency is to create many small objects that contain straightforward responsibilities that are accessible through clearly defined interfaces.These small objects have a single responsibility and specify their own behavior. They are transparent; it is easy to understand the code, and it is clear what will happen if it changes.Because composed objects deal with their parts via an interface, adding a new kind of part is a simple matter of plugging in a new object that honors the interface.Use Composition for has-a Relationships. "},{"title":"1.5.2 Cons of Composition​","type":1,"pageTitle":"1. Composition","url":"docs/building-blocks-of-oop-part-2/composition#152-cons-of-composition","content":"A composed object relies on its many parts. Even if each part is small and easily understood, the combined operation of the whole may be less than obvious.The benefits of structural independence are gained at the cost of automatic message delegation. The composed object must explicitly know which messages to delegate and to whom.As these costs and benefits illustrate, composition is excellent at prescribing rules for assembling an object made of parts but does not provide as much help for the problem of arranging code for a collection of parts that are very nearly identical. "},{"title":"4. Functional programing in JS","type":0,"sectionRef":"#","url":"docs/functional-programming/is_js_functional","content":"","keywords":""},{"title":"4.1 Functional concepts in JS​","type":1,"pageTitle":"4. Functional programing in JS","url":"docs/functional-programming/is_js_functional#41-functional-concepts-in-js","content":"Based on the concepts of FP let's see if we can say that JS is implementing a functional programming paradigm. The first concept is immutability - JavaScript has built-in methods which follow this rule. For example, filter, reduce, map. For more information you can check JS Array methods. Listing 4.1 - Array mutation const fruit = [&quot;banana&quot;, &quot;orange&quot;]; fruit.push(&quot;kiwi&quot;); console.log(fruit); // [&quot;banana&quot;, &quot;orange&quot;, &quot;kiwi&quot;]  Not a functional approach In the Listing 4.1 array of fruit was mutated by adding new fruit to it. Listing 4.2 - immutable Array const fruit = [&quot;banana&quot;, &quot;orange&quot;]; const newFruit = [...fruit, &quot;kiwi&quot;]; console.log(fruit); // [&quot;banana&quot;, &quot;orange&quot;] console.log(newFruit); // [&quot;banana&quot;, &quot;orange&quot;, &quot;kiwi&quot;]  Functional approach In Listing 4.2 it is obvious that we do not mutate the original array (Immutability). So there is a possibility in JavaScript to follow the immutability principle. The second concept is No shared state In order to avoid a shared state in JS, you can use such a library like Redux, any other similar library, or all suggested approaches in the How to avoid shared state part could be used. You might already notice that all of these principles could be applied in JS. The third concept is Composition. The main idea of inheritance is to make code more reusable. With the functional way, as was mentioned before in Composition part we can do it without inheritance by using the composition of small functions. It has some advantages over inheritance - it is more flexible, does not require thinking in advance, and is easier to test. "},{"title":"4.2 Functional possibilities in JS​","type":1,"pageTitle":"4. Functional programing in JS","url":"docs/functional-programming/is_js_functional#42-functional-possibilities-in-js","content":"What about language possibilities? First class function is implemented in JS, so we can use it for our purpose. Listing 4.3 - functions are called one by one const foo = (a, b) =&gt; a + b; const buzz = (c) =&gt; console.log(c); const res = foo(4, 5); buzz(res); // 9  Not a functional approach In the Listing 4.3 there are two functions, foo adds two numbers, and buzz logs the input value in the console. In this case, in order to log the result in the console, we create the additional variable res which contains the result of foo and the pass res as an argument in the buzz. Listing 4.4 - passing function as an argument const foo = (a, b) =&gt; a + b; const buzz = (c) =&gt; console.log(c); buzz(foo(4, 5)); // 9  Functional approach In the Listing 4.4 there are two functions, foo adds two numbers, and buzz logs the input value in the console. In this case, in order to log the result in the console, we pass foo called with the arguments in the buzz. This code will be executed in the next order: foo will be executed with 4, 5result of execution foo will be passed to the buzz as a parameter In Listing 4.4, there is an implementation of how a function can be passed as a parameter to another function, and that is definitely a possibility of functional language. Currying is a technique that has to be supported in the language. So functions with more than one argument can be divided into several functions with one argument. The part Currying tells in detail about supporting this possibility in JavaScript. Conclusion: it might look like JS is a strict functional programming language, because it follows all functional rules. However, JS includes some OOP principles as well. Such as inheritance. So, it will not be completely right to say that it is a functional programming language. It is rather both. So we can combine the best features of both approaches in order to achieve good results. "},{"title":"4.3 Widespread functional JS libraries​","type":1,"pageTitle":"4. Functional programing in JS","url":"docs/functional-programming/is_js_functional#43-widespread-functional-js-libraries","content":""},{"title":"4.3.1 Ramda​","type":1,"pageTitle":"4. Functional programing in JS","url":"docs/functional-programming/is_js_functional#431-ramda","content":"The library is designed specifically for a functional programming style, one that makes it easy to create functional pipelines, one that never mutates user data. Ramda includes all of the favorite list-manipulation functions you expect, e.g. map, filter, reduce, find, etc. Ramda methods are automatically curried. For example, Listing 4.5. The function multiply returns another function, remembers the first arguments, and multiplies the first argument with the second one. Listing 4.5 - curried multiplication const double = R.multiply(2); double(3); // 6  In order to run Listing 4.5 open Try ramda More info - Ramda "},{"title":"4.3.2 Lodash​","type":1,"pageTitle":"4. Functional programing in JS","url":"docs/functional-programming/is_js_functional#432-lodash","content":"The lodash/fp module promotes more functional programming (FP) friendly style by exporting an instance of lodash with its methods wrapped to produce immutable auto-curried iteratee-first data-last methods. Lodash makes JavaScript easier by taking the hassle out of working with arrays, numbers, objects, strings, etc. Lodash modular methods are great for: Iterating arrays, objects, &amp; stringsManipulating &amp; testing valuesCreating composite functions Listing 4.6 - array filtering var users = [ { user: &quot;barney&quot;, age: 36, active: true }, { user: &quot;fred&quot;, age: 40, active: false }, ]; _.filter(users, function (o) { return !o.active; }); // [{ user: &quot;fred&quot;, age: 40, active: false }]  In order to run Listing 4.6 open lodash docs and press the Try in PERL button on any code example. More info - Lodash "},{"title":"4.3.3 React​","type":1,"pageTitle":"4. Functional programing in JS","url":"docs/functional-programming/is_js_functional#433-react","content":"As you know, React is one of the most popular JavaScript libraries to create Web user interfaces. Its success is due to several factors, but maybe one of them is the clean and effective approach to programming. In the React environment, every piece of a UI is a component. Components can be composed together to create other components. The application itself is a component: a composition of components. For example, Listing 4.7. The task is to create a user form. Listing 4.7 - user form const Input = (props) =&gt; { const { value } = props; return ( &lt;div&gt; &lt;input&gt;&lt;/input&gt; {value} &lt;/div&gt; ); }; const Button = () =&gt; { return &lt;button&gt; Click me! &lt;/button&gt;; }; const Main = () =&gt; { return ( &lt;&gt; &lt;Input value=&quot;Name&quot; /&gt; &lt;Input value=&quot;Last Name&quot; /&gt; &lt;Input value=&quot;email&quot; /&gt; &lt;Button /&gt; &lt;/&gt; ); }; // ReactDOM.render( // &lt;Main /&gt;, // document.getElementById('root') // );  Figure 4.1 - Listing 4.7 result  In the code above, there are three components Input, Button, and Main. By composing components in the Main component a variety of screens can be created. For example, in order to create different types of Imput the props have to be passed instead of creating three different Input elements. It is pretty reusable. There are two ways how to run this code: to use configured code pan that supports babel and react.to run npx create-react-app locally. In both cases commented code should be uncommented. More info - React "},{"title":"4.4 Pros and Cons of FP​","type":1,"pageTitle":"4. Functional programing in JS","url":"docs/functional-programming/is_js_functional#44-pros-and-cons-of-fp","content":"Pros No side effects (if they are not necessary) - because we are following the immutability principle.Pure functions are easier to understand because they depend only on the given input and don't change any states. With the same input, they always give the same output. Their function signature gives all the information about them.The ability of functional programming languages to treat functions as values and pass them to functions as parameters make the code more readable and easily understandable.Testing and debugging are easier. Since pure functions take only arguments and produce output, they don't produce any changes don't take input, or produce some hidden output. They use immutable values, so it becomes easier to check some problems in programs written using pure functions.It is used to implement concurrency/parallelism because pure functions don't change variables or any other data outside it.It adopts lazy evaluation which avoids repeated evaluation because the value is evaluated and stored only when it is needed. CONS The readability can be reduced by a lot of pure functions.Loss of performance could take place, because of the immutability principle. "},{"title":"📍 Help","type":0,"sectionRef":"#","url":"docs/Introduction/help","content":"","keywords":""},{"title":"How to Study the Course​","type":1,"pageTitle":"📍 Help","url":"docs/Introduction/help#how-to-study-the-course","content":"The course is developed as single application on top of Docusaurus. It is expected to be cloned from the repository and studied on your local machine. Follow the steps in the project description to start studying the course. In case when you are not able to access the repository for any reason you can use the attached archive. "},{"title":"Communication Channels​","type":1,"pageTitle":"📍 Help","url":"docs/Introduction/help#communication-channels","content":"Please, if you need any assistance, keep in mind that any questions or issues regarding technical implementation related to the framework that may occur while studying program materials/ doing homework should be addressed via MS Teams to JS CC – Questions and Answers Channel.all the questions of technical or administrative nature (issues with Learn, deadlines, mentor-mentee cooperation) should be asked via MS Teams in JS EDU L&amp;D-Software Designs and Algorithms Channel. NB! No organizational questions should be addressed to JS CC Teams channel! "},{"title":"2. Functional language possibilities","type":0,"sectionRef":"#","url":"docs/functional-programming/language_possibilities","content":"","keywords":""},{"title":"2.1 First class functions​","type":1,"pageTitle":"2. Functional language possibilities","url":"docs/functional-programming/language_possibilities#21-first-class-functions","content":"In computer science, they say that a programming language supports first-class functions if it treats functions as first-class citizens. In simple words, language supports first-class functions if it can pass functions as parameters to other functions, can return them as values from other functions, and can assign them to variables or can store them in data structures. Examples: In Listing 2.2 line(1) you can see, that function is assigned to consoleValueIn the Listing 2.2 line(2) function logFn returns as a value from logPowerOfTwoIn the Listing 2.2 line(3) consoleValue is passed as a parameter while calling logPowerOfTwo Listing 2.1 - Example of storing function in object data structure const example = { name: &quot;John&quot;, getName() { return console.log(this.name); }, };  It is important to remember that the language must implement the feature passing function as a parameter. It is not a functional concept, and it is a language possibility. By using this feature we can follow another functional concept such as higher order function (HOF). "},{"title":"2.1.1 Higher order function​","type":1,"pageTitle":"2. Functional language possibilities","url":"docs/functional-programming/language_possibilities#211-higher-order-function","content":"A higher order function is any function that takes a function as an argument, returns a function, or both. Higher order functions are often used to: Abstract or isolate actions, effects, or async flow control using callback functions, promises, monads, etcCreate utilities that can act on a wide variety of data typesPartially apply a function to its arguments or create a curried function for the purpose of reuse or function compositionTake a list of functions and return some composition of those input functions Listing 2.2 const consoleValue = (value) =&gt; console.log(value); // (1) const logPowerOfTwo = (logFn, value) =&gt; logFn(value * value); // (2) logPowerOfTwo(consoleValue, 5); // 25 (3)  Each JavaScript function that takes a callback is a HOF. For example, map, filter, forEach etc. "},{"title":"2.2 Currying​","type":1,"pageTitle":"2. Functional language possibilities","url":"docs/functional-programming/language_possibilities#22-currying","content":"Currying is a technique that converts function with more than one parameter into the chain of functions with one argument. In a math way - it is a process of transforming function with multiple arities in functions with less (usually one) arity. Arity - number of function's arguments. For example, currying a function foo that takes three arguments creates three functions. Usual syntax Listing 2.3 const foo = (a, b, c) =&gt; a + b + c; foo(1, 2, 3); // 6  Currying Listing 2.4 - Based on arrow functions const curryingSum = (a) =&gt; (b) =&gt; (c) =&gt; a + b + c; curryingSum(1)(2)(3); // 6  Listing 2.5 - Based on regular functions const curryingSum = function (a) { return function (b) { return function (c) { return a + b + c; }; }; }; curryingSum(1)(2)(3); // 6  Currying is not something that you have to use every time, it is something that is useful in certain situations. For example, if you need to call the same function with some of the same parameters a lot. This function can be divided into smaller ones and some of them can be called when needed. "},{"title":"5. 📚 Home Task","type":0,"sectionRef":"#","url":"docs/functional-programming/hometask","content":"","keywords":""},{"title":"Start the project​","type":1,"pageTitle":"5. 📚 Home Task","url":"docs/functional-programming/hometask#start-the-project","content":"In the project directory, run command bellow to install all required packages:  npm install  To run the app in the development mode use the following command:  npm start  Open http://localhost:3000 to view it in your browser. The page will reload when you make changes. You may also see any lint errors in the console. "},{"title":"Task​","type":1,"pageTitle":"5. 📚 Home Task","url":"docs/functional-programming/hometask#task","content":"Imagine that you work on the game server, and you need to display some statistics on the UI. In order to do it, you need to get some data from the backend and then show it on the UI. The backend work is already done, and you have three requests with the needed data. On UI, you already have implemented components so what you need is to pass data from API to the component and implement some business logic.  "},{"title":"Input parameters​","type":1,"pageTitle":"5. 📚 Home Task","url":"docs/functional-programming/hometask#input-parameters","content":"getImages - returns array of images (Image[]). interface Image { userID: string; url: string; }  getUsers - returns array of users (User[]). interface User { userID: string; username: string; country: string; name: string; }  getAccounts - returns array of accounts (Account[]). interface Payment { totalSum: number; date: string; } interface Account { userID: string; posts: number; payments: Payment[]; }  The table takes the next array of rows as a parameter (Row[]): interface Row { avatar: string; username: string; country: string; name: string; lastPeyments: number; posts: number; }  "},{"title":"Requirements​","type":1,"pageTitle":"5. 📚 Home Task","url":"docs/functional-programming/hometask#requirements","content":"You need to implement: The first part is to implement is a data converter. Like in real life there are three REST API endpoints and each returns an array of objects. On the UI all the received data should be displayed in one table (it is already implemented). However, the table takes one array with the objects (rows). So it is necessary to convert three arrays into one. The response models are provided above. The next transformation should be done: const dataConverter = ( users: User[], accounts: Account[], images: Image[] ): Rows[] =&gt; { // convert data return rows; }; The second part is to implement some business logic on the page. In the future, we will have a lot of data in the table, so it would be hard to find something in there. That is why we need to have a possibility to sort, filter, and search on the page. Sort, Search and Filter have to work as OR. For example, if the More than 100 posts filter is active, and you type SWEDEN in the Search input, the result will be MIKE and Luke123. if Without posts and More than 100 posts filters are chosen and Sweden is typed in Search input, the result will be Lora123, Luke123 and MIKE. if Without posts and More than 100 posts filters are active, Sweden is typed in Search input and desc is selected sorting, the result will be MIKE, Luke123, Lora123. "},{"title":"Specific instructions​","type":1,"pageTitle":"5. 📚 Home Task","url":"docs/functional-programming/hometask#specific-instructions","content":"Search is not case-sensitive. All the options are valid: SWEDEN, sweden and Sweden.The main idea is to follow functional programming principles, such as immutability, avoiding side effects, using a pure function, no shared state, using higher-order components, currying, composition. "},{"title":"Evaluation Criteria​","type":1,"pageTitle":"5. 📚 Home Task","url":"docs/functional-programming/hometask#evaluation-criteria","content":"All tasks are implemented partially, or one task is not implemented at all.Two tasks have major issues or functional principles are not followed at all.One of the tasks does not have a major part of its implementation.All tasks are implemented to a full extend and functional principles are followed. "},{"title":"2. Creational Design Patterns","type":0,"sectionRef":"#","url":"docs/design-patterns/creational_design_patterns","content":"","keywords":""},{"title":"2.1 Abstract Factory​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#21-abstract-factory","content":"The Abstract Factory or in simple words – factory of factories. It provides you an interface for creating objects for each class of the product family. As long as your code creates objects via this interface, you don't have to worry about creating the wrong variant of a product which doesn't match the products already created by your app. "},{"title":"2.1.1 Abstract Factory Structure​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#211-abstract-factory-structure","content":"Figure 2.1 - Abstract Factory  Abstract Products declare interfaces for a set of distinct but related products which make up a product family as chair or sofa.Concrete Products are various implementations of abstract products, grouped by variants. In this case we implement each abstract product (chair or sofa) in all given variants (Victorian or Modern).The Abstract Factory interface declares a set of methods for creating each of the abstract products.Concrete Factories implement creation methods of the abstract factory. Each concrete factory creates only those product variants, that corresponds to a specific variant of products.Signatures of concrete factories' creation methods must return corresponding abstract products. In this case the client code that uses a factory doesn't get coupled to the specific variant of the product. The Client can work with any concrete factory/product variant, as long as it communicates with their objects via abstract interfaces. "},{"title":"2.1.2 Abstract Factory Example​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#212-abstract-factory-example","content":"Here we have 2 kinds of products: door and door fitting master for each type of doors. Listing 2.1 interface Door { getDescription(); } class WoodenDoor implements Door { public getDescription() { return 'I am a wooden door'; } } class IronDoor implements Door { public getDescription() { return 'I am a iron door'; } } interface DoorFittingExpert { getDescription(); } class Welder implements DoorFittingExpert { public getDescription() { return 'I can only fit iron doors'; } } class Carpenter implements DoorFittingExpert { public getDescription() { return 'I can only fit wooden doors'; } }  We declare abstract and concrete products. Next, our abstract factory that would allow us to create a family of related objects: wooden door and a carpenter from wooden door factoryiron door and a welder from iron door factory As you can see, the wooden doors' factory contains carpenter's creation and a wooden door, and iron doors' factory contains an iron door and a welder Listing 2.2 interface DoorFactory { makeDoor(): Door; makeFittingExpert(): DoorFittingExpert; } class WoodenDoorFactory implements DoorFactory { public makeDoor(): Door { return new WoodenDoor(); } public makeFittingExpert(): DoorFittingExpert { return new Carpenter(); } } class IronDoorFactory implements DoorFactory { public makeDoor(): Door { return new IronDoor(); } public makeFittingExpert(): DoorFittingExpert { return new Welder(); } }  In this case we make sure, that a client who would use a door factory will get a proper specialist for each of the created doors. "},{"title":"2.1.3 When to Apply, Pros and Cons​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#213-when-to-apply-pros-and-cons","content":"We should get benefits from usage of the Abstract Factory while working with various families of related products. In this case we are removing the dependency on concrete classes of these products and allowing future extensibility. The abstract factory encapsulates the details of object creation. But client code can still work with all types of created objects, since their interface is initially defined. Pros ensures compatibility of productsgets rid of couplingextracts the product creation code into one place. (Single responsibility)introducing new variants without breaking existing code. (Open/Closed) Cons code becomes more complicated after introducing lots of new interfacesafter extending abstract factory interface all concrete factories will need to be updated to implement it "},{"title":"2.2 Singleton​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#22-singleton","content":"Singleton is a creational pattern, which means, that the class has only one instance, and it is accessible from any part of application. "},{"title":"2.2.1 Singleton Structure​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#221-singleton-structure","content":"Figure 2.2 - Singleton  Singleton defines static method getInstance(), which returns the only instance of its class. The constructor of singleton should be hidden from client code. Calling the getInstance() method should be the only way of getting the Singleton object. In other words, the Singleton pattern disables all other means of creating objects of a class except for the special creation method. This method either creates a new object or returns an existing one if it has already been created. Singleton solves two tasks at a time, which violates the single responsibility principle. guarantees the existence of single instance of class. It is often useful for accessing common resource, e.g., a databaseprovide a global access point to that instance "},{"title":"2.2.2 Singleton Example​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#222-singleton-example","content":"All implementations of the Singleton in general do the same – they make default constructor private and create public static method, which controls the lifecycle of singleton object. Under the hood, this method calls the private constructor to create an object and saves it in a static field. All following calls to this method return the saved object. Listing 2.3 class President { private static president: President; private constructor() {} public static getInstance(): President { if (!President.president) { President.president = new President(); } return President.president; } } const president1 = President.getInstance(); const president2 = President.getInstance(); president1 === president2 // true  The President is an excellent example of the Singleton pattern. This class doesn't have a public constructor, so the only way to get its instance – is call getInstance() method. This method saves the first created object and will return it in further calls. "},{"title":"2.2.3 When to Apply, Pros and Cons​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#223-when-to-apply-pros-and-cons","content":"if a class in your program should have just a single instance available to all clients; for example, a single database object shared by different parts of the programif you need stricter control over global variables Pros you can be sure that a class has only a single instanceyou gain a global access point to that instancethe singleton object is initialized only when it's requested for the first time Cons violates the Single Responsibility Principlepattern can hide bad designrequires special handling in a multithreaded environmentyou will need to think of a creative way to mock the singleton  "},{"title":"2.3 Builder​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#23-builder","content":"Builder is a creational design pattern that lets you construct complex objects step by step. The pattern allows you to produce different types and representations of an object using the same construction code. In other words: Builder pattern allows creating different parts of object, avoiding overload of constructor. Builder pattern can be used, when object should be built with several parts, or if objects creation takes lots of steps and each of these steps should be configurable. Think of it as dividing an object creation into several steps with different parameters. "},{"title":"2.3.1 Builder Structure​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#231-builder-structure","content":"Imagine a complex object that requires step-by-step initialization of many fields and nested objects. Such initialization code is usually buried inside a huge constructor with lots of parameters. Often most of the parameters will be unused, making the constructor calls ugly. The Builder pattern suggests you extract the object construction code out of its own class and move it to separate objects called builders. The pattern organizes object construction into a set of steps. To create an object, you execute a series of these steps on a builder object. The important part is that you do not need to call all the steps at a time. You can call only those steps that are necessary for producing a particular configuration of an object. You can go further and extract a series of calls to the builder steps to construct a product into a separate class called director. The director class defines the order in which to execute the building steps, while the builder provides the implementation for those steps. Having a director class in your program is not necessary. You can always call the building steps in a specific order directly from the client code. Figure 2.3 - Builder  The Builder interface declares product construction steps that are common to all types of builders.Concrete Builders provide different implementations of the construction steps. Concrete builders may produce products that do not follow the common interface.Products are resulting objects. Products constructed by different builders do not have to belong to the same class hierarchy or interface.The Director class defines the order in which to call construction steps, so you can create and reuse specific configurations of products.The Client must associate one of the builder objects with the director. Usually, it is done just once, via parameters of the director's constructor. Then the director uses that builder object for all further construction. However, there is an alternative approach when the client passes the builder object to the production method of the director. In this case, you can use a different builder each time you produce something with the director. "},{"title":"2.3.2 Builder Example​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#232-builder-example","content":"This example of the Builder pattern illustrates how you can reuse the same object construction code when building diverse types of products, such as cars, and create the corresponding manuals for them. Listing 2.4 class Car {} interface Builder { reset(); setSeats(n: Number); setEngine(n: String); setTripComputer(n: Boolean); setGPS(n: Boolean); } class CarBuilder implements Builder { private car: Car; constructor() { this.reset(); } reset() { this.car = new Car(); } setSeats() {} setEngine() {} setTripComputer() {} setGPS() {} getProduct(): Car { const product = this.car; this.reset(); return product; } }  A car is a complex object that can be constructed in a hundred diverse ways. Instead of bloating the Car class with a huge constructor, we extract the car assembly code into a separate car builder class. This class has a set of methods for configuring various parts of a car. Listing 2.5 class Director { private builder: Builder; setBuilder(b: Builder) { this.builder = b; } makeSportCar(b: Builder = this.builder) { b.reset(); b.setSeats(2); b.setEngine('V12'); b.setTripComputer(true); b.setGPS(true); } } const director = new Director(); const builder = new CarBuilder(); director.makeSportCar(builder);  If the client code needs to assemble a special, fine-tuned model of a car, it can work with the builder directly. On the other hand, the client can delegate the assembly to the Director class, which knows how to use a builder to construct several of the most popular models of cars. "},{"title":"2.3.3 When to Apply, Pros and Cons​","type":1,"pageTitle":"2. Creational Design Patterns","url":"docs/design-patterns/creational_design_patterns#233-when-to-apply-pros-and-cons","content":"to get rid of a &quot;telescopic constructor&quot; – the pattern lets you build objects step by step, using only those steps that you really need. After implementing the pattern, you do not have to cram dozens of parameters into your constructors anymoreto construct complex objects – a builder does not expose the unfinished product while running construction steps. This prevents the client code from fetching an incomplete result Pros constructing objects step-by-step, defer construction steps or run steps recursivelyreusing the same construction code when building various representations of productsisolating complex construction code from the business logic of the product Cons increases complexity of the code since the pattern requires creating multiple new classesclient will be bound to concrete builder classes, since builders interface does not have a method for fetching the result of the construction "},{"title":"🛠 Importance of TypeScript knowledge for the course","type":0,"sectionRef":"#","url":"docs/Introduction/importance-of-TypeScript-knowledge","content":"🛠 Importance of TypeScript knowledge for the course There is an expectation that participants of the course know TypeScript on the basic level. Almost all code snippets presented in the course are written in TypeScript. So, why is TypeScript important for the course? Exploring OOP and design patterns the following keywords are usually mentioned: abstraction, types, interfaces, access modifiers, abstract Classes and Members, etc. OOP and design patterns originate from the typed programming languages. JavaScript is not like that and does not have full coverage for the keywords at the moment. While it is possible to, sort of, implement them using JavaScript flexibility, it will look hacky, and it is not recommended for usage in production. On the other hand, TypeScript was built specifically to provide the support for mentioned things and much more. And TypeScript becomes more used and popular from year to year. Feel free to explore the provided links and if you would like to know more about TypeScript consider applying for dedicated courses on learn portal.","keywords":""},{"title":"✋ Intro","type":0,"sectionRef":"#","url":"docs/Introduction/intro","content":"","keywords":""},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"✋ Intro","url":"docs/Introduction/intro#roles-and-responsibilities","content":""},{"title":"❗️❗️ Curator​","type":1,"pageTitle":"✋ Intro","url":"docs/Introduction/intro#️️-curator","content":"mentoring program process ownerfind mentors, form the groupstrack the progress "},{"title":"❗️❗️ Mentor​","type":1,"pageTitle":"✋ Intro","url":"docs/Introduction/intro#️️-mentor","content":""},{"title":"Learn instruction Mentor​","type":1,"pageTitle":"✋ Intro","url":"docs/Introduction/intro#learn-instruction-mentor","content":"motivated to spend personal time for educationconduct sessions with group to answer questions, show best solution of the HT, discuss common mistakescheck the Home taskcover questions in Teams chatsshare hands on experience "},{"title":"❗️❗️ Mentee is a person whose expertise will be developed.​","type":1,"pageTitle":"✋ Intro","url":"docs/Introduction/intro#️️-mentee-is-a-person-whose-expertise-will-be-developed","content":""},{"title":"Learn instruction Mentee​","type":1,"pageTitle":"✋ Intro","url":"docs/Introduction/intro#learn-instruction-mentee","content":"motivated to spend personal time for educationstudy self-learning theoretical materialdo the Home Taskprepare questions before the Q&amp;A sessions and write them in Wiki tab ask questions in Teams chat answer the questions in Teams chat Important! In case Mentee misses 3 or more deadlines for assigned modules - Mentee can be expelled from the program warning All home tasks have to be done in the mentee’s personal GitHub/GitLab "},{"title":"3. Anti SOLID","type":0,"sectionRef":"#","url":"docs/solid-principles/anti_solid","content":"3. Anti SOLID Let us summarize all the information we got about SOLID principles and talk about anti SOLID behavior that you might have faced. Anti-SRP - &quot;Blurred&quot; responsibility principle: classes are split into many small classes, resulting in logic being spread across multiple classes and/or modules.Anti-OCP - Factory-Factory Principle. The design is too general and extensible, with too many levels of abstraction.Anti-LSP - The principle of unclear inheritance: either an excessive amount of inheritance, or in its complete absence.Anti-ISP - Thousand Interface Principle. Class interfaces are fragmented into too many pieces, making them awkward for all clients to use.Anti-DIP - &quot;DI-brain&quot; Principle. Interfaces are allocated for each class and passed in batches through constructors. It becomes almost impossible to understand where the logic is.","keywords":""},{"title":"4. Conclusion","type":0,"sectionRef":"#","url":"docs/solid-principles/conclusion","content":"4. Conclusion In this lesson you have learnt about SOLID principles that are commonly used in development and software design. These are 5 essential principles used by software engineers all around the globe, and if you are serious about creating solid software, you should start applying these principles today!","keywords":""},{"title":"3. Structural Design Patterns","type":0,"sectionRef":"#","url":"docs/design-patterns/structural_design_patterns","content":"","keywords":""},{"title":"3.1 Façade​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#31-façade","content":"Facade is a structural design pattern that provides a simplified interface to a library, a framework, or any other complex set of classes. "},{"title":"3.1.1 Façade structure​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#311-façade-structure","content":"A facade is a class that provides a simple interface to a complex subsystem which contains lots of moving parts. A facade might provide limited functionality in comparison to working with the subsystem directly. However, it includes only those features that clients really care about. For instance, an app that uploads short funny videos with cats to social media could potentially use a professional video conversion library. However, all that it really needs is a class with the single method encode(filename, format). After creating such a class and connecting it with the video conversion library, you will have your first facade. When you call a shop to place a phone order, an operator is your facade to all services and departments of the shop. The operator provides you a simple voice interface to the ordering system, payment gateways, and various delivery services. Figure 3.1 - Façade  The Facade provides convenient access to a particular part of the subsystem's functionality. It knows where to direct the client's request and how to operate all the moving parts.An Additional Facade class can be created to prevent polluting a single facade with unrelated features that might make it yet another complex structure. Additional facades can be used by both clients and other facades.The Complex Subsystem consists of dozens of various objects. To make them all do something meaningful, you have to dive deep into the subsystem's implementation details, such as initializing objects in the correct order and supplying them with data in the proper format. Subsystem classes aren't aware of the facade's existence. They operate within the system and work with each other directly.The Client uses the facade instead of calling the subsystem objects directly. "},{"title":"3.1.2 Façade example​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#312-façade-example","content":"Here we have a Computer class with lots of unclear methods. Listing 3.1 class Computer { public getElectricShock() { return 'Ouch!'; } public makeSound() { return 'Beep beep!'; } public showLoadingScreen() { return 'Loading..'; } public bam() { return 'Ready to be used!'; } public closeEverything() { return 'Zzzzzz bup'; } public sooth() { return 'shhshh'; } }  And a façade with 2 straightforward methods turnOn and turnOff. Listing 3.2 class ComputerFacade { constructor(protected computer: Computer) { } public turnOn() { this.computer.getElectricShock(); this.computer.makeSound(); this.computer.showLoadingScreen(); this.computer.bam(); } public turnOff() { this.computer.closeEverything(); this.computer.sooth(); } } const computer = new ComputerFacade(new Computer()); computer.turnOn(); computer.turnOff();  "},{"title":"3.1.3 When to apply, pros and cons​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#313-when-to-apply-pros-and-cons","content":"when need a limited but straightforward interface to a complex subsystemto structure a subsystem into layers: create facades to define entry points to each level of a subsystem. You can reduce coupling between multiple subsystems by requiring them to communicate only through facades Pros you can isolate your code from the complexity of a subsystem Cons a facade can become a god object coupled to all classes of an app "},{"title":"3.2 Decorator​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#32-decorator","content":"Decorator is a structural design pattern that lets you attach new behaviors to objects by placing these objects inside special wrapper objects that contain the behaviors. "},{"title":"3.2.1 Decorator structure​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#321-decorator-structure","content":"Imagine you are developing a coffee brewing system. Initially only black coffee brewing is required. Then single black coffee option become not enough. Now you need to implement white coffee and black with cream. Therefore, you reasonably made a Coffee abstract class and implemented it in black, white and black with cream classes. Soon you got request for a white coffee with cream and for coffees with different amount of sugar. Thus, you came to the point, that inheritance is not the case. Extending a class is the first thing that comes to mind when you need to alter an object's behavior. However, inheritance has several serious caveats that you need to be aware of: it is static, and it does not let a class inherit behaviors of multiple classes at the same time. So, apparently, we need a composition here. &quot;Wrapper&quot; is the alternative nickname for the Decorator pattern that clearly expresses the main idea of the pattern. A wrapper is an object that can be linked with some target object. The wrapper contains the same set of methods as the target and delegates to it all requests it receives. However, the wrapper may alter the result by doing something either before or after it passes the request to the target. When does a simple wrapper become the real decorator? As I mentioned, the wrapper implements the same interface as the wrapped object. That's why from the client's perspective these objects are identical. Make the wrapper's reference field accept any object that follows that interface. This will allow you to cover an object in multiple wrappers, adding the combined behavior of all the wrappers to it. Figure 3.2 - Decorator  The Component declares the common interface for both wrappers and wrapped objects.Concrete Component is a class of objects being wrapped. It defines the basic behaviour, which can be altered by decorators.The Base Decorator class has a field for referencing a wrapped object. The field's type should be declared as the component interface, so it can contain both concrete components and decorators. The base decorator delegates all operations to the wrapped object.Concrete Decorators define extra behaviours that can be added to components dynamically. Concrete decorators override methods of the base decorator and execute their behaviour either before or after calling the parent method.The Client can wrap components in multiple layers of decorators, as long as it works with all objects via the component interface. "},{"title":"3.2.2 Decorator example​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#322-decorator-example","content":"Listing 3.3 interface Coffee { getCost(); getDescription(); } class SimpleCoffee implements Coffee { public getCost() { return 10; } public getDescription() { return 'Simple coffee' } } class CoffeeDecorator implements Coffee { protected wrappee: Coffee; constructor(coffee: Coffee) { this.wrappee = coffee; } public getCost() { return this.wrappee.getCost(); } public getDescription() { return this.wrappee.getDescription(); } }  The decorators and the data source class implement the same interface, which makes them all interchangeable in the client code. Listing 3.4 class MilkCoffeeDecorator extends CoffeeDecorator { public getCost(): number { return this.wrappee.getCost() + 2; } public getDescription(): string { return this.wrappee.getDescription() + 'with milk'; } } class WhipCoffeeDecorator extends CoffeeDecorator { public getCost(): number { return this.wrappee.getCost() + 3; } public getDescription(): string { return this.wrappee.getDescription() + 'and with whip'; } } let someCoffee = new SimpleCoffee(); someCoffee.getCost(); // 10 someCoffee.getDescription(); // Simple Coffee someCoffee = new MilkCoffeeDecorator(someCoffee); someCoffee.getCost(); // 12 someCoffee = new WhipCoffeeDecorator(someCoffee); someCoffee.getDescription(); // Simple Coffee with milk and whip  "},{"title":"3.2.3 When to apply, pros and cons​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#323-when-to-apply-pros-and-cons","content":"when you need to be able to assign extra behaviours to objects at runtime without breaking the code that uses these objects – The Decorator lets you structure your business logic into layers, create a decorator for each layer and compose objects with various combinations of this logic at runtime. The client code can treat all these objects in the same way, since they all follow a common interfacewhen it's awkward or not possible to extend an object's behaviour using inheritance. For example, you are working with a library, and you don't have access to alter its behavior, but what you can do is extending it with Decorator Pros extending an object's behavior without making a new subclassadding or remove responsibilities from an object at runtimecombining several behaviors by wrapping an object into multiple decoratorsdividing a monolithic class that implements many possible variants of behavior into several smaller classes Cons hard to remove a specific wrapper from the wrappers stackhard to implement a decorator in such a way that its behavior doesn't depend on the order in the decorators stackinitial configuration code of layers might look overcomplicated "},{"title":"3.3 Proxy​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#33-proxy","content":"Proxy is a structural design pattern that lets you provide a substitute or placeholder for another object. A proxy controls access to the original object, allowing you to perform something either before or after the request gets through to the original object. In other words by using proxy, one class provides functionality of another class. Unlike Decorator, a Proxy usually manages the life cycle of its service object on its own. "},{"title":"3.3.1 Proxy structure​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#331-proxy-structure","content":"Figure 3.3 - Proxy  The ServiceInterface declares the interface of the Service. The proxy must follow this interface to be able to disguise itself as a service object.The Service is a class that provides some useful business logic.The Proxy class has a reference field that points to a service object. After the proxy finishes its processing (e.g., lazy initialization, logging, access control, caching, etc.), it passes the request to the service object.Usually, proxies manage the full lifecycle of their service objects.The Client should work with both services and proxies via the same interface. This way you can pass a proxy into any code that expects a service object. "},{"title":"3.3.2 Proxy example​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#332-proxy-example","content":"Listing 3.5 // Presume we have an input filed with an ID of inputname: const el = `&lt;input type=&quot;text&quot; id=&quot;inputname&quot; value=&quot;&quot; /&gt;`; // We also have a JS object named myUser with // an id property which references this input const myUser = { id: 'inputname', name: '' }; // Our first objective is to update myUser.name // when a user changes the input value. This can be achieved // with an onchange event handler on the field: (function inputChange(myObject) { if (!myObject || !myObject.id) return; const input = document.getElementById(myObject.id); input.addEventListener('onchange', function (e) { myObject.name = input.value; }); })(myUser);  There is a JavaScript native class Proxy, which allows catching get/set calls of objects and perform additional actions. Here we use this feature to create a primitive but operating bi-directional data-binding. Listing 3.6 // create proxy const myUserProxy = new Proxy(myUser, { set: function(target, prop, newValue) { if (prop === 'name' &amp;&amp; target.id) { // update object property target[prop] = newValue; // update input field value document.getElementById(target.id).value = newValue; return true; } return false; } }); // set a new name myUserProxy.name = 'Craig'; console.log(myUserProxy.name); // Craig console.log(document.getElementById('inputname').value);  "},{"title":"3.3.3 When to apply, pros and cons​","type":1,"pageTitle":"3. Structural Design Patterns","url":"docs/design-patterns/structural_design_patterns#333-when-to-apply-pros-and-cons","content":"lazy initialization (virtual proxy) of a heavyweight service object that wastes system resources by being always up, but is needed from time to time. Instead of creating the object when the app launches, you can delay the object's initialization to a time when it's really neededaccess control (protection proxy) – for letting only specific clients to be able to use the service object; for instance, when your objects are crucial parts of an operating system and clients are various launched applications (including malicious ones). The proxy can pass the request to the service object only if the client's credentials match some criterialocal execution of a remote service (remote proxy). This is when the service object is located on a remote server. In this case, the proxy passes the client request over the network, handling all the nasty details of working with the networklogging requests (logging proxy). This is when you want to keep a history of requests to the service object. The proxy can log each request before passing it to the servicecaching request results (caching proxy). This is when you need to cache results of client requests and manage the life cycle of this cache, especially if results are quite large. The proxy can implement caching for recurring requests that always yield the same results. The proxy may use the parameters of requests as the cache keys Pros controlling the service object without clients knowing about itmanaging the lifecycle of the service object when clients don't care about itthe proxy works even if the service object isn't ready or is not availableintroducing new proxies without changing the service or clients Cons overcomplicated code since you need to introduce a lot of new classesthe response from the service might get delayed "},{"title":"5. 📚 Home Task","type":0,"sectionRef":"#","url":"docs/solid-principles/hometask","content":"5. 📚 Home Task Identify SOLID Principles Choose a large open source project written in TypeScript preferably (choose another OOP language if you want: Java, C#, Ruby). You may want to look at Angular or VS Code source code. A project may be considered large enough if it contains at least 30 classes. Try to identify at least 1 (one) example of each SOLID principle. Document them by filling in the table below. Note that you don't need to give code examples itself, just provide the link to file with line numbers range (or whatever you want to clearly recognize the example you describe, e.g. file hello.ts:15-36, class Foo), you can also write free text. Principle\tExamplesSingle Responsibility Principle Open / Closed Principle Liskov Substitution Principle Interface Seggregation Principle Dependency Inversion Principle Violations of SOLID and Other Principles Try to find at least 1 (one) violations of each SOLID principle in the project you have chosen for Problem 1 and document it. Additionally, you can describe other (DRY/KISS/YAGNI/etc.) violations. You may provide short descriptions about how to refactor/improve such violations. Optionally, you can add small examples with results of such refactoring using pseudocode or real code.","keywords":""},{"title":"1. Introduction","type":0,"sectionRef":"#","url":"docs/solid-principles/introduction","content":"","keywords":""},{"title":"1.1 Design Principles Overview​","type":1,"pageTitle":"1. Introduction","url":"docs/solid-principles/introduction#11-design-principles-overview","content":"There are formal (measurable) criteria that describe the quality of the code or design, e.g. the cyclomatic complexity of methods, the depth of the inheritance hierarchy, the number of method lines, etc. They are certainly useful and keeping these values in the normal range is necessary but not sufficient condition for good software design. Figure 1.1 - Good code VS Bad code  In addition to formal criteria, there are common concepts of good design: low coupling and high cohesion. Low coupling - modules should be as independent as possible from other modules, so that changes to modules do not heavily impact other modules. High cohesion - keep elements of the module that are related to the functionality that module provides as close to each other as possible. Even though these concepts are useful, they are too abstract and informal. Figure 1.2 - Low coupling/high cohesion VS high coupling/low cohesion  There are design principles between formal and informal criteria. Design principles are rules that experienced designers rely on. Their main goal is to describe in simple words what is &quot;good and what is bad&quot; in software design. For example: &quot;A class should have only one reason to change, have a minimal interface, correctly implement inheritance and prevent cascading changes in the code when requirements change&quot;. Design principles are used to combat complexity and make it easier to introduce changes needed. So before studying design principles, let us quickly review code smells that make our systems more complicated. Consider the following code smells: Rigidity – hard to change.Fragility – easy to break.Immobility – hard to reuse.Viscosity – hard to choose the right way to introduce changes.Needless complexity – overdesign. As you can see, all smells are somehow related to a change in the code. "},{"title":"1.2 What is SOLID​","type":1,"pageTitle":"1. Introduction","url":"docs/solid-principles/introduction#12-what-is-solid","content":"When our application has only 200 lines, the design itself is not needed. It is enough to write 5-7 methods carefully and everything will be fine. Problems might arise when the system grows and requires scaling. SOLID is an acronym used for the first five object-oriented design principles by Robert C. Martin (also known as Uncle Bob). He did not invent or discover them, but simply structured and combined into a set of 5 principles commonly known to us. SOLID stands for: S – Single-responsibility PrincipleO – Open-closed PrincipleL – Liskov Substitution PrincipleI – Interface Segregation PrincipleD – Dependency Inversion Principle These principles establish practices that tend to develop software with considerations for maintaining and extending as the project grows. Adopting these practices can also contribute to avoiding code smells, refactoring code, and agile or adaptive software development. info SOLID principles make both development and software design adaptive to changes, easy to scale and maintain. "},{"title":"4. Behavioral Design Patterns","type":0,"sectionRef":"#","url":"docs/design-patterns/behavioral_design_patterns","content":"","keywords":""},{"title":"4.1 Template Method​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#41-template-method","content":"Template Method is a behavioral design pattern that defines the skeleton of an algorithm in the superclass but allows subclasses to override specific steps of the algorithm without changing its structure. "},{"title":"4.1.1 Template Method structure​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#411-template-method-structure","content":"The Template Method pattern suggests you break down an algorithm into a series of steps, turn these steps into methods, and put a series of calls to these methods inside a single template method. The steps may either be abstract, or have some default implementation. To use the algorithm, the client is supposed to provide its own subclass, implement all abstract steps, and override some optional ones if needed (but not the template method itself). There are three types of steps: abstract steps must be implemented by every subclassoptional steps already have default implementation, but can be overridden if neededhooks are optional steps with an empty body. A template method would work even if a hook is not overridden. Usually, hooks are placed before and after crucial steps of algorithms, providing subclasses with additional extension points for an algorithm. Figure 4.1 - Template Method  The AbstractClass declares methods that act as steps of an algorithm, as well as the actual template method which calls these methods in a specific order. The steps may either be declared abstract or have some default implementation.ConcreteClasses can override all the steps, but not the template method itself. Listing 4.1 - Template Method for making tea and coffee boilWater(); brew(); pourInCup() addCondiments();  "},{"title":"4.1.2 Template Method example​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#412-template-method-example","content":"Listing 4.2 abstract class Builder { // Template method public build() { this.test(); this.lint(); this.assemble(); this.deploy(); } abstract test(); abstract lint(); abstract assemble(); abstract deploy(); } class AndroidBuilder extends Builder { public test() { return 'Running android tests'; } public lint() { return 'Linting android code'; } public assemble() { return 'Assembling android build'; } public deploy() { return 'Deploying android build to server'; } } class IosBuilder extends Builder { public test() { return 'Running ios tests'; } public lint() { return 'Linting ios code'; } public assemble() { return 'Assembling ios build'; } public deploy() { return 'Deploying ios build to server'; } } const androidBuilder = new AndroidBuilder(); androidBuilder.build(); // Running android tests // Linting android code // Assembling android build // Deploying android build to server const iosBuilder = new IosBuilder(); androidBuilder.build(); // Running ios tests // Linting ios code // Assembling ios build // Deploying ios build to server  "},{"title":"4.1.3 When to apply, pros and cons​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#413-when-to-apply-pros-and-cons","content":"to let clients extend only particular steps of an algorithm, but not the whole algorithm or its structure. The Template Method lets you turn a monolithic algorithm into a series of individual steps which can be easily extended by subclasses while keeping intact the structure defined in a superclasswhen you have several classes that contain almost identical algorithms with some minor differences. As a result, you might need to modify all classes when the algorithm changes. When you turn such an algorithm into a template method, you can also move the steps with similar implementations into a superclass, eliminating code duplication. Code that varies between subclasses can remain in subclasses Pros letting clients override only certain parts of a large algorithm, making them less affected by changes that happen to other parts of the algorithmmove the duplicate code into a superclass Cons some clients may be limited by the provided skeleton of an algorithmyou might violate the Liskov Substitution Principle by suppressing a default step implementation via a subclasstemplate methods tend to be harder to maintain the more steps they have "},{"title":"4.2 Strategy​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#42-strategy","content":"Strategy is a behavioral design pattern that lets you define a family of algorithms, put each of them into a separate class, and make their objects interchangeable. Allows switching between algorithms or strategies depending on situation. "},{"title":"4.2.1 Strategy structure​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#421-strategy-structure","content":"The Strategy pattern suggests you take a class that does something specific in a lot of diverse ways and extract all these algorithms into separate classes called strategies. The original class, called context, must have a field for storing a reference to one of the strategies. The context delegates the work to a linked strategy object instead of executing it on its own. The context is not responsible for selecting an appropriate algorithm for the job. Instead, the client passes the desired strategy to the context. In fact, the context does not know much about strategies. It works with all strategies through the same generic interface, which only exposes a single method for triggering the algorithm encapsulated within the selected strategy. This way the context becomes independent of concrete strategies, so you can add new algorithms or modify existing ones without changing the code of the context or other strategies. Figure 4.2 - Strategy  The Context keeps a reference to one of the concrete strategies and communicates with this object only via the strategy interface.The Strategy interface is unified for all concrete strategies. It declares a method the context uses to execute a strategy.ConcreteStrategies implement different variations of an algorithm the context uses.The context calls the execution method on the linked strategy object each time it needs to run the algorithm. The context does not know what type of strategy it works with or how the algorithm is executed.The Client creates a specific strategy object and passes it to the context. The context exposes a setter which lets clients replace the strategy associated with the context at runtime. "},{"title":"4.2.2 Strategy example​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#422-strategy-example","content":"Listing 4.3 // The strategy interface declares operations common // to all supported versions of some algorithm. interface Strategy { execute(a: number, b: number): number; } // Concrete strategies implement the algorithm while following // the base strategy interface. The interface makes them // interchangable in the context. class ConcreteStrategyAdd implements Strategy { execute(a, b) { return a + b; } } class ConcreteStrategySubstract implements Strategy { execute(a, b) { return a - b; } } class ConcreteStrategyMultiply implements Strategy { execute(a, b) { return a * b; } }  We have common interface and 3 concrete classes implementing this interface. The Context in not aware of what specific strategy he works with. Context knows that it can send the execution message. Thus, the client decides when and which strategy should be used. It can switch them on the fly, getting different behavior, without changing the interface. Listing 4.4 // The context defines the interface of interest to clients. class Context { private strategy: Strategy; setStrategy(s: Strategy) { this.strategy = s; } // The context delegates some work to the strategy object // instead of implementing multiple versions of the // algorithm on its own. executeStrategy(a: number, b: number) { return this.strategy.execute(a, b); } } let ctx = new Context(); ctx.setStrategy(new ConcreteStrategyAdd()); ctx.executeStrategy(5, 2); // 7  "},{"title":"4.2.3 When to apply, pros and cons​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#423-when-to-apply-pros-and-cons","content":"when you want to use different variants of an algorithm within an object and be able to switch from one algorithm to another during runtime. The Strategy pattern lets you indirectly alter the object's behavior at runtime by associating it with different sub-objects which can perform specific sub-tasks in diverse wayswhen you have a lot of similar classes that only differ in the way they execute some behavior. The Strategy pattern lets you extract the varying behavior into a separate class hierarchy and combine the original classes into one, thereby reducing duplicate codeto isolate the business logic of a class from the implementation details of algorithms that may not be as important in the context of that logic. The Strategy pattern lets you isolate the code, internal data, and dependencies of various algorithms from the rest of the code. Various clients get a simple interface to execute the algorithms and switch them at runtimewhen your class has a massive conditional operator that switches between different variants of the same algorithm Pros swapping algorithms used inside an object at runtimeisolating the implementation details of an algorithm from the code that uses itreplacing inheritance with compositionintroducing new strategies without having to change the context Cons if you have only a couple of algorithms, and they rarely change, there is no real reason to overcomplicate the program with new classes and interfaces that come along with the patternclients must be aware of the differences between strategies to be able to select a proper one "},{"title":"4.3 Visitor​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#43-visitor","content":"Visitor is a behavioral design pattern that lets you separate algorithms from the objects on which they operate. "},{"title":"4.3.1 Visitor structure​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#431-visitor-structure","content":"Imagine that your team develops an app which works with geographic information structured as one colossal graph. Each node of the graph may represent a complex entity such as a city, but also more granular things like industries, sightseeing areas, etc. The nodes are connected with others if there is a relation between the real objects that they represent. Under the hood, each node type is represented by its own class, while each specific node is an object. At some point, you got a task to implement exporting the graph into XML format. At first, the job seemed straightforward. You planned to add an export method to each node class and then leverage recursion to go over each node of the graph, executing the export method. The solution was simple and elegant: thanks to polymorphism, you were not coupling the code which called the export method to concrete classes of nodes. The Visitor pattern suggests you put the new behavior into a separate class called visitor, instead of trying to integrate it into existing classes. The original object that has to perform the behavior is now passed to one of the visitor's methods as an argument, providing the method access to all necessary data contained within the object. Now, what if that behavior can be executed over objects of different classes? For example, in our case with XML export, the actual implementation will probably be a little different across various node classes. Thus, the visitor class may define not one, but a set of methods, each of which could take arguments of different types. Figure 4.3 - Visitor  The Visitor interface declares a set of visiting methods that can take concrete elements of an object structure as arguments. These methods may have the same names if the program is written in a language that supports overloading, but the type of their parameters must be different.Each ConcreteVisitor implements several versions of the same behaviors, tailored for different concrete element classes.The Element interface declares a method for &quot;accepting&quot; visitors. This method should have one parameter declared with the type of the visitor interface.Each ConcreteElement must implement the acceptance method. The purpose of this method is to redirect the call to the proper visitor's method corresponding to the current element class. Be aware that even if a base element class implements this method, all subclasses must still override this method in their own classes and call the appropriate method on the visitor object.The Client usually represents a collection or some other complex object (for example, a Composite tree). Usually, clients are not aware of all the concrete element classes because they work with objects from that collection via some abstract interface. "},{"title":"4.3.2 Visitor example​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#432-visitor-example","content":"The element interface declares an accept method that takes the base visitor interface as an argument. Each concrete element class must implement the accept method in such a way that it calls the visitor's method that corresponds to the element's class. Listing 4.5 // The component interface declares an 'accept' method that // takes the base visitor interface as an argument. interface Shape { move(x, y); draw(); accept(v: Visitor); } // Each concrete component class must implement the 'accept' method class Dot implements Shape { accept(v: Visitor) { v.visitDot(this); } move(x, y) {} draw() {} } class Circle implements Shape { accept(v: Visitor) { v.visitCircle(this); } move(x, y) {} draw() {} } class Rectangle implements Shape { accept(v: Visitor) { v.visitRectangle(this); } move(x, y) {} draw() {} }  The Visitor interface declares a set of visiting methods that correspond to element classes. The signature of a visiting method lets the visitor identify the exact class of the element that it's dealing with. Listing 4.6 // The Visitor interface declares a set of visiting methods that // correspond to component classes. interface Visitor { visitDot(d: Dot); visitCircle(c: Circle); visitRectangle(r: Rectangle); } class JSONExportVisitor implements Visitor { visitDot(d: Dot) { // Export the dot's ID and coordinates. } visitCircle(d: Circle) { // Export the circle's ID, center coordinates and radius. } visitRectangle(d: Rectangle) { // Export the rectangle's ID, left-top coordinates, width and height. } } // The client code can run visitor operations over any set of // elements without figuring out their concrete classes. The // 'accept' operation directs a call to the appropriate operation // in the visitor object. const allShapes = [new Dot(), new Circle(), new Rectangle()]; const exportVisitor = new JSONExportVisitor(); allShapes.forEach(shape =&gt; shape.accept(exportVisitor));  Concrete visitors implement several versions of the same algorithm, which can work with all concrete element classes. "},{"title":"4.3.3 When to apply, pros and cons​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#433-when-to-apply-pros-and-cons","content":"when you need to perform an operation on all elements of a complex object structure (for example, an object tree). The Visitor pattern allows you to execute an operation over a set of objects with different classes by having a visitor object implementing several variants of the same operation, which correspond to all target classesto clean up the business logic of auxiliary behaviors. The pattern allows you to make the primary classes of your app more focused on their main jobs by extracting all other behaviors into a set of visitor classeswhen a behavior makes sense only in some classes of a class hierarchy, but not in others. You can extract this behavior into a separate visitor class and implement only those visiting methods that accept objects of relevant classes, leaving the rest empty Pros introducing new behavior that can work with objects of different classes without changing these classes (Open/Closed)moving multiple versions of the same behavior into the same class (Single Responsibility)a visitor object can accumulate some useful information while working with various objects. This might be handy when you want to traverse some complex object structure, such as an object tree, and apply the visitor to each object of this structure Cons you need to update all visitors each time a class gets added to or removed from the element hierarchyvisitors might lack the necessary access to the private fields and methods of the elements that they are supposed to work with "},{"title":"4.4 Command​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#44-command","content":"Command is a behavioral design pattern that turns a request into a stand-alone object that contains all information about the request. This transformation allows you to parameterize methods with different requests, delay or queue a request's execution, and support undoable operations. In other words – it allows to incapsulate actions in objects. The main idea of Command pattern is to provide a way of separating client from receiver. "},{"title":"4.4.1 Command real-life example​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#441-command-real-life-example","content":"Remote control example – we've got on and off buttons, client configures each of these buttons for particular commands. At the same time buttons are not aware of which command are they assigned to. Another example is a friendly waiter taking your order, writing it down on a piece of paper. Then he goes to the kitchen and sticks the order on the wall. After a while, the order gets to the chef, who reads it and cooks the meal accordingly. The cook places the meal on a tray along with the order. The waiter discovers the tray, checks the order to make sure everything is as you wanted it, and brings everything to your table. "},{"title":"4.4.2 Command structure​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#442-command-structure","content":"Good software design is often based on the principle of separation of concerns, which usually results in breaking an app into layers. The most common example: a layer for the graphical user interface and another layer for the business logic. The GUI layer is responsible for rendering a beautiful picture on the screen, capturing any input and showing results of what the user and the app are doing. However, when it comes to doing something important, like calculating the trajectory of the moon or composing an annual report, the GUI layer delegates the work to the underlying layer of business logic. In the code it might look like this: a GUI object calls a method of a business logic object, passing it some arguments. This process is usually described as one object sending another a request. The Command pattern suggests that GUI objects should not send these requests directly. Instead, you should extract all the request details, such as the object being called, the name of the method and the list of arguments into a separate command class with a single method that triggers this request. Command objects serve as links between various GUI and business logic objects. From now on, the GUI object does not need to know what business logic object will receive the request and how it will be processed. The GUI object just triggers the command, which handles all the details. The next step is make your commands to implement the same interface. Usually it has just a single execution method that takes no parameters. This interface lets you use various commands with the same request sender, without coupling it to concrete classes of commands. As a bonus, now you can switch command objects linked to the sender, effectively changing the sender's behavior at runtime. Figure 4.4 - Command  The Sender class (aka invoker) is responsible for initiating requests. This class must have a field for storing a reference to a command object. The sender triggers that command instead of sending the request directly to the receiver. Note that the sender is not responsible for creating the command object. Usually, it gets a pre-created command from the client via the constructor.The Command interface usually declares just a single method for executing the command.ConcreteCommands implement various kinds of requests. A concrete command is not supposed to perform the work on its own, but rather to pass the call to one of the business logic objects. However, to simplify the code, these classes can be merged.Parameters required to execute a method on a receiving object can be declared as fields in the concrete command. You can make command objects immutable by only allowing the initialization of these fields via the constructorThe Receiver class contains some business logic. Almost any object may act as a receiver. Most commands only handle the details of how a request is passed to the receiver, while the receiver itself does the actual work.The Client creates and configures concrete command objects. The client must pass all the request parameters, including a receiver instance, into the command's constructor. After that, the resulting command may be associated with one or multiple senders. "},{"title":"4.4.3 Command example​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#443-command-example","content":"In this example the Command pattern handles command execution history, allows to cancel them if necessary. Commands, altering the editor state (e.g. paste command), save a copy of editor state before execution. abstract class Command { protected app: Application; protected editor: Editor; protected backup: string; constructor (app: Application, editor: Editor) { this.app = app; this.editor = editor; } saveBackup() { this.backup = this.editor.text; } undo() { this.editor.text = this.backup; } abstract execute(); }  Copies of executed commands are placed into command history, where they can be accessed for cancelling. Classes of UI, command history and others don't depend on concrete commands, since they work via common interface with them. Thus, new commands can be added to application without changing existing code. class CopyCommand extends Command { execute() { this.app.clipboard = this.editor.getSelection(); } } class PasteCommand extends Command { execute() { this.saveBackup(); this.editor.replaceSelection(this.app.clipboard); } } class CommandHistory { private history: Command[]; push(c: Command) { this.history.push(c); } pop(): Command { return this.history[this.history.length -1]; } } class Editor { text: string; getSelection() { return 'some selection'; } replaceSelection(clipboard) { return `some ${clipboard} selection`; } }  The application class sets up object relations. It acts as a sender: when something needs to be done, it creates a command object and executes it. class Application { clipboard: string; editor: Editor; activeEditor: Editor; history: CommandHistory; bindComands() { shortcuts.onkeypress('Ctrl+C', () =&gt; { return this.executeCommand(new CopyCommand(this, this.editor)); }); shortcuts.onkeypress('Ctrl+V', () =&gt; { return this.executeCommand(new PasteCommand(this, this.editor)); }); } executeCommand(command: Command) { this.history.push(command); command.execute(); } undo() { const command = this.history.pop(); command.undo(); } }  Take the most recent command from the history and run its undo method. Note that we don't know the class of that command. But we don't have to, since the command knows how to undo its own action. "},{"title":"4.4.4 When to apply, pros and cons​","type":1,"pageTitle":"4. Behavioral Design Patterns","url":"docs/design-patterns/behavioral_design_patterns#444-when-to-apply-pros-and-cons","content":"when you want to parametrize objects with operations. The Command pattern can turn a specific method call into a stand-alone object. This change opens up a lot of interesting uses: you can pass commands as method arguments, store them inside other objects, switch linked commands at runtime, etc. Here's an example: you're developing a GUI component such as a context menu, and you want your users to be able to configure menu items that trigger operations when an end user clicks an itemwhen you want to queue operations, schedule their execution, or execute them remotely. As with any other object, a command can be serialized, which means converting it to a string that can be easily written to a file or a database. Later, the string can be restored as the initial command object. Thus, you can delay and schedule command execution. But there's even more! In the same way, you can queue, log or send commands over the networkwhen you want to implement reversible operations. Although there are many ways to implement undo/redo, the Command pattern is perhaps the most popular of all. To be able to revert operations, you need to implement the history of performed operations. The command history is a stack that contains all executed command objects along with related backups of the application's state. This method has two drawbacks. First, it isn't that easy to save an application's state because some of it can be private. This problem can be mitigated with the Memento pattern. Second, the state backups may consume quite a lot of RAM. Therefore, sometimes you can resort to an alternative implementation: instead of restoring the past state, the command performs the inverse operation. The reverse operation also has a price: it may turn out to be hard or even impossible to implement. Pros decoupling classes that invoke operations from classes that perform these operations (Single Responsibility)introducing new commands into the app without breaking existing client code (Open/Closed)implementing undo/redoimplementing deferred execution of operationsassembling a set of simple commands into a complex one Cons the code may become more complicated since you're introducing a whole new layer between senders and receivers "},{"title":"3. Main concepts","type":0,"sectionRef":"#","url":"docs/functional-programming/main_concepts","content":"","keywords":""},{"title":"3.1 Immutability​","type":1,"pageTitle":"3. Main concepts","url":"docs/functional-programming/main_concepts#31-immutability","content":"The main rule of an immutable object is it cannot be modified after creation. Conversely, a mutable object is each object which can be modified after creation. The data flow in the program is lossy if the immutability principle is not followed, that is why it is the main concept of functional programming. For example, Listing 3.1. In case the data is mutated in the program some bugs which are hard to find can hide there. Listing 3.1 const stat = [ { name: &quot;John&quot;, score: 1.003 }, { name: &quot;Lora&quot;, score: 2 }, { name: &quot;Max&quot;, score: 3.76 }, ]; const statScoreInt = stat.map((el) =&gt; { // (1) el.score = Math.floor(el.score); // (2) el.name = el.name; // (3) return el; // (4) }); console.log(stat); // [{ name: &quot;John&quot;, score: 1 }, { name: &quot;Lora&quot;, score: 2 }, { name: &quot;Max&quot;, score: 3 }] console.log(statScoreInt); // [{ name: &quot;John&quot;, score: 1 }, { name: &quot;Lora&quot;, score: 2 }, { name: &quot;Max&quot;, score: 3 }]  In the Listing 3.1 the stat array includes actual data from a database. It has player name and player score that shows win percentage. The task is to display the score to the user as a rounded down integer. In lines from (1) to (4) it goes through array and modifies score in a needed way and the result of this operation is statScoreInt array. The last step is to console two arrays stat and statScoreInt and the result is unexpectable. Both arrays are equal. That is because inside the map the stat item was modified. These kinds of bugs are hard to find and can lead to strange actions. Immutability helps to avoid such behavior. For example, Listing 3.2. The tasks is the same. Listing 3.2 const stat = [ { name: &quot;John&quot;, score: 1.003 }, { name: &quot;Lora&quot;, score: 2 }, { name: &quot;Max&quot;, score: 3.76 }, ]; const statScoreInt = stat.map((el) =&gt; { return { score: Math.floor(el.score), ...el }; }); console.log(stat); // [{ name: &quot;John&quot;, score: 1.003 }, { name: &quot;Lora&quot;, score: 2 }, { name: &quot;Max&quot;, score: 3.76 }] console.log(statScoreInt); // [{ name: &quot;John&quot;, score: 1 }, { name: &quot;Lora&quot;, score: 2 }, { name: &quot;Max&quot;, score: 3 }]  There are two arrays stat and statScoreInt in Listing 3.2. The difference is in the map function, instead of modifying stat item it creates a new element with copied data from stat item and modified score value. As a result, there are two arrays with different values. In JavaScript, it might be easy to confuse const with immutability. The variable which cannot be redeclared is created by using const but immutable objects are not created by const. You can't change the object that the binding refers to, but you can still change the properties of the object, which means that bindings created with const are mutable. Immutable objects can't be changed at all. You can make a value truly immutable by deep-freezing the object. JavaScript has a method that freezes an object one-level deep (in order to freeze an object deeply, recursion could be used to freeze each property and nested objects): Listing 3.3 const a = Object.freeze({ greeting: &quot;Hello&quot;, subject: &quot;student&quot;, mark: &quot;!&quot;, }); a.greeting = &quot;Goodbye&quot;; // Error: Cannot assign to read only property 'foo' of object Object  There are several libraries in JavaScript which try to follow this principle, for example, Immutable.js. "},{"title":"3.1.1 Side effects​","type":1,"pageTitle":"3. Main concepts","url":"docs/functional-programming/main_concepts#311-side-effects","content":"If state changes are observable outside the called function and they are not returned value of the function it is a side effect. Side effects include: Modifying any external variable or object property (e.g., a global variable, or a variable in the parent function scope chain)Logging to the consoleAlertWriting to the screen, in other words, replacing the content of a specific tag (querySelector(), getElementById(), etc.)Writing to a fileThe HTTP request might have side effects - therefore the function that triggers the request transitively have side effectsTriggering any external processCalling any other functions with side effects In functional programming side effects are mostly avoided. It makes a program much easier to understand, and much easier to test. That is important to understand that a program without side effects does nothing. If the code does not write to or read from a database, does not make any requests, does not change UI, etc., it does not bring any value. So we cannot completely avoid side effects. What we can do is isolate side effects from the rest of your software. In case of keeping side effects separately from the rest of the software, the application will be much easier to extend, refactor, debug, test, and maintain. That is why a lot of front-end frameworks suggest using state management tools along with the library. Because it separates components rendering from state management, and they are loosely coupled modules. ReactJS and Redux are examples of that. "},{"title":"3.1.2 Pure functions​","type":1,"pageTitle":"3. Main concepts","url":"docs/functional-programming/main_concepts#312-pure-functions","content":"A function is called pure if it has the following properties: Given the same input, always returns the same outputFunction without side effects A pure function also can be called a deterministic function. Such JS arrays methods as: map, filter, reduce etc., are examples of pure function. A pure function does not depend on any state, it only depends on input parameters. Let's look on the example: Listing 3.4 const doubledPrice = (price) =&gt; price * 2; doubledPrice(2);  In this case, there are no side effects because price comes as an argument. Also, the result will always be 4 if the price is 2. Just to compare let's check another example: Listing 3.5 let price = 2; const doubledPrice = () =&gt; (price = price * 2); doubledPrice();  I believe, you already noticed the difference, there is a side effect in this case. The price is changed inside the function, but price is declared outside the doubledPrice scope. "},{"title":"3.2 No shared state​","type":1,"pageTitle":"3. Main concepts","url":"docs/functional-programming/main_concepts#32-no-shared-state","content":"Shared state is a memory space (could be an object or simple variable) that is reachable from all program parts. In other words, it is global and exists in shared scope. It also could be passed as a property between scopes. If two or more application parts change the same data, then the data is a shared state. "},{"title":"3.2.1 Problems with shared state​","type":1,"pageTitle":"3. Main concepts","url":"docs/functional-programming/main_concepts#321-problems-with-shared-state","content":"If the state is changing from more than one place in the application, there is a risk of one modification preventing another part of the application to work with the actual data. So it might lead to strange hard to track bugs. Listing 3.6 const arr = [&quot;bread&quot;, &quot;milk&quot;, &quot;wine&quot;]; function logGrocery(arr) { for (let i = 0; i &lt;= arr.length + 1; i++) { console.log(arr.shift()); } } function main() { // some code logGrocery(arr); } function minor() { // some code logGrocery(arr); } main(); minor(); // bread // milk // wine // undefined (1)  In this case, there are three independent parties: Functions main() and minor() do something and wants to log an arr.Function logElements() logs elements into console. However, it removes elements from the array while logging them.logElements() breaks minor() and that is why there is an undefined in a line (1). "},{"title":"3.2.2 How to avoid it​","type":1,"pageTitle":"3. Main concepts","url":"docs/functional-programming/main_concepts#322-how-to-avoid-it","content":"We can avoid shared state by copying data Until we are reading from a shared state without any modification we are safe. Before doing some modifications we need to &quot;un-share&quot; our state. Let's try to fix the previous example: Listing 3.7 const arr = [&quot;bread&quot;, &quot;milk&quot;, &quot;wine&quot;]; function logGrocery(arr) { const localArr = [...arr]; for (let i = 0; i &lt;= localArr.length + 1; i++) { console.log(localArr.shift()); } } function main() { // some code logGrocery(arr); } function minor() { // some code logGrocery(arr); } main(); minor(); // bread // milk // wine // bread // milk // wine  In this case, there are three independent parties: Functions main() and minor() do something and wants to log an arr. Function logElements() logs elements into console. The code creates a new variable localArray, a copy of arr. So the localArray is modified, and it is a new declaration on each call. So everything works as expected. Avoiding mutations by updating non-destructively Let's imagine that we have to add some fruit to our shopping list. Listing 3.8 const shoppingList = [&quot;bread&quot;, &quot;milk&quot;, &quot;wine&quot;]; function addToShoppingList(arr, item) { return [...arr, item]; } function main(item) { // some code return addToShoppingList(arr, item); } const withFruit = main(&quot;fruit&quot;); console.log(withFruit); // ['bread', 'milk', 'wine', 'fruit'] console.log(shoppingList); // ['bread', 'milk', 'wine']  Preventing mutations by making data immutable We can prevent mutations of shared data by making that data immutable. If data is immutable, it can be shared without any risks. In particular, there is no need to copy defensively. "},{"title":"3.3 Composition​","type":1,"pageTitle":"3. Main concepts","url":"docs/functional-programming/main_concepts#33-composition","content":"Function composition is a combination of two or more functions. The single function does a small piece which is not valuable for an application, so in order to achieve the desired result, small functions have to be combined together. You can imagine composing functions as pipes of functions that data has to go through, so that outcome is reached. In functional programming, it is preferable to use composition over inheritance. "},{"title":"3.3.1 Composition over inheritance​","type":1,"pageTitle":"3. Main concepts","url":"docs/functional-programming/main_concepts#331-composition-over-inheritance","content":"Let's check the example with object composition in JavaScript. This approach combines the power of objects and functional programming. For example, let's create an animal that can talk and eat. Previously, using inheritance we would have abstract class Animal and a child class TalkingAnimal. Imagine we had to add more and more animals. In this case, the hierarchy could become messy, since abilities are shared between animals. Composition helps to solve the problem: Listing 3.9 const dog = (name) =&gt; { // (1) const self = { name, }; return self; }; const buddy = dog(&quot;Buddy&quot;);  The first step in Listing 3.9 (1) is to create a function that creates an animal (e.g. dog). The internal variable self represents the prototype using classes or prototypes. The next step (2) (Listing 3.10 (2)) is defining behaviors, it will be created as functions receiving the self. Because they are functions it is easy to combine them. And finally (3), all of these functions have to be merged. Object.assign or the spread operator ({...a, ...b}) can be used for this purpose. Listing 3.10 const canSayHi = (self) =&gt; ({ // (1) sayHi: () =&gt; console.log(`Hi! I'm ${self.name}`), }); const canEat = () =&gt; ({ eat: (food) =&gt; console.log(`Eating ${food}...`), }); const behaviors = (self) =&gt; Object.assign({}, canSayHi(self), canEat()); // (2) const dog = (name) =&gt; { const self = { name, }; const dogBehaviors = (self) =&gt; ({ bark: () =&gt; console.log(&quot;Ruff!&quot;), }); return Object.assign(self, behaviors(self), dogBehaviors(self)); // (3) }; const buddy = dog(&quot;Buddy&quot;); buddy.sayHi(); // Hi! I'm Buddy buddy.eat(&quot;Petfood&quot;); // Eating Petfood... buddy.bark(); // Ruff!  The different behaviors were defined by using the prefix can. Also, some behavior was combined Listing 3.10, 2 by composition. Let's create another animal, for example, a cat. The cat can talk and, it can eat as all animals do: Listing 3.11 const cat = (name) =&gt; { const self = { name, }; const catBehaviors = (self) =&gt; ({ meow: () =&gt; console.log(&quot;Meow!&quot;), haveLunch: (food) =&gt; { self.eat(food); }, }); return Object.assign(self, catBehaviors(self), canEat()); }; const kitty = cat(&quot;Kitty&quot;); kitty.haveLunch(&quot;fish&quot;); // Eating fish... kitty.meow(); // Meow!  Keep in mind that all functionality was added in the same self reference, that is a reason why self.eat can be called within haveLunch. That allows us to create catBehaviors on top of other behaviors. So composition is easier in maintenance and for reusability purposes. It is easy to refactor the code if needed. Composition is a simple mental model, so there is no need to think in advance of hierarchy, and we can combine all small pieces in the way that we need them to be. For example, Listing 3.12. The task is to create a statistic board with the possibility to sort, find all occurrences, and filter by prop. Listing 3.12 const stat = [ { name: &quot;Lora&quot;, score: 1.003 }, { name: &quot;Lora&quot;, score: 1.003 }, { name: &quot;Lora&quot;, score: 2 }, { name: &quot;Max&quot;, score: 3.76 }, ]; const sort = (arr) =&gt; { return arr.sort((a, b) =&gt; b.score - a.score); }; const filter = (params) =&gt; { return (arr) =&gt; arr.filter((item) =&gt; item.name === params); }; const findAll = (params) =&gt; { return (arr) =&gt; arr.filter((item) =&gt; item.score === params); }; const compose = (...funcs) =&gt; { return (arr) =&gt; { return funcs.reverse().reduce((acc, func) =&gt; func(acc), arr); }; }; console.log(compose(filter(&quot;Lora&quot;))(stat)); // [{ name: &quot;Lora&quot;, score: 1.003 }, { name: &quot;Lora&quot;, score: 1.003 }, { name: &quot;Lora&quot;, score: 2 }] console.log(compose(findAll(1.003), filter(&quot;Lora&quot;))(stat)); // [{ name: &quot;Lora&quot;, score: 1.003 }, { name: &quot;Lora&quot;, score: 1.003 }] console.log(compose(sort, filter(&quot;Lora&quot;))(stat)); // [{ name: &quot;Lora&quot;,score: 2 }, { name: &quot;Lora&quot;,score: 1.003 }, { name: &quot;Lora&quot;,score: 1.003 }]  sort function sorts,findAll function finds all score occurrences,and filter filters by name,compose function is a self-invoking* function that can take any number of parameters and execute right-to-left, in other words, performs right-to-left function composition. So, you can compose functions the way you need. There is a possibility to filter and sort in one part of the application and filter and find in another without any duplication, by composing small reusable parts. * self-invoking function is a nameless (anonymous) function that is invoked immediately after its definition. "},{"title":"2. SOLID","type":0,"sectionRef":"#","url":"docs/solid-principles/solid","content":"","keywords":""},{"title":"2.1 Single Responsibility Principle (SRP)​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#21-single-responsibility-principle-srp","content":"info A class should have one and only one reason to change, meaning that a class should have only one job. Classes, software components and microservices that have only one responsibility are much easier to explain, understand and implement than the ones that provide a solution for everything. This reduces the number of bugs, improves your development speed, and makes your life as a software developer a lot easier. Unfortunately, following the single responsibility principle sounds a lot easier than it often is. If you build your software over a longer period and if you need to adapt it to changing requirements, it might seem like the easiest and fastest approach is adding a method or functionality to your existing code instead of writing a new class or component. But that often results in classes with more responsibilities and makes it more and more difficult to maintain the software. You can avoid these problems by asking simple questions before you make any changes: Is this class doing too much? Correct answer: No, it is responsible for only one specific functionality.How many sources of new requirements does this class have? Correct answer: Single source or new requirements.Who is this class responsible to? Correct answer: It is only responsible to one person or role. "},{"title":"2.1.1 SRP Example​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#211-srp-example","content":"Suppose we have TradeProcessor class, which purpose is to retrieve trade operations from one data source and transfer them to another. TradeProcessor class responsibilities are: read each line from the Stream parameter.parse fields from each line and store them in an array of TradeRecord instances with validation.iterate over an array of TradeRecord instances and save them to the database. Listing 2.1 class TradeProcessor { public process(stream: Stream) { const connection = new DBConnection(/* */); const reader: StreamReader = new StreamReader(stream); const lines: string[] = reader.readLines(); lines.reduce((records: TradeRecord[], line: string) =&gt; { const fields = line.split(','); if (fields.length !== 2) { /* handle format validation error */} const [amount, price] = [parseInt(fields[1], 10), parseInt(fields[2], 10)]; if (amount &lt; 0 || price &lt; 0) { /* handle trade validation error */} return [...records, new TradeRecord(amount, price)]; }, []).forEach((trade: TradeRecord) =&gt; { connection.save(trade); }) connection.close() } }  SRP states that class should have only one reason to change. However, the reality of TradeProcessor is that it will change under the following circumstances: You need to change the data source from the stream to the REST API.The data format needs to be changed.Validation rules have changed.When the procedure for saving data to the database changes, for example, instead of mapping incoming parameters to a database table, we will save them in several tables with foreign keys. Now you need to ask &quot;Who is to blame for the changes?&quot;. Having answered it, you will divide the requirements into three groups of responsibilities. What to do next? Separate the interfaces and as a result make the class follow SRP. So, the first step in refactoring TradeProcessor is to create interfaces that will be used to perform three high-level tasks: reading, processing and storing trade data. In accordance with the SRP, three main responsibilities will be carried out by three different classes. Figure 2.1 - SRP  So, now the class TradeProcessor is not engaged in the process of reading, parsing, validating and saving trade operations to the database. It is simulating the process of transferring trade data from one format to another. This is its only responsibility and the only reason it can be changed. If the process itself changes, TradeProcessor class will also be changed. If new requirements come for specific parts of the process, they will be introduced into the appropriate classes. In this case there is no need to change TradeProcessor class. Listing 2.2 class TradeProcessor { constructor(private validator: Validator, private storage: Storage) {} public process(trades: DataProvider) { const validTrades = trades.reduce((validTrades: TradeRecord[], trade: TradeRecord) =&gt; { if (!this.validator.isValid(trade)) { /* handle invalid data */} return [...validTrades, trade]; }, []) this.storage.persist(validTrades); } }  You may ask: &quot;What if we already have clients who use TradeProcessor in its previous implementation?&quot; This is a valid question, and ideally you should already have an interface or abstract processor class allocated. We just add a new processor implementation in the form of an adapter composing the new version and adjusting it to the old interface. If we do not have such abstraction, then we can implement the adapter directly in the current processor implementation, declare it deprecated and remove it in the next version of the application/library. "},{"title":"2.1.2 SRP Summary​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#212-srp-summary","content":"When to use? Your module is constantly changing and the requirements for changes come from different roles in your project.The actions in the module do not correlate with each other.The logic in the module is too complex to understand and / or test. How to apply? Combine things that change for one reason. Separate things that change for different reasons.Isolate changes, separate the component parts of the module logically.Reduce dependencies.Apply the principle only when it matters. Do not introduce extra dependencies. "},{"title":"2.2 Open-Closed Principle (OCP)​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#22-open-closed-principle-ocp","content":"info Objects or entities should be open for extension but closed for modification. Based on the definition above modules have two main characteristics: They are open to expansion. It means that the behavior of the module can be extended. When the requirements for the application change, we add new behavior to the module to meet the changed requirements.They are closed for modification. It means that extending a module's behavior does not involve changes to the source code of the module. In other words, we should be able to change the behavior of the module without changing the module itself. How to achieve that? "},{"title":"2.2.1 OCP Example​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#221-ocp-example","content":"Let us go back to the TradeProcessor example. When we removed data retrieval, parsing and saving from TradeProcessor class and created separate class for each type of responsibility, we made TradeProcessor class to conform to OCP. If the requirements change, we can get completely different functionality without changing the TradeProcessor itself. Suppose at some point we were given requirement to support multiple data sources at the same time (stream, REST API and XML file). It is not a problem for us. We can use polymorphic DataProvider in TradeProcessor. As you can see on the diagram below, we have created classes for every data source: StreamDataProvider, RESTAPIDataProvider and XMLFileDataProvider. All of them are inherited from base DataProvider class and override reduce() method. So, in the future, whenever we need to receive data from some new sources, we will do exactly the same thing. Therefore, OCP is not violated. We are closed for modifications (no need to change DataProvider class) and at the same time we are open for expansion. Figure 2.2 - OCP  "},{"title":"2.2.2 Single Choice Principle​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#222-single-choice-principle","content":"Suppose we have a hierarchy of classes designed to import data from files of different formats. We also have a factory method that creates the required Importer depending on the file extension. Does the implementation of such a factory comply with the OCP? Or do we need to introduce an ImporterFactory interface and factory hierarchy to comply with this principle? The factory method by itself already hides the way to get the desired Importer from its customers and an additional level of indirection is not needed here. Listing 2.3 class ImporterFactory { public static create(fileName: string): Importer { switch(getExtension(fileName)) { case 'json': return new JsonImporter(); case 'xls': case 'xlsx': return new XlsImporter(); default: throw new Error('Extension is not supported') } } }  Here is what Bertrand Meyer writes about this: &quot;It is necessary to admit the possibility that the list of variants, given and known at some stage of program development, may subsequently be changed by adding or removing variants. To ensure that this approach to the software development process is implemented, you need to find a way to protect the program structure from the impact of such changes. Hence, follows the principle of Single Choice.&quot; info In other words: whenever a software system needs to support multiple alternatives, only one module of the system should know the complete list. "},{"title":"2.2.3 OCP Summary​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#223-ocp-summary","content":"So, the goal of OCP is to minimize changes to existing classes when new functionality is added. It is achieved by adding extension points (not just inheritance) that allow us to take advantage of powerful tools like composition, aggregation, and polymorphism. "},{"title":"2.3 Liskov Substitution Principle (LSP)​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#23-liskov-substitution-principle-lsp","content":"info Let Q(x) be a property provable about objects x of type T. Then Q(y) should be true for objects y of type S where S is a subtype of T. To be honest, such a scientific definition might be necessary, but it does not help a lot in our daily work as software developers. So, what does it mean for our code? The principle defines that objects of a superclass should be replaceable with objects of its subclasses without breaking the application. That requires the objects of your subclasses to behave in the same way as the objects of your superclass. Clients can reliably use any type or subtype, always expecting consistent behavior or, in other words, that the contract will be kept. A simple formulation of the principle is as follows: it should be possible to substitute any subtype for base type. There are several &quot;rules&quot; that must be followed for LSP compliance: contract rules and variance rules. "},{"title":"2.3.1 Contract Rules​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#231-contract-rules","content":"1. Preconditions cannot be strengthened in a subtype Preconditions are defined as all the conditions necessary for a method to run reliably and without fault. If subclass is replaced with superclass and preconditions are tightened for existing methods, then existing functionality will break. Suppose we have a class for calculating shipping price ShippingCalculator. This class has calculate() method defined, which takes two arguments: size and weight and calculates delivery price. The calculate() method will not work properly if weight or size provided are less or equal zero. These are preconditions. Suppose at some point we are given new requirements for shipping service: we need to support worldwide delivery that should be done only if weight and size of product we want to deliver are less than 10. We create class WorldWideShipping that extends ShippingCalculator class and override calculate() method based on new requirements. Now WorldWideShipping does not fulfill ShippingCalculator expectations, because it works only with size and weight less than 10. As a result, WorldWideShipping strengthens preconditions and violates the Liskov substitution principle. All clients should now be aware of the new type and treat it as a special case. Listing 2.4 class ShippingCalculator { public calculate(weight: number, size: number, destination: USADestination) { if (weight &lt;= 0 || size &lt;= 0) { throw new Error('Weight and size should be greater than 0') } const shippingPrice = weight * size; return shippingPrice; } } class WorldWideShipping extends ShippingCalculator { // correct destination type passed: Destination public calculate(weight: number, size: number, destination: Destination) { // preconditions are strengthened if (weight &lt; 10 &amp;&amp; size &lt; 10) { throw new Error('No international shipping for you') } return super.calculate(weight, size, destination); } }  2. Postconditions cannot be weakened in a subtype Postconditions check whether an object is being left in a valid state before a method is returned. The reason you cannot weaken postconditions is because existing clients might break when a new subclass is introduced. Let us get back to ShippingCalculator.calculate() method. The postcondition is the rule that the delivery cost is always more than 0. Suppose our customers decided to bring in free delivery for products which size and weight are less than 1. We create class FreeShipping and override calculate() method based on new requirements. In this case, we weakened postconditions compared to the original ones. We broke the original logic which assumed that the shippingPrice is always a positive number. As a result, clients who are sure in original postconditions and who have previously worked with the base class, may break when switching to the subclass. Moreover, it will also be required for them to check which instance of the calculator they are working with to handle new requirements. Listing 2.5 class FreeShipping extends ShippingCalculator { // incorrect destination type passed: should be Destination public calculate(weight: number, size: number, destination: TexasDestination) { if (weight &lt;= 0 || size &lt;= 0) { throw new Error('Weight and size should be greater than 0') } // postconditions are weakened const shippingPrice = (weight &lt; 1 &amp;&amp; size &lt; 1) ? 0 : super.calculate(weight, size, destination); return shippingPrice; } }  "},{"title":"2.3.2 Variance Rules​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#232-variance-rules","content":"1. There must be covariance of the return types in the subtype. Covariance is when function return values can be changed to subtypes, moving down the hierarchy. Let us have a look at the example below. Suppose we have a base Product class defined with getShippingProvider() method which returns an instance of ShippingCalculator class. We want to introduce a new product phone, that is why we create Phone class and extend it from base Product class. Phones can be delivered worldwide. Therefore, getShippingProvider() should return an instance of WorldWideShipping class. Covariance of return types is kept: getShippingProvider() returns an instance of WorldWideShipping class, which is subtype of ShippingCalculator (moving down to hierarchy). Listing 2.6 class Product { public getShippingProvider() : ShippingCalculator { return new ShippingCalculator(); } } class Phone extends Product { // WorldWideShipping is subtype of ShippingCalculator public getShippingProvider() : WorldWideShipping { return new WorldWideShipping(); } }  Example of violating the covariance rule of return types in subtype is given below. As you can see, we are moving up the hierarchy of classes. Listing 2.7 class Product { public getShippingProvider() : WorldWideShipping { return new WorldWideShipping(); } } class Phone extends Product { public getShippingProvider() : ShippingCalculator { return new ShippingCalculator(); } }  2. There must be contravariance of the method arguments in the subtype. Contravariance is when function arguments can be changed to supertypes, moving up the hierarchy. Let us have a look at the example below. Suppose at some point we decided to deliver products only to the USA and free shipping is possible only to Texas. We extend calculate() method and pass destination needed to it. Contravariance of function arguments is kept in WorldWideShipping class, but not in FreeShipping class. Destination should be an instance of Destination class in FreeShipping.calculate() method. Listing 2.8 class Destination {} class USADestination extends Destination {} class TexasDestination extends USADestination {} class ShippingCalculator { public calculate(weight: number, size: number, destination: USADestination) { // calculate } } class WorldWideShipping extends ShippingCalculator { // correct destination type passed: Destination public calculate(weight: number, size: number, destination: Destination) { // calculate } } class FreeShipping extends ShippingCalculator { // incorrect destination type passed: should be Destination public calculate(weight: number, size: number, destination: TexasDestination) { // calculate } }  3. Invariants must be maintained. A data invariant is a state that remains true for the entire lifetime of an object. Data invariants refer to the expected internal state of an object. Whenever a new subclass is created, it must continue to honor all the data invariants that were part of the base class. The violation of this principle is easy to introduce because subclasses have a lot of freedom to introduce new ways of changing previously private data. A list of users with unique emails can be an example of a data invariant. Let us have a look at Users.add() method. By adding a simple guard condition to the method, we prevented adding an invalid value and preserved the data invariant. In NotUniqueUsers.add() method we violate the parent class invariants, since we give the opportunity to add non-unique values to the collection of users. Data invariants must be persisted throughout the hierarchy of classes. Every class in the chain of inheritance must fulfill the invariants of all its heirs, otherwise no one can guarantee the correctness of the behavior. Listing 2.9 class User { constructor(private email: string) {} hasSameEmail(other: User) : boolean { return other.email === this.email; } } class Users { private users: User[] = []; public add(user: User) : boolean { if (this.users.some(user.hasSameEmail.bind(user))) { return false; } this.users.push(user); return true; } } class NotUniqueUsers extends Users { private collection: User[] = []; public add(user: User) : boolean { this.collection.push(user); return true; } }  "},{"title":"2.3.3 LSP Summary​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#233-lsp-summary","content":"In case of not following LSP: Inheritance hierarchies will lead to confusion. So, passing the subclass instance instead of base class into the method will result in a weird behavior of the existing code.Unit tests for base class will never pass for subclasses. "},{"title":"2.4 Interface Segregation Principle (ISP)​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#24-interface-segregation-principle-isp","content":"info A client should never be forced to implement an interface that it does not use, or clients should not be forced to depend on methods that they do not use. The goal of this principle is to reduce the side effects of using larger interfaces by breaking application interfaces into smaller ones. It is like the Single Responsibility Principle, where each class or interface serves a single purpose. Precise application design and correct abstraction is the key behind the Interface Segregation Principle. Though it will take more time and effort in the design phase of an application and might increase the code complexity, in the end, we get a flexible code. "},{"title":"2.4.1 ISP Example​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#241-isp-example","content":"Let us have a look at the example below. We have Staff interface and class Lecturer that implements Staff interface. Thus, it does not violate the principle. For simplicity, let us ignore the actual business implementation of these methods. Listing 2.10 interface Staff { name: string, salary: number, adjustSalary(): number, } class Lecturer implements Staff { constructor(public name:string, public salary:number) {} adjustSalary() { return this.salary * 0.9 } }  Now, as we move ahead in time, and more features come in, there is a need to add management staff, so we created Administrator class. Everything looks good so far. But what if we need to extend Lecturer and Administrator classes behavior? Let us say that we want to add giveLecture() method to Lecturer class and arrangeMeeting() to Administrator. In this case we need to extend Staff interface with those methods. Listing 2.11 interface Staff { name: string, salary: number, adjustSalary(): number, giveLecture():void, arrangeMeeting(): void } class Lecturer implements Staff { constructor(public name: string, public salary: number) {} adjustSalary() { return this.salary * 0.9 } giveLecture() {} arrangeMeeting() {} } class Administrator implements Staff { constructor(public name: string, public salary: number) {} adjustSalary() { return this.salary * 0.75 } arrangeMeeting() { } giveLecture() {} }  Now, since the Staff interface has changed and more methods were added, all the implementing classes now must implement the new methods. The problem is, implementing them is unwanted and could lead to many side effects. Here, the Administrator implementation class must implement the giveLecture() method without any actual need for this. And so, the principle is violated. Let us break up the interfaces and apply the Interface Segregation Principle. As you can see, we have created two more interfaces AcademicStaff and ManagerStaff that extend the base Staff interface. Each of the new interfaces contain only those methods that they need. Therefore, Lecturer class now implements AcademicStaff and Administrator class AcademicStaff interface. Listing 2.12 interface Staff { name: string, salary: number, adjustSalary(): number, } interface AcademicStaff extends Staff { giveLecture(): void, } interface ManagerStaff extends Staff { arrangeMeeting(): void, } class Lecturer implements AcademicStaff { constructor(public name: string, public salary: number) {} adjustSalary() { return this.salary * 0.9 } giveLecture() {} } class Administrator implements ManagerStaff { constructor(public name: string, public salary: number) {} adjustSalary() { return this.salary * 0.75 } arrangeMeeting() { } }  "},{"title":"2.4.2 ISP Summary​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#242-isp-summary","content":"As you can see fat interfaces lead to inadvertent coupling between classes, and you should avoid them. When designing interfaces, you should always ask yourself the question &quot;Do really need all the methods on this interface I'm using? If not, how can I break them into smaller interfaces?&quot;. Treat interface segregation with certain pragmatism and use common sense. "},{"title":"2.5 Dependency Inversion Principle (DIP)​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#25-dependency-inversion-principle-dip","content":"info High-level modules should not depend on low-level modules. Both should depend on abstractions. Abstractions should not depend on details. Details should depend on abstractions. The general idea of this principle is as simple as it is important: High-level modules, which provide complex logic, should be easily reusable and unaffected by changes in low-level modules, which provide utility features. To achieve that, you need to introduce an abstraction that decouples the high-level and low-level modules from each other. The design principle does not just change the direction of the dependency, as you might have expected when you read its name for the first time. It splits the dependency between the high-level and low-level modules by introducing an abstraction between them. So, in the end, you get two dependencies: the high-level module depends on the abstraction, and the low-level depends on the same abstraction. "},{"title":"2.5.1 DIP Example​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#251-dip-example","content":"Let us dive deep into dependency inversion principle by having a look at the example below. Suppose we are working on an application that uses MySQL database. We have UserTransaction class that will be used to query User table in the database. It contains init() method that takes instance of MySQLDatabase class and two base operations: insert() and delete(). Listing 2.13 interface Database { insert(entity: object): object delete(entity: object): object get(entity: object): object } class UserTransaction { private db; init(db: MySQLDatabase) { this.db = db } insert(user: object) { return (!this.db.get(user)) ? this.db.insert(user) : null; } delete(user: object) { return (!this.db.get(user)) ? this.db.delete(user) : null; } }  MySQLDatabase is a low-level module, UserTransaction is a high-level one. But based on the definition of the Dependency Inversion Principle, which says to separate abstractions from the implementation, this fragment of code violates it, because the UserTransaction class depends on the MySQLDatabase class. But what if at some point we decided to replace MySQL to PostgreSQL database, which has a completely different interface compared to MySQL? We would not only need to create PostgreSQLDatabase class, but also update UserTransaction class implementation. Listing 2.14 class PostgreSQLDatabase { insert(entity: object) { return { /* insert using PostgreSQL syntax */ } } delete(entity: object) { return { /* delete using PostgreSQL syntax */ } } get(entity: object) { return { /* get using PostgreSQL syntax */ } } }  There should be low coupling between classes used. UserTransaction class does not have to worry about the database being used. To fix that, we have to create an interface so that the low-level and high-level modules depend on the abstraction (interface). Listing 2.15 interface Database { insert(entity: object): object delete(entity: object): object get(entity: object): object } class PostgreSQLDatabase implements Database { insert(entity: object) { return { /* insert using PostgreSQL syntax */ } } delete(entity: object) { return { /* delete using PostgreSQL syntax */ } } get(entity: object) { return { /* get using PostgreSQL syntax */ } } } class UserTransaction { private db; init(db: Database) { this.db = db } insert(user: object) { return (!this.db.get(user)) ? this.db.insert(user) : null; } delete(user: object) { return (!this.db.get(user)) ? this.db.delete(user) : null; } }  Now both modules (low-level and high-level) depend on abstraction. No matter which database is used (either PostgreSQL or MySQL), UserTransaction class depends on Database interface. Therefore, if at some point we decide to roll back to MySQL or introduce a new database, we will not need to change the UserTransaction class. Dependency Inversion principle is not violated, and we can introduce new requirements very quickly without changing all the related modules. "},{"title":"2.5.2 DIP Summary​","type":1,"pageTitle":"2. SOLID","url":"docs/solid-principles/solid#252-dip-summary","content":"The Dependency Inversion Principle is the fifth and final design principle that we discussed in this lecture. It introduces an interface abstraction between higher-level and lower-level software components to remove the dependencies between them. When to allocate an interface from a class? Class is an implementation of some strategy and will be used in a polymorphic manner.Class is used to work with external environments (files, sockets, configuration, etc.). When not to allocate a class interface? Class is an immutable Value Object or Data Object.Class has stable behavior (does not work with the external environment). "}]